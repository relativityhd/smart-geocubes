{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#smart-geocubes","title":"Smart-Geocubes","text":"<p>A high-performance library for intelligent loading and caching of remote geospatial raster data, built with xarray, zarr and icechunk.</p> <p>Inspiration</p> <p>The concept of this package is heavily inspired by EarthMovers implementation of serverless datacube generation.</p>"},{"location":"#quickstart","title":"Quickstart","text":"<p>Install the package with <code>uv</code> or <code>pip</code>:</p> <pre><code>pip install smart-geocubes\n</code></pre> <pre><code>uv add smart-geocubes\n</code></pre> <p>Open data for your region of interest:</p> <pre><code>import smart_geocubes\nfrom odc.geo.geobox import GeoBox\n\naccessor = smart_geocubes.ArcticDEM32m(\"datacubes/arcticdem_32m.icechunk\")\n\nroi = GeoBox.from_bbox((150, 65, 151, 65.5), shape=(1000, 1000), crs=\"EPSG:4326\")\n\narcticdem_at_roi = accessor.load(roi, create=True)\n</code></pre>"},{"location":"#whats-next","title":"What's next?","text":"<ul> <li> <p> Getting Started</p> <p>Get an overview on how this package works.</p> <p> Get Started</p> </li> <li> <p> Write custom Dataset Accessors</p> <p>Read how <code>smart-geocubes</code> works to learn how to access other datasets with own implemented accessors.</p> <p> How it Works</p> </li> <li> <p> Contribute</p> <p>Learn about what I plan to do with this package and how you can help.</p> <p> Contribute &amp; Roadmap</p> </li> <li> <p> API Reference</p> <p>View the API reference of the components.</p> <p> Reference</p> </li> </ul>"},{"location":"#out-of-the-box-included-datasets","title":"Out of the box included datasets","text":"Dataset Quickuse Source Link ArcticDEM Mosaic 2m <code>smart_geocubes.ArcticDEM2m</code> STAC PGC ArcticDEM Mosaic 10m <code>smart_geocubes.ArcticDEM10m</code> STAC PGC ArcticDEM Mosaic 32m <code>smart_geocubes.ArcticDEM32m</code> STAC PGC Tasseled Cap Tren <code>smart_geocubes.TCTrend</code> Google Earth Engine AWI"},{"location":"#implemented-remote-accessors","title":"Implemented Remote Accessors","text":"Accessor Description <code>smart_geocubes.accessors.STAC</code> Accessor for the STAC API, which allows to download data from a STAC API. <code>smart_geocubes.accessors.GEE</code> Accessor for Google Earth Engine, which allows to download data from Google Earth Engine."},{"location":"#what-is-the-purpose-of-this-package","title":"What is the purpose of this package?","text":"<p>This package solves a specific problem that most people who work with Earth observation data don't need to worry about. When you're creating new data from existing data (for example, doing image segmentation with machine learning on Sentinel-2 images), people usually:</p> <ol> <li>Download all the data</li> <li>Run the algorithms and data science on it</li> <li>Delete the data afterwards</li> </ol> <p>This \"batched-processing\" works great if you have a big computer with lots of storage space, like a cluster.</p> <p>But if you're working on a smaller computer (like a laptop with a few hundred GB of storage and 16GB of RAM), this approach creates problems. It makes it really hard to test and improve your programs because you don't have enough space. Using frameworks like Ray for processing is also tricky with this approach. They work better with \"concurrent-processing\": when each step of your processing pipeline can be done for each elements separately instead expecting to run a single step for all your data at once. Plus, if you only need to look at certain areas but don't know which ones ahead of time, downloading everything is wasteful.</p> <p>So instead, this package downloads the data only when you need it. But downloading the same thing over and over is inefficient. That's why we save (or \"cache\") the data on your computer's hard drive in form of zarr datacubes. We call this way of working \"procedural download\" because you download pieces as you need them.</p> <p>Therefore, this package does handle:</p> <ol> <li>The download \"on-demand\" (or \"procedural download\") of the data</li> <li>The caching of the data on your computer's hard drive</li> <li>The loading of the data into memory for regions specified by the user</li> <li>Making everything thread-safe, so you can run on any scaling framework you like.</li> </ol> <p>Multiprocessing</p> <p>On linux systems it is necessary to the the multiprocessing start method to <code>spawn</code> or <code>forkserver</code>. Read more about this here, here and here.</p> <p>The approach itself is already implemented in one of the pipelines we develop at the AWI, you can read more about their docs.</p> <p>Cloud computing</p> <p>This won't help if your computer doesn't have fast storage space available - like if you're working on a cloud-cluster that can't save files locally.</p>"},{"location":"contribute/","title":"Contribute","text":""},{"location":"contribute/#contribute","title":"Contribute","text":"<p>You are welcome do add a new pre-defined dataset. For other features, please open an issue on GitHub.</p>"},{"location":"contribute/#roadmap","title":"Roadmap","text":"<p>Features:</p> <ul> <li> STAC: Add dask download as optional</li> <li> STAC: Make the progress-bar optional</li> <li> Overall: Add support for temporal axis</li> <li> Overall: Add support for 3D data</li> <li> Overall: Add support for 4D data</li> <li> GEE Accessor</li> <li> Widen support for lat-lon data</li> <li> Support different x-y resolutions</li> <li> True threaded mode: multiple threads for downloading, one thread for writing, multiple for loading</li> <li> Predownload data</li> <li> Interface with geobox</li> <li> Interface with geopandas: find all intersecting tiles between geopandas and the cubes extent</li> </ul> <p>Datasets:</p> <ul> <li> ArcticDEM: increase readspeed by using extent files</li> <li> TCTrend Dataset</li> <li> S2 Dataset</li> <li> Landsat Dataset</li> </ul> <p>Admin:</p> <ul> <li> Use StopUhr to measure performance</li> <li> Write documentation (sphinx or mkdocs)</li> <li> Add GitHub Action</li> <li> Publish to PyPy</li> <li> Replace all execptions with custom exceptions</li> <li> Further flatten the public facing API</li> <li> Replace TileWrapper NamedTuple with a dataclass</li> <li> Make concurrency and storage module private</li> </ul>"},{"location":"how_it_works/","title":"How does it work?","text":""},{"location":"how_it_works/#how-does-it-work","title":"How does it work?","text":"<p>Uncomplete and out of date</p> <p>As of right now, this documentation page is just copied from the DARTS documentation. It will be updated in the future.</p>"},{"location":"how_it_works/#why-zarr-datacubes","title":"Why Zarr Datacubes?","text":"<p>Zarr is a file format for storing chunked, compressed, N-dimensional arrays. It is designed to store large arrays of data, and to facilitate fast and efficient IO. Zarr works well integrated with Dask and Xarray.</p> <p>By storing the auxiliary data in Zarr Datacubes, it is much easier and faster to access the data of interest. If we would use GeoTiffs, we would have to first create a Cloud-Optimized GeoTiff (COG), which is basically an ensemble (mosaic) of multiple GeoTiffs. Then we would have to read from the COG, which behind the scenes would open multiple GeoTiffs and crops them to fit the region of interest. E.g. Opening a specific region of interest 10km x 10km from a 2m resolution COG would take up to 2 minutes, if the COGs extend is panarctic. Opening the same region from a Zarr Datacube takes less than 1 second.</p>"},{"location":"how_it_works/#procedural-download","title":"Procedural download","text":"<p>Info</p> <p>The currently used auxiliary data is downloaded on demand, only data actually used is downloaded and stored on your local machine. Hence, the stored datacubes can be thought of as a cache, which is filled with data as needed.</p> <p>There are currently two implementations of the procedural download used: a cloud based STAC download and a download via Google Earth-Engine.</p> <p>Because the single tiles of the STAC mosaic can be overlapping and intersect with multiple Zarr chunks, the STAC download is slightly more complicated. Since Google Earth-Engine allows for exact geoboxes, download of the exact chunks is possible. This reduces the complexity of the download.</p> STAC GEE 1. ROI 2. ROI <p>The above graphics shows the difference between loading data from STAC (left) and Google Earth-Engine (right). With the STAC download, the data is downloaded from a mosaic of tiles, which can be overlapping with each other and cover multiple Zarr chunks. It may occur that a chunk is not fully covered by the STAC mosaic, which results in only partial loaded chunks. In such cases, the missing data in these chunks will be updated if the other intersecting tile is downloaded, which may occur to a later time if a connected ROI is requested. The download process is much easier for GEE, since one can request the exact geoboxes of the Zarr chunks and GEE will handle the rest. Hence, chunks will always be fully covered by the downloaded data.</p> <p>Regarding the open ROI process, both implementations follow the same principle:</p> <ol> <li>Check which Tiles / Chunks intersect with the region of interest</li> <li>Dowload all new Tiles / Chunks</li> <li>Store the new Tiles / Chunks in their specific Zarr chunks</li> <li>Return the region of interest of the Zarr Datacube</li> </ol>"},{"location":"how_it_works/#stac-download","title":"STAC download","text":""},{"location":"how_it_works/#google-earth-engine-download","title":"Google Earth-Engine download","text":""},{"location":"examples/quickstart/","title":"Getting started with smart-geocubes","text":"In\u00a0[\u00a0]: Copied! <pre>import folium\nfrom odc.geo.geobox import GeoBox\nfrom stopuhr import stopuhr\n\nimport smart_geocubes\n</pre> import folium from odc.geo.geobox import GeoBox from stopuhr import stopuhr  import smart_geocubes <p>Let's start by creating an accessor to the ArcticDEM dataset. <code>smart-geocubes</code> provides the 32m resolution mosaic of the ArcticDEM dataset, along with some other datasets.</p> In\u00a0[\u00a0]: Copied! <pre>accessor = smart_geocubes.ArcticDEM32m(\"datacubes/arcticdem_32m.icechunk\")\naccessor\n</pre> accessor = smart_geocubes.ArcticDEM32m(\"datacubes/arcticdem_32m.icechunk\") accessor Out[\u00a0]: <pre>ArcticDEM32m(GeoBox(Shape2d(x=231256, y=234381), Anchor[-4000096.0 - 4100096.0], EPSG:3413), ['dem', 'datamask'])</pre> <p>This didn't do much yet. Let's define an region of interest with an ODC-GeoBox in eastern russia.</p> In\u00a0[3]: Copied! <pre>roi = GeoBox.from_bbox((150, 65, 151, 65.5), shape=(1000, 1000))\nroi.explore()\n</pre> roi = GeoBox.from_bbox((150, 65, 151, 65.5), shape=(1000, 1000)) roi.explore() Out[3]: Make this Notebook Trusted to load map: File -&gt; Trust Notebook <p>Now let's load the data. We measure the time with the <code>stopuhr</code> package, which provides a very convinient contextmanager for timing code blocks.</p> <p>Note: This may take a while (up to 10 minutes), since the data is downloaded from the ArcticDEM STAC API.</p> In\u00a0[4]: Copied! <pre>with stopuhr(\"Loading ArcticDEM at ROI\"):\n    arcticdem_at_roi = accessor.load(roi, create=True)\nprint(arcticdem_at_roi)\n</pre> with stopuhr(\"Loading ArcticDEM at ROI\"):     arcticdem_at_roi = accessor.load(roi, create=True) print(arcticdem_at_roi) <pre>Loading ArcticDEM at ROI took 109.95s\n&lt;xarray.Dataset&gt; Size: 20MB\nDimensions:      (y: 2110, x: 1908)\nCoordinates:\n  * y            (y) float64 17kB 2.657e+06 2.657e+06 ... 2.589e+06 2.589e+06\n    spatial_ref  int32 4B 3413\n  * x            (x) float64 15kB -7.581e+05 -7.581e+05 ... -6.971e+05\nData variables:\n    dem          (y, x) float32 16MB 103.4 103.6 103.8 ... 79.65 79.78 79.67\n    datamask     (y, x) bool 4MB True True True True ... True True True True\nAttributes:\n    title:         ArcticDEM32m\n    loaded_tiles:  ['67_33_32m_v4.1', '66_34_32m_v4.1', '66_33_32m_v4.1', '67...\n</pre> <p>It took a while, but now we have the data downloaded and cached. Hence, opening the same region the next time will be much faster.</p> <p>Now let's visualize what we got.</p> In\u00a0[5]: Copied! <pre>m = roi.explore()\narcticdem_at_roi[\"dem\"].odc.explore(map=m)\nm\n</pre> m = roi.explore() arcticdem_at_roi[\"dem\"].odc.explore(map=m) m Out[5]: Make this Notebook Trusted to load map: File -&gt; Trust Notebook <p>Our data covers the region we defined, but it does not fit perfectly to our specified region. This is because we specified our region in another coordinate reference system (CRS) than the data is stored in. <code>smart-geocubes</code> will always return the data in the CRS of the dataset, which is EPSG:3413 for ArcticDEM. If we want to fit the data to our region, we need to reproject it manually, e.g. using <code>odc.geo</code>:</p> In\u00a0[6]: Copied! <pre>arcticdem_at_roi_reprojected = arcticdem_at_roi.odc.reproject(roi)\n\nm = roi.explore()\narcticdem_at_roi_reprojected[\"dem\"].odc.explore(map=m)\nm\n</pre> arcticdem_at_roi_reprojected = arcticdem_at_roi.odc.reproject(roi)  m = roi.explore() arcticdem_at_roi_reprojected[\"dem\"].odc.explore(map=m) m Out[6]: Make this Notebook Trusted to load map: File -&gt; Trust Notebook <p>As mentioned earlier, <code>smart-geocubes</code> cached the downloaded data. To be exact, it stored it in a <code>zarr</code> datacube backed an <code>icechunk</code> store, located in the <code>\"datacubes/arcticdem_32m.icechunk\"</code> folder we specified earlier at the creation of our accessor. This datacube will be filled up the more regions we download. We can visualize how much of the datacube is already filled:</p> In\u00a0[7]: Copied! <pre>accessor.visualize_state();\n</pre> accessor.visualize_state(); <p>We can see that the datacube is already filled with four tiles. That means that our region of interest overlaps with four tiles of the ArcticDEM dataset. Let us check this theory:</p> In\u00a0[8]: Copied! <pre>m = accessor.current_state().explore()\nroi.explore(map=m)\nm\n</pre> m = accessor.current_state().explore() roi.explore(map=m) m Out[8]: Make this Notebook Trusted to load map: File -&gt; Trust Notebook <p>Seems to be correct.</p> In\u00a0[9]: Copied! <pre>second_roi = GeoBox.from_bbox((150.5, 65, 151.5, 65.5), shape=(1000, 1000))\nsecond_roi.explore()\n</pre> second_roi = GeoBox.from_bbox((150.5, 65, 151.5, 65.5), shape=(1000, 1000)) second_roi.explore() Out[9]: Make this Notebook Trusted to load map: File -&gt; Trust Notebook In\u00a0[\u00a0]: Copied! <pre>with stopuhr(\"Loading ArcticDEM at second ROI\"):\n    arcticdem_at_second_roi = accessor.load(second_roi)\nprint(arcticdem_at_second_roi)\n</pre> with stopuhr(\"Loading ArcticDEM at second ROI\"):     arcticdem_at_second_roi = accessor.load(second_roi) print(arcticdem_at_second_roi) <pre>Loading ArcticDEM at second ROI took 0.24s\n&lt;xarray.Dataset&gt; Size: 20MB\nDimensions:      (x: 1919, y: 2119)\nCoordinates:\n    spatial_ref  int32 4B 3413\n  * x            (x) float64 15kB -7.812e+05 -7.811e+05 ... -7.198e+05\n  * y            (y) float64 17kB 2.65e+06 2.65e+06 ... 2.583e+06 2.583e+06\nData variables:\n    datamask     (y, x) bool 4MB False False False False ... True True True True\n    dem          (y, x) float32 16MB 95.91 95.91 95.91 ... 54.34 54.11 54.14\nAttributes:\n    title:         ArcticDEM32m\n    loaded_tiles:  ['67_33_32m_v4.1', '66_34_32m_v4.1', '66_33_32m_v4.1', '67...\n</pre> <p>Wow, this was fast! Because this region also overlaps with the tiles we already downloaded before, <code>smart-geocubes</code> just opened the existing tiles from the cache.</p> <p>Let's visualize all together (try to play with the layer control on the top right):</p> In\u00a0[11]: Copied! <pre>m = roi.explore(name=\"First ROI\", grid_lines=False)\nsecond_roi.explore(map=m, name=\"Second ROI\", grid_lines=False)\narcticdem_at_roi[\"dem\"].odc.explore(map=m, name=\"DEM at first ROI\")\narcticdem_at_second_roi[\"dem\"].odc.explore(map=m, name=\"DEM at second ROI\")\naccessor.current_state().explore(m=m, name=\"Already loaded tiles\")\nfolium.LayerControl().add_to(m)\nm\n</pre> m = roi.explore(name=\"First ROI\", grid_lines=False) second_roi.explore(map=m, name=\"Second ROI\", grid_lines=False) arcticdem_at_roi[\"dem\"].odc.explore(map=m, name=\"DEM at first ROI\") arcticdem_at_second_roi[\"dem\"].odc.explore(map=m, name=\"DEM at second ROI\") accessor.current_state().explore(m=m, name=\"Already loaded tiles\") folium.LayerControl().add_to(m) m Out[11]: Make this Notebook Trusted to load map: File -&gt; Trust Notebook In\u00a0[\u00a0]: Copied! <pre>third_roi = GeoBox.from_bbox((151, 65, 152, 65.5), shape=(1000, 1000))\nwith stopuhr(\"Loading ArcticDEM at third ROI\"):\n    arcticdem_at_third_roi = accessor.load(third_roi)\nprint(arcticdem_at_third_roi)\n</pre> third_roi = GeoBox.from_bbox((151, 65, 152, 65.5), shape=(1000, 1000)) with stopuhr(\"Loading ArcticDEM at third ROI\"):     arcticdem_at_third_roi = accessor.load(third_roi) print(arcticdem_at_third_roi) <pre>Loading ArcticDEM at third ROI took 67.40s\n&lt;xarray.Dataset&gt; Size: 21MB\nDimensions:      (x: 1930, y: 2126)\nCoordinates:\n    spatial_ref  int32 4B 3413\n  * x            (x) float64 15kB -8.041e+05 -8.041e+05 ... -7.424e+05\n  * y            (y) float64 17kB 2.644e+06 2.644e+06 ... 2.576e+06 2.576e+06\nData variables:\n    datamask     (y, x) bool 4MB True True True True ... True True True True\n    dem          (y, x) float32 16MB 89.64 89.88 90.26 ... 46.83 46.66 46.63\nAttributes:\n    title:         ArcticDEM32m\n    loaded_tiles:  ['67_33_32m_v4.1', '66_34_32m_v4.1', '66_33_32m_v4.1', '67...\n</pre> <p>It again took a while, but only half as long as the first time. This is because this region overlaps with four tiles, two of which we already downloaded. Hence, only two new tiles need to be downloaded. Let's visualize the new state of the datacube:</p> In\u00a0[13]: Copied! <pre>accessor.visualize_state();\n</pre> accessor.visualize_state(); <p>We can see that two new tiles were added to the datacube, making it a total of six tiles.</p> <p>Rerunning this notebook would not result in the same behavior: The load times would be significantly faster, since the data is already cached.</p>"},{"location":"examples/quickstart/#getting-started-with-smart-geocubes","title":"Getting started with smart-geocubes\u00b6","text":"<p>This notebook demonstrates how one could use the <code>smart-geocubes</code> package to download and cache specific regions from large scale geospatial datasets at the example of the ArcticDEM.</p>"},{"location":"examples/quickstart/#first-region","title":"First region\u00b6","text":""},{"location":"examples/quickstart/#reprojection","title":"Reprojection\u00b6","text":""},{"location":"examples/quickstart/#datacube-state","title":"Datacube State\u00b6","text":""},{"location":"examples/quickstart/#second-region","title":"Second region\u00b6","text":"<p>Let's load a different region of interest, located just next to the previous one:</p>"},{"location":"examples/quickstart/#third-region","title":"Third region\u00b6","text":"<p>What happens when we want to load a third region of interest, which only partially overlaps with the tiles we already downloaded?</p>"},{"location":"reference/smart_geocubes/","title":"smart_geocubes","text":""},{"location":"reference/smart_geocubes/#smart_geocubes","title":"smart_geocubes","text":"<p>Smart-Geocubes: A high-performance library for intelligent loading and caching of remote geospatial raster data, built with xarray and zarr.</p> <p>Modules:</p> <ul> <li> <code>accessors</code>           \u2013            <p>Smart-Geocubes accessor implementations.</p> </li> <li> <code>backends</code>           \u2013            <p>Download backends for smart-geocubes.</p> </li> <li> <code>core</code>           \u2013            <p>Core functionality of smart-geocubes.</p> </li> <li> <code>datasets</code>           \u2013            <p>Predefined datasets for the SmartGeocubes package.</p> </li> <li> <code>exceptions</code>           \u2013            <p>Exceptions for the smart_geocubes package.</p> </li> </ul> <p>Classes:</p> <ul> <li> <code>AlphaEarthEmbeddings</code>           \u2013            <p>Accessor for AlphaEarth Embeddings data.</p> </li> <li> <code>ArcticDEM10m</code>           \u2013            <p>Accessor for ArcticDEM 10m data.</p> </li> <li> <code>ArcticDEM2m</code>           \u2013            <p>Accessor for ArcticDEM 2m data.</p> </li> <li> <code>ArcticDEM32m</code>           \u2013            <p>Accessor for ArcticDEM 32m data.</p> </li> <li> <code>TCTrend2019</code>           \u2013            <p>Accessor for TCTrend data derived from 2000-2019.</p> </li> <li> <code>TCTrend2020</code>           \u2013            <p>Accessor for TCTrend data derived from 2001-2020.</p> </li> <li> <code>TCTrend2022</code>           \u2013            <p>Accessor for TCTrend data derived from 2003-2022.</p> </li> </ul>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings","title":"AlphaEarthEmbeddings","text":"<pre><code>AlphaEarthEmbeddings(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n)\n</code></pre> <p>               Bases: <code>GEEMosaicAccessor</code></p> <p>Accessor for AlphaEarth Embeddings data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the zarr array. Should be equal to the extent geobox.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_patches</code>             \u2013              <p>Get the adjacent patches for the given geobox.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>assert_temporal_cube</code>             \u2013              <p>Assert that the datacube has a temporal dimension.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_patch</code>             \u2013              <p>Download the data for the given patch.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>loaded_patches</code>             \u2013              <p>Get the ids of already (down-)loaded patches.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Post create actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>post_init</code>             \u2013              <p>Post init actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download tiles procedurally.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n        backend (Literal[\"threaded\", \"simple\"], optional): The backend to use for downloading data.\n            Currently, only \"threaded\" is supported. Defaults to \"threaded\".\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = Chronometer(logger.debug)\n\n    if backend == \"threaded\":\n        if not _check_python_version(3, 13):\n            raise NotImplementedError(\n                \"The 'threaded' backend is only fully supported in Python 3.13 and above.\"\n                \" Please consider using the 'simple' backend in a multiprocessing environment\"\n                \" or upgrade your Python version.\"\n            )\n        self.backend = ThreadedBackend(self.repo, self.download_patch)\n    elif backend == \"simple\":\n        self.backend = SimpleBackend(self.repo, self.download_patch)\n    else:\n        raise ValueError(f\"Unknown backend {backend}\")\n\n    self.post_init()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings(backend)","title":"<code>backend</code>","text":"(<code>Literal['threaded', 'simple']</code>, default:                   <code>'threaded'</code> )           \u2013            <p>The backend to use for downloading data. Currently, only \"threaded\" is supported. Defaults to \"threaded\".</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre> <p>Check if the datacube already exists in the storage.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.is_temporal","title":"is_temporal  <code>property</code>","text":"<pre><code>is_temporal: bool\n</code></pre> <p>Check if the datacube has a temporal dimension.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube has a temporal dimension.</p> </li> </ul>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.adjacent_patches","title":"adjacent_patches","text":"<pre><code>adjacent_patches(\n    roi: Geometry | GeoBox | GeoDataFrame, toi: TOI\n) -&gt; list[Item]\n</code></pre> <p>Get the adjacent patches for the given geobox.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[Item]</code>           \u2013            <p>list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the ROI type is invalid.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If the datacube is not temporal, but a time of interest is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def adjacent_patches(self, roi: Geometry | GeoBox | gpd.GeoDataFrame, toi: TOI) -&gt; list[Item]:\n    \"\"\"Get the adjacent patches for the given geobox.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        roi (Geometry | GeoBox | gpd.GeoDataFrame): The reference geometry, geobox or reference geodataframe\n        toi (TOI): The time of interest to download.\n\n    Returns:\n        list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.\n\n    Raises:\n        ValueError: If the ROI type is invalid.\n        ValueError: If the datacube is not temporal, but a time of interest is provided.\n\n    \"\"\"\n    if toi is not None and not self.is_temporal:\n        raise ValueError(\"Datacube is not temporal, but time of interest is provided.\")\n\n    if isinstance(roi, gpd.GeoDataFrame):\n        adjacent_geometries = (\n            gpd.sjoin(self._tile_geometries, roi.to_crs(self.extent.crs.wkt), how=\"inner\", predicate=\"intersects\")\n            .reset_index()\n            .drop_duplicates(subset=\"index\", keep=\"first\")\n            .set_index(\"index\")\n        )\n        spatial_idxs: list[tuple[int, int]] = list(adjacent_geometries[\"idx\"])\n    elif isinstance(roi, GeoBox):\n        spatial_idxs: list[tuple[int, int]] = list(self._extent_tiles.tiles(roi.extent))\n    elif isinstance(roi, Geometry):\n        spatial_idxs: list[tuple[int, int]] = list(self._extent_tiles.tiles(roi))\n    else:\n        raise ValueError(\"Invalid ROI type.\")\n\n    if not self.is_temporal:\n        return [\n            PatchIndex(\n                self._stringify_index(spatial_idx),\n                self._extent_tiles[spatial_idx].geographic_extent,\n                None,\n                Item(self._extent_tiles[spatial_idx], None),\n            )\n            for spatial_idx in spatial_idxs\n        ]\n\n    # Now datacube is temporal\n    toi = normalize_toi(self.temporal_extent, toi)\n    patch_idxs = []\n    for time in toi:\n        time_idx = self.temporal_extent.get_loc(time)\n        assert isinstance(time_idx, int), \"Non-Unique temporal extents are not supported!\"\n        for spatial_idx in spatial_idxs:\n            patch_idxs.append(\n                PatchIndex(\n                    self._stringify_index(spatial_idx, time_idx),\n                    self._extent_tiles[spatial_idx].geographic_extent,\n                    time,\n                    Item(self._extent_tiles[spatial_idx], time),\n                )\n            )\n    return patch_idxs\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.adjacent_patches(roi)","title":"<code>roi</code>","text":"(<code>Geometry | GeoBox | GeoDataFrame</code>)           \u2013            <p>The reference geometry, geobox or reference geodataframe</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.adjacent_patches(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\"\"\"\n    self.backend.assert_created()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.assert_temporal_cube","title":"assert_temporal_cube","text":"<pre><code>assert_temporal_cube()\n</code></pre> <p>Assert that the datacube has a temporal dimension.</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube has no temporal dimension.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_temporal_cube(self):\n    \"\"\"Assert that the datacube has a temporal dimension.\n\n    Raises:\n        ValueError: If the datacube has no temporal dimension.\n\n    \"\"\"\n    if self.temporal_extent is None:\n        msg = f\"Datacube {self.title} has no temporal dimension.\"\n        logger.error(msg)\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.create","title":"create","text":"<pre><code>create(overwrite: bool = False, exists_ok: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location and exists_ok is False.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def create(self, overwrite: bool = False, exists_ok: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube.\n            Has no effect if exists_ok is True. Defaults to False.\n        exists_ok (bool, optional): Do not raise an error if the datacube already exists.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location and exists_ok is False.\n\n    \"\"\"\n    if exists_ok and self.created:\n        logger.debug(\"Datacube was already created.\")\n        return\n\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Expand to temporal dimension if defined\n        if self.temporal_extent is not None:\n            ds = ds.expand_dims(time=self.temporal_extent)\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        if self.temporal_extent is not None:\n            coords_encoding[\"time\"] = {\"chunks\": ds.time.shape, **optimize_temporal_encoding(self.temporal_extent)}\n        chunks = (\n            (1, self.chunk_size, self.chunk_size)\n            if self.temporal_extent is not None\n            else (self.chunk_size, self.chunk_size)\n        )\n        var_encoding = {\n            name: {\n                \"chunks\": chunks,\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Has no effect if exists_ok is True. Defaults to False.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.create(exists_ok)","title":"<code>exists_ok</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Do not raise an error if the datacube already exists.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.\n\n    \"\"\"\n    import geopandas as gpd\n\n    if not self.created:\n        return None\n\n    loaded_patches = self.loaded_patches()\n\n    if len(loaded_patches) == 0:\n        return None\n\n    patch_infos = []\n    for pid in loaded_patches:\n        spatial_idx, temporal_idx = self._parse_index(pid)\n        geometry = self._extent_tiles[spatial_idx].extent.geom\n        if self.is_temporal:\n            time = self.temporal_extent[temporal_idx]\n            patch_infos.append({\"geometry\": geometry, \"id\": pid, \"time\": time})\n        else:\n            patch_infos.append({\"geometry\": geometry, \"id\": pid})\n\n    gdf = gpd.GeoDataFrame(patch_infos, crs=self.extent.crs.to_wkt())\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.download_patch","title":"download_patch","text":"<pre><code>download_patch(idx: PatchIndex[Item]) -&gt; xr.Dataset\n</code></pre> <p>Download the data for the given patch.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded patch data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def download_patch(self, idx: PatchIndex[Item]) -&gt; xr.Dataset:\n    \"\"\"Download the data for the given patch.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        idx (PatchIndex[Item]): The reference patch to download the data for.\n\n    Returns:\n        xr.Dataset: The downloaded patch data.\n\n    \"\"\"\n    import ee\n    import rioxarray  # noqa: F401\n    import xee  # noqa: F401\n\n    # Note: This is a little bit weird: First we create an own grid which overlaps to the chunks\n    # of the zarr array. Then we create a mosaic of the data and clip it to a single chunk.\n    # We could load the images from the collection directly instead of creating a mosaic.\n    # However, this would require more testing and probably results a lot of manual computation\n    # of slices etc. like in the stac variant. So for now, we just use the mosaic.\n    logging.getLogger(\"urllib3.connectionpool\").disabled = True\n\n    ee_col = ee.ImageCollection(self.collection)\n    if self.is_temporal:\n        ee_col = ee_col.filterDate(idx.item.time)\n    geom = ee.Geometry.Rectangle(idx.item.geobox.geographic_extent.boundingbox)\n    ee_img = ee_col.mosaic().clip(geom)\n\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=UserWarning, message=EE_WARN_MSG)\n        patch = xr.open_dataset(\n            ee_img,\n            engine=\"ee\",\n            geometry=geom,\n            crs=f\"epsg:{self.extent.crs.to_epsg()}\",\n            scale=self.extent.resolution.x,\n        )\n\n    # Do a mosaic if time axis are returned for non-temporal data\n    if \"time\" in patch.dims and not self.is_temporal:\n        patch = patch.max(\"time\")\n\n    patch = patch.rename({\"lon\": \"x\", \"lat\": \"y\"})\n    if \"time\" in patch.dims:\n        patch[\"time\"] = [idx.item.time]\n        patch = patch.transpose(\"time\", \"y\", \"x\")\n    else:\n        patch = patch.transpose(\"y\", \"x\")\n\n    # Download the data\n    logger.debug(f\"{idx.id=}: Trigger GEE download)\")\n    patch.load()\n    logger.debug(f\"{idx.id=}: Finished GEE download\")\n    logging.getLogger(\"urllib3.connectionpool\").disabled = False\n\n    # Flip y-axis, because convention is x in positive direction and y in negative, but gee use positive for both\n    patch = patch.isel(y=slice(None, None, -1))\n\n    # For some reason xee does not always set the crs\n    patch = patch.odc.assign_crs(self.extent.crs)\n\n    # Recrop the data to the tile, since gee does not always return the exact extent\n    patch = patch.odc.crop(idx.item.geobox.extent)\n\n    return patch\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.download_patch(idx)","title":"<code>idx</code>","text":"(<code>PatchIndex[Item]</code>)           \u2013            <p>The reference patch to download the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.load","title":"load","text":"<pre><code>load(\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load(\n    self,\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        aoi (Geometry | GeoBox): The reference geometry to load the data for. If a Geobox is provided,\n            it will use the extent of the geobox.\n        toi (TOI): The temporal slice to load. Defaults to None.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    if toi is not None:\n        self.assert_temporal_cube()\n\n    if isinstance(aoi, GeoBox):\n        aoi = aoi.extent\n\n    with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        aligned_aoi = aoi.to_crs(self.extent.crs)\n        with self.stopuhr(f\"{_geometry_repr(aoi)}: Procedural download in blocking mode\"):\n            self.procedural_download(aligned_aoi, toi)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get temporal slice if time is provided\n        if toi is not None:\n            xrcube = xrcube.sel(time=toi)\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(aligned_aoi, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.load(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry | GeoBox</code>)           \u2013            <p>The reference geometry to load the data for. If a Geobox is provided, it will use the extent of the geobox.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.load(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>, default:                   <code>None</code> )           \u2013            <p>The temporal slice to load. Defaults to None.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    toi = None\n    if \"time\" in ref.coords and self.temporal_extent is not None:\n        toi = ref.get_index(\"time\")\n    return self.load(ref.geobox, toi=toi, **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.loaded_patches","title":"loaded_patches","text":"<pre><code>loaded_patches() -&gt; list[str]\n</code></pre> <p>Get the ids of already (down-)loaded patches.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>list[str]: A list of already loaded patch ids.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def loaded_patches(self) -&gt; list[str]:\n    \"\"\"Get the ids of already (down-)loaded patches.\n\n    Returns:\n        list[str]: A list of already loaded patch ids.\n\n    \"\"\"\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube.attrs.get(\"loaded_patches\", []).copy()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    return self.backend.open_xarray()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    return self.backend.open_zarr()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Post create actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_create(self):\n    \"\"\"Post create actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.post_init","title":"post_init","text":"<pre><code>post_init()\n</code></pre> <p>Post init actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_init(self):\n    \"\"\"Post init actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(aoi: Geometry, toi: TOI)\n</code></pre> <p>Download tiles procedurally.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If not all downloads were successful.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def procedural_download(self, aoi: Geometry, toi: TOI):\n    \"\"\"Download tiles procedurally.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        aoi (Geometry): The geometry of the aoi to download.\n        toi (TOI): The time of interest to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If not all downloads were successful.\n\n    \"\"\"\n    adjacent_patches = self.adjacent_patches(aoi, toi)\n    # interest-string\n    soi = f\"{_geometry_repr(aoi)}\" + (f\" @ {_repr_toi(toi)}\" if toi is not None else \"\")\n    if not adjacent_patches:\n        logger.error(f\"{soi}: No adjacent patches found: {adjacent_patches=}\")\n        raise ValueError(\"No adjacent patches found - is the provided aoi and toi correct?\")\n\n    loaded_patches = self.loaded_patches()\n\n    new_patches = [patch for patch in adjacent_patches if patch.id not in loaded_patches]\n\n    logger.debug(f\"{soi}:  {len(adjacent_patches)=} &amp; {len(loaded_patches)=} -&gt; {len(new_patches)=} to download\")\n    if not new_patches:\n        return\n\n    # This raises Errors if anything goes wrong -&gt; we want to propagate\n    self.backend.submit(new_patches)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.procedural_download(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry</code>)           \u2013            <p>The geometry of the aoi to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.procedural_download(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/alphaearth.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    raise NotImplementedError(\"Visualization not implemented yet for AlphaEarth Embeddings datacube.\")\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.AlphaEarthEmbeddings.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m","title":"ArcticDEM10m","text":"<pre><code>ArcticDEM10m(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n)\n</code></pre> <p>               Bases: <code>ArcticDEMABC</code></p> <p>Accessor for ArcticDEM 10m data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the underlaying zarr array. Should be equal to the extent geobox. However, this property is used to find the target index of the downloaded data, so better save than sorry.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_patches</code>             \u2013              <p>Get adjacent patch indexes from a STAC API.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>assert_temporal_cube</code>             \u2013              <p>Assert that the datacube has a temporal dimension.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_patch</code>             \u2013              <p>Download the data for the given patch.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>loaded_patches</code>             \u2013              <p>Get the ids of already (down-)loaded patches.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> </li> <li> <code>post_init</code>             \u2013              <p>Check if the ArcticDEM mosaic extent info is already downloaded and downlaod if not.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download tiles procedurally.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n        backend (Literal[\"threaded\", \"simple\"], optional): The backend to use for downloading data.\n            Currently, only \"threaded\" is supported. Defaults to \"threaded\".\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = Chronometer(logger.debug)\n\n    if backend == \"threaded\":\n        if not _check_python_version(3, 13):\n            raise NotImplementedError(\n                \"The 'threaded' backend is only fully supported in Python 3.13 and above.\"\n                \" Please consider using the 'simple' backend in a multiprocessing environment\"\n                \" or upgrade your Python version.\"\n            )\n        self.backend = ThreadedBackend(self.repo, self.download_patch)\n    elif backend == \"simple\":\n        self.backend = SimpleBackend(self.repo, self.download_patch)\n    else:\n        raise ValueError(f\"Unknown backend {backend}\")\n\n    self.post_init()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m(backend)","title":"<code>backend</code>","text":"(<code>Literal['threaded', 'simple']</code>, default:                   <code>'threaded'</code> )           \u2013            <p>The backend to use for downloading data. Currently, only \"threaded\" is supported. Defaults to \"threaded\".</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre> <p>Check if the datacube already exists in the storage.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.is_temporal","title":"is_temporal  <code>property</code>","text":"<pre><code>is_temporal: bool\n</code></pre> <p>Check if the datacube has a temporal dimension.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube has a temporal dimension.</p> </li> </ul>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.adjacent_patches","title":"adjacent_patches","text":"<pre><code>adjacent_patches(\n    roi: Geometry | GeoBox | GeoDataFrame, toi: TOI\n) -&gt; list[PatchIndex]\n</code></pre> <p>Get adjacent patch indexes from a STAC API.</p> <p>Overwrite the default implementation from the STAC accessor to use pre-downloaded extent files instead of querying the STAC API. This results in a faster loading time, but requires the extent files to be downloaded beforehand. This is done in the post_create step.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[PatchIndex]</code>           \u2013            <p>list[PatchIndex]: List of adjacent patches, wrapped in own datastructure for easier processing.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the roi is not a GeoBox or a GeoDataFrame.</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def adjacent_patches(self, roi: Geometry | GeoBox | gpd.GeoDataFrame, toi: TOI) -&gt; list[PatchIndex]:\n    \"\"\"Get adjacent patch indexes from a STAC API.\n\n    Overwrite the default implementation from the STAC accessor\n    to use pre-downloaded extent files instead of querying the STAC API.\n    This results in a faster loading time, but requires the extent files to be downloaded beforehand.\n    This is done in the post_create step.\n\n    Args:\n        roi (Geometry | GeoBox | gpd.GeoDataFrame): The reference geometry, geobox or reference geodataframe\n        toi (TOI): The time of interest to download.\n            Not used in this implementation since ArcticDEM is not temporal.\n\n    Returns:\n        list[PatchIndex]: List of adjacent patches, wrapped in own datastructure for easier processing.\n\n    Raises:\n        ValueError: If the roi is not a GeoBox or a GeoDataFrame.\n\n    \"\"\"\n    # Assumes that the extent files are already present and the datacube is already created\n    self.assert_created()\n\n    resolution = f\"{int(self.extent.resolution.x)}m\"\n    extent_info = gpd.read_parquet(self._aux_dir / f\"ArcticDEM_Mosaic_Index_v4_1_{resolution}.parquet\")\n    if isinstance(roi, gpd.GeoDataFrame):\n        adjacent_tiles = (\n            gpd.sjoin(\n                extent_info,\n                roi[[\"geometry\"]].to_crs(self.extent.crs.wkt),\n                how=\"inner\",\n                predicate=\"intersects\",\n            )\n            .reset_index()\n            .drop_duplicates(subset=\"index\", keep=\"first\", ignore_index=True)\n        )\n    elif isinstance(roi, GeoBox):\n        adjacent_tiles = extent_info.loc[extent_info.intersects(roi.boundingbox.polygon.geom)].copy()\n    elif isinstance(roi, Geometry):\n        adjacent_tiles = extent_info.loc[extent_info.intersects(roi.geom)].copy()\n    else:\n        raise ValueError(\"roi must be a GeoBox or a GeoDataFrame\")\n    if adjacent_tiles.empty:\n        return []\n    return [\n        LazyStacPatchIndex(tile.dem_id, _get_stac_url(tile.dem_id, resolution))\n        for tile in adjacent_tiles.itertuples()\n    ]\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.adjacent_patches(roi)","title":"<code>roi</code>","text":"(<code>Geometry | GeoBox | GeoDataFrame</code>)           \u2013            <p>The reference geometry, geobox or reference geodataframe</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.adjacent_patches(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download. Not used in this implementation since ArcticDEM is not temporal.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\"\"\"\n    self.backend.assert_created()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.assert_temporal_cube","title":"assert_temporal_cube","text":"<pre><code>assert_temporal_cube()\n</code></pre> <p>Assert that the datacube has a temporal dimension.</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube has no temporal dimension.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_temporal_cube(self):\n    \"\"\"Assert that the datacube has a temporal dimension.\n\n    Raises:\n        ValueError: If the datacube has no temporal dimension.\n\n    \"\"\"\n    if self.temporal_extent is None:\n        msg = f\"Datacube {self.title} has no temporal dimension.\"\n        logger.error(msg)\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.create","title":"create","text":"<pre><code>create(overwrite: bool = False, exists_ok: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location and exists_ok is False.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def create(self, overwrite: bool = False, exists_ok: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube.\n            Has no effect if exists_ok is True. Defaults to False.\n        exists_ok (bool, optional): Do not raise an error if the datacube already exists.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location and exists_ok is False.\n\n    \"\"\"\n    if exists_ok and self.created:\n        logger.debug(\"Datacube was already created.\")\n        return\n\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Expand to temporal dimension if defined\n        if self.temporal_extent is not None:\n            ds = ds.expand_dims(time=self.temporal_extent)\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        if self.temporal_extent is not None:\n            coords_encoding[\"time\"] = {\"chunks\": ds.time.shape, **optimize_temporal_encoding(self.temporal_extent)}\n        chunks = (\n            (1, self.chunk_size, self.chunk_size)\n            if self.temporal_extent is not None\n            else (self.chunk_size, self.chunk_size)\n        )\n        var_encoding = {\n            name: {\n                \"chunks\": chunks,\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Has no effect if exists_ok is True. Defaults to False.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.create(exists_ok)","title":"<code>exists_ok</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Do not raise an error if the datacube already exists.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.\n\n    \"\"\"\n    import geopandas as gpd\n    import pystac_client\n\n    if not self.created:\n        return None\n\n    loaded_patches = self.loaded_patches()\n\n    if len(loaded_patches) == 0:\n        return None\n\n    catalog = pystac_client.Client.open(self.stac_api_url)\n    search = catalog.search(collections=[self.collection], ids=loaded_patches)\n    stac_json = search.item_collection_as_dict()\n\n    gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.download_patch","title":"download_patch","text":"<pre><code>download_patch(idx: PatchIndex[Item]) -&gt; xr.Dataset\n</code></pre> <p>Download the data for the given patch.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded patch data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def download_patch(self, idx: PatchIndex[\"Item\"]) -&gt; xr.Dataset:\n    \"\"\"Download the data for the given patch.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        idx (PatchIndex[Item]): The reference patch to download the data for.\n\n    Returns:\n        xr.Dataset: The downloaded patch data.\n\n    \"\"\"\n    from odc.stac import stac_load\n\n    patch = stac_load([idx.item], bands=self.channels, chunks=None, progress=None)\n\n    # Do a mosaic if multiple items are returned for non-temporal data\n    if \"time\" in patch.dims and self.temporal_extent is None:\n        patch = patch.max(\"time\")\n\n    return patch\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.download_patch(idx)","title":"<code>idx</code>","text":"(<code>PatchIndex[Item]</code>)           \u2013            <p>The reference patch to download the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.load","title":"load","text":"<pre><code>load(\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load(\n    self,\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        aoi (Geometry | GeoBox): The reference geometry to load the data for. If a Geobox is provided,\n            it will use the extent of the geobox.\n        toi (TOI): The temporal slice to load. Defaults to None.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    if toi is not None:\n        self.assert_temporal_cube()\n\n    if isinstance(aoi, GeoBox):\n        aoi = aoi.extent\n\n    with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        aligned_aoi = aoi.to_crs(self.extent.crs)\n        with self.stopuhr(f\"{_geometry_repr(aoi)}: Procedural download in blocking mode\"):\n            self.procedural_download(aligned_aoi, toi)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get temporal slice if time is provided\n        if toi is not None:\n            xrcube = xrcube.sel(time=toi)\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(aligned_aoi, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.load(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry | GeoBox</code>)           \u2013            <p>The reference geometry to load the data for. If a Geobox is provided, it will use the extent of the geobox.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.load(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>, default:                   <code>None</code> )           \u2013            <p>The temporal slice to load. Defaults to None.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    toi = None\n    if \"time\" in ref.coords and self.temporal_extent is not None:\n        toi = ref.get_index(\"time\")\n    return self.load(ref.geobox, toi=toi, **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.loaded_patches","title":"loaded_patches","text":"<pre><code>loaded_patches() -&gt; list[str]\n</code></pre> <p>Get the ids of already (down-)loaded patches.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>list[str]: A list of already loaded patch ids.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def loaded_patches(self) -&gt; list[str]:\n    \"\"\"Get the ids of already (down-)loaded patches.\n\n    Returns:\n        list[str]: A list of already loaded patch ids.\n\n    \"\"\"\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube.attrs.get(\"loaded_patches\", []).copy()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    return self.backend.open_xarray()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    return self.backend.open_zarr()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def post_create(self):\n    \"\"\"Download the ArcticDEM mosaic extent info and store it in the datacube.\"\"\"\n    _download_arcticdem_extent(self._aux_dir)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.post_init","title":"post_init","text":"<pre><code>post_init()\n</code></pre> <p>Check if the ArcticDEM mosaic extent info is already downloaded and downlaod if not.</p> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def post_init(self):\n    \"\"\"Check if the ArcticDEM mosaic extent info is already downloaded and downlaod if not.\"\"\"\n    required_files = [self._aux_dir / f\"ArcticDEM_Mosaic_Index_v4_1_{res}.parquet\" for res in [\"2m\", \"10m\", \"32m\"]]\n    if not all(file.exists() for file in required_files):\n        _download_arcticdem_extent(self._aux_dir)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(aoi: Geometry, toi: TOI)\n</code></pre> <p>Download tiles procedurally.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If not all downloads were successful.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def procedural_download(self, aoi: Geometry, toi: TOI):\n    \"\"\"Download tiles procedurally.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        aoi (Geometry): The geometry of the aoi to download.\n        toi (TOI): The time of interest to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If not all downloads were successful.\n\n    \"\"\"\n    adjacent_patches = self.adjacent_patches(aoi, toi)\n    # interest-string\n    soi = f\"{_geometry_repr(aoi)}\" + (f\" @ {_repr_toi(toi)}\" if toi is not None else \"\")\n    if not adjacent_patches:\n        logger.error(f\"{soi}: No adjacent patches found: {adjacent_patches=}\")\n        raise ValueError(\"No adjacent patches found - is the provided aoi and toi correct?\")\n\n    loaded_patches = self.loaded_patches()\n\n    new_patches = [patch for patch in adjacent_patches if patch.id not in loaded_patches]\n\n    logger.debug(f\"{soi}:  {len(adjacent_patches)=} &amp; {len(loaded_patches)=} -&gt; {len(new_patches)=} to download\")\n    if not new_patches:\n        return\n\n    # This raises Errors if anything goes wrong -&gt; we want to propagate\n    self.backend.submit(new_patches)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.procedural_download(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry</code>)           \u2013            <p>The geometry of the aoi to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.procedural_download(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    import cartopy.crs as ccrs\n    import cartopy.feature as cfeature\n    import matplotlib.path as mpath\n    import matplotlib.pyplot as plt\n\n    tile_info = self.current_state()\n\n    if tile_info is None:\n        raise ValueError(\"Datacube is not created or loaded yet. Can't visualize!\")\n\n    # Define the projection\n    projection = ccrs.Stereographic(central_latitude=90, central_longitude=-45, true_scale_latitude=70)\n\n    # Create a figure\n    fig = None\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": projection})\n\n    # Set the extent to focus on the North Pole\n    ax.set_extent([-180, 180, 50, 90], crs=ccrs.PlateCarree())\n\n    # Add features\n    ax.add_feature(cfeature.LAND, zorder=0, edgecolor=\"black\", facecolor=\"white\")\n    ax.add_feature(cfeature.OCEAN, zorder=0, facecolor=\"lightgrey\")\n    ax.add_feature(cfeature.COASTLINE)\n    ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n    ax.add_feature(cfeature.LAKES, alpha=0.5)\n    ax.add_feature(cfeature.RIVERS)\n\n    # Add gridlines\n    gl = ax.gridlines(draw_labels=True)\n    gl.top_labels = False\n    gl.right_labels = False\n\n    # Compute a circle in axes coordinates, which we can use as a boundary\n    # for the map. We can pan/zoom as much as we like - the boundary will be\n    # permanently circular.\n    theta = np.linspace(0, 2 * np.pi, 100)\n    center, radius = [0.5, 0.5], 0.5\n    verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n    circle = mpath.Path(verts * radius + center)\n\n    ax.set_boundary(circle, transform=ax.transAxes)\n\n    tile_info.plot(\n        \"title\",\n        ax=ax,\n        transform=ccrs.PlateCarree(),\n        edgecolor=\"black\",\n        categorical=True,\n        aspect=\"equal\",\n        alpha=0.5,\n    )\n\n    if fig is not None:\n        return fig\n    else:\n        return ax\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m","title":"ArcticDEM2m","text":"<pre><code>ArcticDEM2m(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n)\n</code></pre> <p>               Bases: <code>ArcticDEMABC</code></p> <p>Accessor for ArcticDEM 2m data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the underlaying zarr array. Should be equal to the extent geobox. However, this property is used to find the target index of the downloaded data, so better save than sorry.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_patches</code>             \u2013              <p>Get adjacent patch indexes from a STAC API.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>assert_temporal_cube</code>             \u2013              <p>Assert that the datacube has a temporal dimension.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_patch</code>             \u2013              <p>Download the data for the given patch.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>loaded_patches</code>             \u2013              <p>Get the ids of already (down-)loaded patches.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> </li> <li> <code>post_init</code>             \u2013              <p>Check if the ArcticDEM mosaic extent info is already downloaded and downlaod if not.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download tiles procedurally.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n        backend (Literal[\"threaded\", \"simple\"], optional): The backend to use for downloading data.\n            Currently, only \"threaded\" is supported. Defaults to \"threaded\".\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = Chronometer(logger.debug)\n\n    if backend == \"threaded\":\n        if not _check_python_version(3, 13):\n            raise NotImplementedError(\n                \"The 'threaded' backend is only fully supported in Python 3.13 and above.\"\n                \" Please consider using the 'simple' backend in a multiprocessing environment\"\n                \" or upgrade your Python version.\"\n            )\n        self.backend = ThreadedBackend(self.repo, self.download_patch)\n    elif backend == \"simple\":\n        self.backend = SimpleBackend(self.repo, self.download_patch)\n    else:\n        raise ValueError(f\"Unknown backend {backend}\")\n\n    self.post_init()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m(backend)","title":"<code>backend</code>","text":"(<code>Literal['threaded', 'simple']</code>, default:                   <code>'threaded'</code> )           \u2013            <p>The backend to use for downloading data. Currently, only \"threaded\" is supported. Defaults to \"threaded\".</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre> <p>Check if the datacube already exists in the storage.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.is_temporal","title":"is_temporal  <code>property</code>","text":"<pre><code>is_temporal: bool\n</code></pre> <p>Check if the datacube has a temporal dimension.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube has a temporal dimension.</p> </li> </ul>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.adjacent_patches","title":"adjacent_patches","text":"<pre><code>adjacent_patches(\n    roi: Geometry | GeoBox | GeoDataFrame, toi: TOI\n) -&gt; list[PatchIndex]\n</code></pre> <p>Get adjacent patch indexes from a STAC API.</p> <p>Overwrite the default implementation from the STAC accessor to use pre-downloaded extent files instead of querying the STAC API. This results in a faster loading time, but requires the extent files to be downloaded beforehand. This is done in the post_create step.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[PatchIndex]</code>           \u2013            <p>list[PatchIndex]: List of adjacent patches, wrapped in own datastructure for easier processing.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the roi is not a GeoBox or a GeoDataFrame.</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def adjacent_patches(self, roi: Geometry | GeoBox | gpd.GeoDataFrame, toi: TOI) -&gt; list[PatchIndex]:\n    \"\"\"Get adjacent patch indexes from a STAC API.\n\n    Overwrite the default implementation from the STAC accessor\n    to use pre-downloaded extent files instead of querying the STAC API.\n    This results in a faster loading time, but requires the extent files to be downloaded beforehand.\n    This is done in the post_create step.\n\n    Args:\n        roi (Geometry | GeoBox | gpd.GeoDataFrame): The reference geometry, geobox or reference geodataframe\n        toi (TOI): The time of interest to download.\n            Not used in this implementation since ArcticDEM is not temporal.\n\n    Returns:\n        list[PatchIndex]: List of adjacent patches, wrapped in own datastructure for easier processing.\n\n    Raises:\n        ValueError: If the roi is not a GeoBox or a GeoDataFrame.\n\n    \"\"\"\n    # Assumes that the extent files are already present and the datacube is already created\n    self.assert_created()\n\n    resolution = f\"{int(self.extent.resolution.x)}m\"\n    extent_info = gpd.read_parquet(self._aux_dir / f\"ArcticDEM_Mosaic_Index_v4_1_{resolution}.parquet\")\n    if isinstance(roi, gpd.GeoDataFrame):\n        adjacent_tiles = (\n            gpd.sjoin(\n                extent_info,\n                roi[[\"geometry\"]].to_crs(self.extent.crs.wkt),\n                how=\"inner\",\n                predicate=\"intersects\",\n            )\n            .reset_index()\n            .drop_duplicates(subset=\"index\", keep=\"first\", ignore_index=True)\n        )\n    elif isinstance(roi, GeoBox):\n        adjacent_tiles = extent_info.loc[extent_info.intersects(roi.boundingbox.polygon.geom)].copy()\n    elif isinstance(roi, Geometry):\n        adjacent_tiles = extent_info.loc[extent_info.intersects(roi.geom)].copy()\n    else:\n        raise ValueError(\"roi must be a GeoBox or a GeoDataFrame\")\n    if adjacent_tiles.empty:\n        return []\n    return [\n        LazyStacPatchIndex(tile.dem_id, _get_stac_url(tile.dem_id, resolution))\n        for tile in adjacent_tiles.itertuples()\n    ]\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.adjacent_patches(roi)","title":"<code>roi</code>","text":"(<code>Geometry | GeoBox | GeoDataFrame</code>)           \u2013            <p>The reference geometry, geobox or reference geodataframe</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.adjacent_patches(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download. Not used in this implementation since ArcticDEM is not temporal.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\"\"\"\n    self.backend.assert_created()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.assert_temporal_cube","title":"assert_temporal_cube","text":"<pre><code>assert_temporal_cube()\n</code></pre> <p>Assert that the datacube has a temporal dimension.</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube has no temporal dimension.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_temporal_cube(self):\n    \"\"\"Assert that the datacube has a temporal dimension.\n\n    Raises:\n        ValueError: If the datacube has no temporal dimension.\n\n    \"\"\"\n    if self.temporal_extent is None:\n        msg = f\"Datacube {self.title} has no temporal dimension.\"\n        logger.error(msg)\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.create","title":"create","text":"<pre><code>create(overwrite: bool = False, exists_ok: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location and exists_ok is False.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def create(self, overwrite: bool = False, exists_ok: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube.\n            Has no effect if exists_ok is True. Defaults to False.\n        exists_ok (bool, optional): Do not raise an error if the datacube already exists.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location and exists_ok is False.\n\n    \"\"\"\n    if exists_ok and self.created:\n        logger.debug(\"Datacube was already created.\")\n        return\n\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Expand to temporal dimension if defined\n        if self.temporal_extent is not None:\n            ds = ds.expand_dims(time=self.temporal_extent)\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        if self.temporal_extent is not None:\n            coords_encoding[\"time\"] = {\"chunks\": ds.time.shape, **optimize_temporal_encoding(self.temporal_extent)}\n        chunks = (\n            (1, self.chunk_size, self.chunk_size)\n            if self.temporal_extent is not None\n            else (self.chunk_size, self.chunk_size)\n        )\n        var_encoding = {\n            name: {\n                \"chunks\": chunks,\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Has no effect if exists_ok is True. Defaults to False.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.create(exists_ok)","title":"<code>exists_ok</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Do not raise an error if the datacube already exists.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.\n\n    \"\"\"\n    import geopandas as gpd\n    import pystac_client\n\n    if not self.created:\n        return None\n\n    loaded_patches = self.loaded_patches()\n\n    if len(loaded_patches) == 0:\n        return None\n\n    catalog = pystac_client.Client.open(self.stac_api_url)\n    search = catalog.search(collections=[self.collection], ids=loaded_patches)\n    stac_json = search.item_collection_as_dict()\n\n    gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.download_patch","title":"download_patch","text":"<pre><code>download_patch(idx: PatchIndex[Item]) -&gt; xr.Dataset\n</code></pre> <p>Download the data for the given patch.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded patch data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def download_patch(self, idx: PatchIndex[\"Item\"]) -&gt; xr.Dataset:\n    \"\"\"Download the data for the given patch.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        idx (PatchIndex[Item]): The reference patch to download the data for.\n\n    Returns:\n        xr.Dataset: The downloaded patch data.\n\n    \"\"\"\n    from odc.stac import stac_load\n\n    patch = stac_load([idx.item], bands=self.channels, chunks=None, progress=None)\n\n    # Do a mosaic if multiple items are returned for non-temporal data\n    if \"time\" in patch.dims and self.temporal_extent is None:\n        patch = patch.max(\"time\")\n\n    return patch\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.download_patch(idx)","title":"<code>idx</code>","text":"(<code>PatchIndex[Item]</code>)           \u2013            <p>The reference patch to download the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.load","title":"load","text":"<pre><code>load(\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load(\n    self,\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        aoi (Geometry | GeoBox): The reference geometry to load the data for. If a Geobox is provided,\n            it will use the extent of the geobox.\n        toi (TOI): The temporal slice to load. Defaults to None.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    if toi is not None:\n        self.assert_temporal_cube()\n\n    if isinstance(aoi, GeoBox):\n        aoi = aoi.extent\n\n    with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        aligned_aoi = aoi.to_crs(self.extent.crs)\n        with self.stopuhr(f\"{_geometry_repr(aoi)}: Procedural download in blocking mode\"):\n            self.procedural_download(aligned_aoi, toi)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get temporal slice if time is provided\n        if toi is not None:\n            xrcube = xrcube.sel(time=toi)\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(aligned_aoi, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.load(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry | GeoBox</code>)           \u2013            <p>The reference geometry to load the data for. If a Geobox is provided, it will use the extent of the geobox.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.load(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>, default:                   <code>None</code> )           \u2013            <p>The temporal slice to load. Defaults to None.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    toi = None\n    if \"time\" in ref.coords and self.temporal_extent is not None:\n        toi = ref.get_index(\"time\")\n    return self.load(ref.geobox, toi=toi, **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.loaded_patches","title":"loaded_patches","text":"<pre><code>loaded_patches() -&gt; list[str]\n</code></pre> <p>Get the ids of already (down-)loaded patches.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>list[str]: A list of already loaded patch ids.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def loaded_patches(self) -&gt; list[str]:\n    \"\"\"Get the ids of already (down-)loaded patches.\n\n    Returns:\n        list[str]: A list of already loaded patch ids.\n\n    \"\"\"\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube.attrs.get(\"loaded_patches\", []).copy()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    return self.backend.open_xarray()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    return self.backend.open_zarr()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def post_create(self):\n    \"\"\"Download the ArcticDEM mosaic extent info and store it in the datacube.\"\"\"\n    _download_arcticdem_extent(self._aux_dir)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.post_init","title":"post_init","text":"<pre><code>post_init()\n</code></pre> <p>Check if the ArcticDEM mosaic extent info is already downloaded and downlaod if not.</p> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def post_init(self):\n    \"\"\"Check if the ArcticDEM mosaic extent info is already downloaded and downlaod if not.\"\"\"\n    required_files = [self._aux_dir / f\"ArcticDEM_Mosaic_Index_v4_1_{res}.parquet\" for res in [\"2m\", \"10m\", \"32m\"]]\n    if not all(file.exists() for file in required_files):\n        _download_arcticdem_extent(self._aux_dir)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(aoi: Geometry, toi: TOI)\n</code></pre> <p>Download tiles procedurally.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If not all downloads were successful.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def procedural_download(self, aoi: Geometry, toi: TOI):\n    \"\"\"Download tiles procedurally.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        aoi (Geometry): The geometry of the aoi to download.\n        toi (TOI): The time of interest to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If not all downloads were successful.\n\n    \"\"\"\n    adjacent_patches = self.adjacent_patches(aoi, toi)\n    # interest-string\n    soi = f\"{_geometry_repr(aoi)}\" + (f\" @ {_repr_toi(toi)}\" if toi is not None else \"\")\n    if not adjacent_patches:\n        logger.error(f\"{soi}: No adjacent patches found: {adjacent_patches=}\")\n        raise ValueError(\"No adjacent patches found - is the provided aoi and toi correct?\")\n\n    loaded_patches = self.loaded_patches()\n\n    new_patches = [patch for patch in adjacent_patches if patch.id not in loaded_patches]\n\n    logger.debug(f\"{soi}:  {len(adjacent_patches)=} &amp; {len(loaded_patches)=} -&gt; {len(new_patches)=} to download\")\n    if not new_patches:\n        return\n\n    # This raises Errors if anything goes wrong -&gt; we want to propagate\n    self.backend.submit(new_patches)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.procedural_download(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry</code>)           \u2013            <p>The geometry of the aoi to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.procedural_download(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    import cartopy.crs as ccrs\n    import cartopy.feature as cfeature\n    import matplotlib.path as mpath\n    import matplotlib.pyplot as plt\n\n    tile_info = self.current_state()\n\n    if tile_info is None:\n        raise ValueError(\"Datacube is not created or loaded yet. Can't visualize!\")\n\n    # Define the projection\n    projection = ccrs.Stereographic(central_latitude=90, central_longitude=-45, true_scale_latitude=70)\n\n    # Create a figure\n    fig = None\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": projection})\n\n    # Set the extent to focus on the North Pole\n    ax.set_extent([-180, 180, 50, 90], crs=ccrs.PlateCarree())\n\n    # Add features\n    ax.add_feature(cfeature.LAND, zorder=0, edgecolor=\"black\", facecolor=\"white\")\n    ax.add_feature(cfeature.OCEAN, zorder=0, facecolor=\"lightgrey\")\n    ax.add_feature(cfeature.COASTLINE)\n    ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n    ax.add_feature(cfeature.LAKES, alpha=0.5)\n    ax.add_feature(cfeature.RIVERS)\n\n    # Add gridlines\n    gl = ax.gridlines(draw_labels=True)\n    gl.top_labels = False\n    gl.right_labels = False\n\n    # Compute a circle in axes coordinates, which we can use as a boundary\n    # for the map. We can pan/zoom as much as we like - the boundary will be\n    # permanently circular.\n    theta = np.linspace(0, 2 * np.pi, 100)\n    center, radius = [0.5, 0.5], 0.5\n    verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n    circle = mpath.Path(verts * radius + center)\n\n    ax.set_boundary(circle, transform=ax.transAxes)\n\n    tile_info.plot(\n        \"title\",\n        ax=ax,\n        transform=ccrs.PlateCarree(),\n        edgecolor=\"black\",\n        categorical=True,\n        aspect=\"equal\",\n        alpha=0.5,\n    )\n\n    if fig is not None:\n        return fig\n    else:\n        return ax\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m","title":"ArcticDEM32m","text":"<pre><code>ArcticDEM32m(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n)\n</code></pre> <p>               Bases: <code>ArcticDEMABC</code></p> <p>Accessor for ArcticDEM 32m data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the underlaying zarr array. Should be equal to the extent geobox. However, this property is used to find the target index of the downloaded data, so better save than sorry.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_patches</code>             \u2013              <p>Get adjacent patch indexes from a STAC API.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>assert_temporal_cube</code>             \u2013              <p>Assert that the datacube has a temporal dimension.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_patch</code>             \u2013              <p>Download the data for the given patch.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>loaded_patches</code>             \u2013              <p>Get the ids of already (down-)loaded patches.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> </li> <li> <code>post_init</code>             \u2013              <p>Check if the ArcticDEM mosaic extent info is already downloaded and downlaod if not.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download tiles procedurally.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n        backend (Literal[\"threaded\", \"simple\"], optional): The backend to use for downloading data.\n            Currently, only \"threaded\" is supported. Defaults to \"threaded\".\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = Chronometer(logger.debug)\n\n    if backend == \"threaded\":\n        if not _check_python_version(3, 13):\n            raise NotImplementedError(\n                \"The 'threaded' backend is only fully supported in Python 3.13 and above.\"\n                \" Please consider using the 'simple' backend in a multiprocessing environment\"\n                \" or upgrade your Python version.\"\n            )\n        self.backend = ThreadedBackend(self.repo, self.download_patch)\n    elif backend == \"simple\":\n        self.backend = SimpleBackend(self.repo, self.download_patch)\n    else:\n        raise ValueError(f\"Unknown backend {backend}\")\n\n    self.post_init()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m(backend)","title":"<code>backend</code>","text":"(<code>Literal['threaded', 'simple']</code>, default:                   <code>'threaded'</code> )           \u2013            <p>The backend to use for downloading data. Currently, only \"threaded\" is supported. Defaults to \"threaded\".</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre> <p>Check if the datacube already exists in the storage.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.is_temporal","title":"is_temporal  <code>property</code>","text":"<pre><code>is_temporal: bool\n</code></pre> <p>Check if the datacube has a temporal dimension.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube has a temporal dimension.</p> </li> </ul>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.adjacent_patches","title":"adjacent_patches","text":"<pre><code>adjacent_patches(\n    roi: Geometry | GeoBox | GeoDataFrame, toi: TOI\n) -&gt; list[PatchIndex]\n</code></pre> <p>Get adjacent patch indexes from a STAC API.</p> <p>Overwrite the default implementation from the STAC accessor to use pre-downloaded extent files instead of querying the STAC API. This results in a faster loading time, but requires the extent files to be downloaded beforehand. This is done in the post_create step.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[PatchIndex]</code>           \u2013            <p>list[PatchIndex]: List of adjacent patches, wrapped in own datastructure for easier processing.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the roi is not a GeoBox or a GeoDataFrame.</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def adjacent_patches(self, roi: Geometry | GeoBox | gpd.GeoDataFrame, toi: TOI) -&gt; list[PatchIndex]:\n    \"\"\"Get adjacent patch indexes from a STAC API.\n\n    Overwrite the default implementation from the STAC accessor\n    to use pre-downloaded extent files instead of querying the STAC API.\n    This results in a faster loading time, but requires the extent files to be downloaded beforehand.\n    This is done in the post_create step.\n\n    Args:\n        roi (Geometry | GeoBox | gpd.GeoDataFrame): The reference geometry, geobox or reference geodataframe\n        toi (TOI): The time of interest to download.\n            Not used in this implementation since ArcticDEM is not temporal.\n\n    Returns:\n        list[PatchIndex]: List of adjacent patches, wrapped in own datastructure for easier processing.\n\n    Raises:\n        ValueError: If the roi is not a GeoBox or a GeoDataFrame.\n\n    \"\"\"\n    # Assumes that the extent files are already present and the datacube is already created\n    self.assert_created()\n\n    resolution = f\"{int(self.extent.resolution.x)}m\"\n    extent_info = gpd.read_parquet(self._aux_dir / f\"ArcticDEM_Mosaic_Index_v4_1_{resolution}.parquet\")\n    if isinstance(roi, gpd.GeoDataFrame):\n        adjacent_tiles = (\n            gpd.sjoin(\n                extent_info,\n                roi[[\"geometry\"]].to_crs(self.extent.crs.wkt),\n                how=\"inner\",\n                predicate=\"intersects\",\n            )\n            .reset_index()\n            .drop_duplicates(subset=\"index\", keep=\"first\", ignore_index=True)\n        )\n    elif isinstance(roi, GeoBox):\n        adjacent_tiles = extent_info.loc[extent_info.intersects(roi.boundingbox.polygon.geom)].copy()\n    elif isinstance(roi, Geometry):\n        adjacent_tiles = extent_info.loc[extent_info.intersects(roi.geom)].copy()\n    else:\n        raise ValueError(\"roi must be a GeoBox or a GeoDataFrame\")\n    if adjacent_tiles.empty:\n        return []\n    return [\n        LazyStacPatchIndex(tile.dem_id, _get_stac_url(tile.dem_id, resolution))\n        for tile in adjacent_tiles.itertuples()\n    ]\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.adjacent_patches(roi)","title":"<code>roi</code>","text":"(<code>Geometry | GeoBox | GeoDataFrame</code>)           \u2013            <p>The reference geometry, geobox or reference geodataframe</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.adjacent_patches(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download. Not used in this implementation since ArcticDEM is not temporal.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\"\"\"\n    self.backend.assert_created()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.assert_temporal_cube","title":"assert_temporal_cube","text":"<pre><code>assert_temporal_cube()\n</code></pre> <p>Assert that the datacube has a temporal dimension.</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube has no temporal dimension.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_temporal_cube(self):\n    \"\"\"Assert that the datacube has a temporal dimension.\n\n    Raises:\n        ValueError: If the datacube has no temporal dimension.\n\n    \"\"\"\n    if self.temporal_extent is None:\n        msg = f\"Datacube {self.title} has no temporal dimension.\"\n        logger.error(msg)\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.create","title":"create","text":"<pre><code>create(overwrite: bool = False, exists_ok: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location and exists_ok is False.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def create(self, overwrite: bool = False, exists_ok: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube.\n            Has no effect if exists_ok is True. Defaults to False.\n        exists_ok (bool, optional): Do not raise an error if the datacube already exists.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location and exists_ok is False.\n\n    \"\"\"\n    if exists_ok and self.created:\n        logger.debug(\"Datacube was already created.\")\n        return\n\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Expand to temporal dimension if defined\n        if self.temporal_extent is not None:\n            ds = ds.expand_dims(time=self.temporal_extent)\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        if self.temporal_extent is not None:\n            coords_encoding[\"time\"] = {\"chunks\": ds.time.shape, **optimize_temporal_encoding(self.temporal_extent)}\n        chunks = (\n            (1, self.chunk_size, self.chunk_size)\n            if self.temporal_extent is not None\n            else (self.chunk_size, self.chunk_size)\n        )\n        var_encoding = {\n            name: {\n                \"chunks\": chunks,\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Has no effect if exists_ok is True. Defaults to False.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.create(exists_ok)","title":"<code>exists_ok</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Do not raise an error if the datacube already exists.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.\n\n    \"\"\"\n    import geopandas as gpd\n    import pystac_client\n\n    if not self.created:\n        return None\n\n    loaded_patches = self.loaded_patches()\n\n    if len(loaded_patches) == 0:\n        return None\n\n    catalog = pystac_client.Client.open(self.stac_api_url)\n    search = catalog.search(collections=[self.collection], ids=loaded_patches)\n    stac_json = search.item_collection_as_dict()\n\n    gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.download_patch","title":"download_patch","text":"<pre><code>download_patch(idx: PatchIndex[Item]) -&gt; xr.Dataset\n</code></pre> <p>Download the data for the given patch.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded patch data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def download_patch(self, idx: PatchIndex[\"Item\"]) -&gt; xr.Dataset:\n    \"\"\"Download the data for the given patch.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        idx (PatchIndex[Item]): The reference patch to download the data for.\n\n    Returns:\n        xr.Dataset: The downloaded patch data.\n\n    \"\"\"\n    from odc.stac import stac_load\n\n    patch = stac_load([idx.item], bands=self.channels, chunks=None, progress=None)\n\n    # Do a mosaic if multiple items are returned for non-temporal data\n    if \"time\" in patch.dims and self.temporal_extent is None:\n        patch = patch.max(\"time\")\n\n    return patch\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.download_patch(idx)","title":"<code>idx</code>","text":"(<code>PatchIndex[Item]</code>)           \u2013            <p>The reference patch to download the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.load","title":"load","text":"<pre><code>load(\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load(\n    self,\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        aoi (Geometry | GeoBox): The reference geometry to load the data for. If a Geobox is provided,\n            it will use the extent of the geobox.\n        toi (TOI): The temporal slice to load. Defaults to None.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    if toi is not None:\n        self.assert_temporal_cube()\n\n    if isinstance(aoi, GeoBox):\n        aoi = aoi.extent\n\n    with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        aligned_aoi = aoi.to_crs(self.extent.crs)\n        with self.stopuhr(f\"{_geometry_repr(aoi)}: Procedural download in blocking mode\"):\n            self.procedural_download(aligned_aoi, toi)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get temporal slice if time is provided\n        if toi is not None:\n            xrcube = xrcube.sel(time=toi)\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(aligned_aoi, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.load(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry | GeoBox</code>)           \u2013            <p>The reference geometry to load the data for. If a Geobox is provided, it will use the extent of the geobox.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.load(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>, default:                   <code>None</code> )           \u2013            <p>The temporal slice to load. Defaults to None.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    toi = None\n    if \"time\" in ref.coords and self.temporal_extent is not None:\n        toi = ref.get_index(\"time\")\n    return self.load(ref.geobox, toi=toi, **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.loaded_patches","title":"loaded_patches","text":"<pre><code>loaded_patches() -&gt; list[str]\n</code></pre> <p>Get the ids of already (down-)loaded patches.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>list[str]: A list of already loaded patch ids.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def loaded_patches(self) -&gt; list[str]:\n    \"\"\"Get the ids of already (down-)loaded patches.\n\n    Returns:\n        list[str]: A list of already loaded patch ids.\n\n    \"\"\"\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube.attrs.get(\"loaded_patches\", []).copy()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    return self.backend.open_xarray()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    return self.backend.open_zarr()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def post_create(self):\n    \"\"\"Download the ArcticDEM mosaic extent info and store it in the datacube.\"\"\"\n    _download_arcticdem_extent(self._aux_dir)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.post_init","title":"post_init","text":"<pre><code>post_init()\n</code></pre> <p>Check if the ArcticDEM mosaic extent info is already downloaded and downlaod if not.</p> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def post_init(self):\n    \"\"\"Check if the ArcticDEM mosaic extent info is already downloaded and downlaod if not.\"\"\"\n    required_files = [self._aux_dir / f\"ArcticDEM_Mosaic_Index_v4_1_{res}.parquet\" for res in [\"2m\", \"10m\", \"32m\"]]\n    if not all(file.exists() for file in required_files):\n        _download_arcticdem_extent(self._aux_dir)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(aoi: Geometry, toi: TOI)\n</code></pre> <p>Download tiles procedurally.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If not all downloads were successful.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def procedural_download(self, aoi: Geometry, toi: TOI):\n    \"\"\"Download tiles procedurally.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        aoi (Geometry): The geometry of the aoi to download.\n        toi (TOI): The time of interest to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If not all downloads were successful.\n\n    \"\"\"\n    adjacent_patches = self.adjacent_patches(aoi, toi)\n    # interest-string\n    soi = f\"{_geometry_repr(aoi)}\" + (f\" @ {_repr_toi(toi)}\" if toi is not None else \"\")\n    if not adjacent_patches:\n        logger.error(f\"{soi}: No adjacent patches found: {adjacent_patches=}\")\n        raise ValueError(\"No adjacent patches found - is the provided aoi and toi correct?\")\n\n    loaded_patches = self.loaded_patches()\n\n    new_patches = [patch for patch in adjacent_patches if patch.id not in loaded_patches]\n\n    logger.debug(f\"{soi}:  {len(adjacent_patches)=} &amp; {len(loaded_patches)=} -&gt; {len(new_patches)=} to download\")\n    if not new_patches:\n        return\n\n    # This raises Errors if anything goes wrong -&gt; we want to propagate\n    self.backend.submit(new_patches)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.procedural_download(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry</code>)           \u2013            <p>The geometry of the aoi to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.procedural_download(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    import cartopy.crs as ccrs\n    import cartopy.feature as cfeature\n    import matplotlib.path as mpath\n    import matplotlib.pyplot as plt\n\n    tile_info = self.current_state()\n\n    if tile_info is None:\n        raise ValueError(\"Datacube is not created or loaded yet. Can't visualize!\")\n\n    # Define the projection\n    projection = ccrs.Stereographic(central_latitude=90, central_longitude=-45, true_scale_latitude=70)\n\n    # Create a figure\n    fig = None\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": projection})\n\n    # Set the extent to focus on the North Pole\n    ax.set_extent([-180, 180, 50, 90], crs=ccrs.PlateCarree())\n\n    # Add features\n    ax.add_feature(cfeature.LAND, zorder=0, edgecolor=\"black\", facecolor=\"white\")\n    ax.add_feature(cfeature.OCEAN, zorder=0, facecolor=\"lightgrey\")\n    ax.add_feature(cfeature.COASTLINE)\n    ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n    ax.add_feature(cfeature.LAKES, alpha=0.5)\n    ax.add_feature(cfeature.RIVERS)\n\n    # Add gridlines\n    gl = ax.gridlines(draw_labels=True)\n    gl.top_labels = False\n    gl.right_labels = False\n\n    # Compute a circle in axes coordinates, which we can use as a boundary\n    # for the map. We can pan/zoom as much as we like - the boundary will be\n    # permanently circular.\n    theta = np.linspace(0, 2 * np.pi, 100)\n    center, radius = [0.5, 0.5], 0.5\n    verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n    circle = mpath.Path(verts * radius + center)\n\n    ax.set_boundary(circle, transform=ax.transAxes)\n\n    tile_info.plot(\n        \"title\",\n        ax=ax,\n        transform=ccrs.PlateCarree(),\n        edgecolor=\"black\",\n        categorical=True,\n        aspect=\"equal\",\n        alpha=0.5,\n    )\n\n    if fig is not None:\n        return fig\n    else:\n        return ax\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019","title":"TCTrend2019","text":"<pre><code>TCTrend2019(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n)\n</code></pre> <p>               Bases: <code>TCTrendABC</code></p> <p>Accessor for TCTrend data derived from 2000-2019.</p> <p>Attributes:</p> <ul> <li> <code>collection</code>               (<code>str</code>)           \u2013            <p>The collection ID of the datacube.</p> </li> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the zarr array. Should be equal to the extent geobox.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_patches</code>             \u2013              <p>Get the adjacent patches for the given geobox.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>assert_temporal_cube</code>             \u2013              <p>Assert that the datacube has a temporal dimension.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_patch</code>             \u2013              <p>Download the data for the given patch.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>loaded_patches</code>             \u2013              <p>Get the ids of already (down-)loaded patches.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Post create actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>post_init</code>             \u2013              <p>Post init actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download tiles procedurally.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n        backend (Literal[\"threaded\", \"simple\"], optional): The backend to use for downloading data.\n            Currently, only \"threaded\" is supported. Defaults to \"threaded\".\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = Chronometer(logger.debug)\n\n    if backend == \"threaded\":\n        if not _check_python_version(3, 13):\n            raise NotImplementedError(\n                \"The 'threaded' backend is only fully supported in Python 3.13 and above.\"\n                \" Please consider using the 'simple' backend in a multiprocessing environment\"\n                \" or upgrade your Python version.\"\n            )\n        self.backend = ThreadedBackend(self.repo, self.download_patch)\n    elif backend == \"simple\":\n        self.backend = SimpleBackend(self.repo, self.download_patch)\n    else:\n        raise ValueError(f\"Unknown backend {backend}\")\n\n    self.post_init()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019(backend)","title":"<code>backend</code>","text":"(<code>Literal['threaded', 'simple']</code>, default:                   <code>'threaded'</code> )           \u2013            <p>The backend to use for downloading data. Currently, only \"threaded\" is supported. Defaults to \"threaded\".</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre> <p>Check if the datacube already exists in the storage.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.is_temporal","title":"is_temporal  <code>property</code>","text":"<pre><code>is_temporal: bool\n</code></pre> <p>Check if the datacube has a temporal dimension.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube has a temporal dimension.</p> </li> </ul>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.adjacent_patches","title":"adjacent_patches","text":"<pre><code>adjacent_patches(\n    roi: Geometry | GeoBox | GeoDataFrame, toi: TOI\n) -&gt; list[Item]\n</code></pre> <p>Get the adjacent patches for the given geobox.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[Item]</code>           \u2013            <p>list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the ROI type is invalid.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If the datacube is not temporal, but a time of interest is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def adjacent_patches(self, roi: Geometry | GeoBox | gpd.GeoDataFrame, toi: TOI) -&gt; list[Item]:\n    \"\"\"Get the adjacent patches for the given geobox.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        roi (Geometry | GeoBox | gpd.GeoDataFrame): The reference geometry, geobox or reference geodataframe\n        toi (TOI): The time of interest to download.\n\n    Returns:\n        list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.\n\n    Raises:\n        ValueError: If the ROI type is invalid.\n        ValueError: If the datacube is not temporal, but a time of interest is provided.\n\n    \"\"\"\n    if toi is not None and not self.is_temporal:\n        raise ValueError(\"Datacube is not temporal, but time of interest is provided.\")\n\n    if isinstance(roi, gpd.GeoDataFrame):\n        adjacent_geometries = (\n            gpd.sjoin(self._tile_geometries, roi.to_crs(self.extent.crs.wkt), how=\"inner\", predicate=\"intersects\")\n            .reset_index()\n            .drop_duplicates(subset=\"index\", keep=\"first\")\n            .set_index(\"index\")\n        )\n        spatial_idxs: list[tuple[int, int]] = list(adjacent_geometries[\"idx\"])\n    elif isinstance(roi, GeoBox):\n        spatial_idxs: list[tuple[int, int]] = list(self._extent_tiles.tiles(roi.extent))\n    elif isinstance(roi, Geometry):\n        spatial_idxs: list[tuple[int, int]] = list(self._extent_tiles.tiles(roi))\n    else:\n        raise ValueError(\"Invalid ROI type.\")\n\n    if not self.is_temporal:\n        return [\n            PatchIndex(\n                self._stringify_index(spatial_idx),\n                self._extent_tiles[spatial_idx].geographic_extent,\n                None,\n                Item(self._extent_tiles[spatial_idx], None),\n            )\n            for spatial_idx in spatial_idxs\n        ]\n\n    # Now datacube is temporal\n    toi = normalize_toi(self.temporal_extent, toi)\n    patch_idxs = []\n    for time in toi:\n        time_idx = self.temporal_extent.get_loc(time)\n        assert isinstance(time_idx, int), \"Non-Unique temporal extents are not supported!\"\n        for spatial_idx in spatial_idxs:\n            patch_idxs.append(\n                PatchIndex(\n                    self._stringify_index(spatial_idx, time_idx),\n                    self._extent_tiles[spatial_idx].geographic_extent,\n                    time,\n                    Item(self._extent_tiles[spatial_idx], time),\n                )\n            )\n    return patch_idxs\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.adjacent_patches(roi)","title":"<code>roi</code>","text":"(<code>Geometry | GeoBox | GeoDataFrame</code>)           \u2013            <p>The reference geometry, geobox or reference geodataframe</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.adjacent_patches(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\"\"\"\n    self.backend.assert_created()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.assert_temporal_cube","title":"assert_temporal_cube","text":"<pre><code>assert_temporal_cube()\n</code></pre> <p>Assert that the datacube has a temporal dimension.</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube has no temporal dimension.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_temporal_cube(self):\n    \"\"\"Assert that the datacube has a temporal dimension.\n\n    Raises:\n        ValueError: If the datacube has no temporal dimension.\n\n    \"\"\"\n    if self.temporal_extent is None:\n        msg = f\"Datacube {self.title} has no temporal dimension.\"\n        logger.error(msg)\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.create","title":"create","text":"<pre><code>create(overwrite: bool = False, exists_ok: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location and exists_ok is False.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def create(self, overwrite: bool = False, exists_ok: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube.\n            Has no effect if exists_ok is True. Defaults to False.\n        exists_ok (bool, optional): Do not raise an error if the datacube already exists.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location and exists_ok is False.\n\n    \"\"\"\n    if exists_ok and self.created:\n        logger.debug(\"Datacube was already created.\")\n        return\n\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Expand to temporal dimension if defined\n        if self.temporal_extent is not None:\n            ds = ds.expand_dims(time=self.temporal_extent)\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        if self.temporal_extent is not None:\n            coords_encoding[\"time\"] = {\"chunks\": ds.time.shape, **optimize_temporal_encoding(self.temporal_extent)}\n        chunks = (\n            (1, self.chunk_size, self.chunk_size)\n            if self.temporal_extent is not None\n            else (self.chunk_size, self.chunk_size)\n        )\n        var_encoding = {\n            name: {\n                \"chunks\": chunks,\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Has no effect if exists_ok is True. Defaults to False.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.create(exists_ok)","title":"<code>exists_ok</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Do not raise an error if the datacube already exists.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.\n\n    \"\"\"\n    import geopandas as gpd\n\n    if not self.created:\n        return None\n\n    loaded_patches = self.loaded_patches()\n\n    if len(loaded_patches) == 0:\n        return None\n\n    patch_infos = []\n    for pid in loaded_patches:\n        spatial_idx, temporal_idx = self._parse_index(pid)\n        geometry = self._extent_tiles[spatial_idx].extent.geom\n        if self.is_temporal:\n            time = self.temporal_extent[temporal_idx]\n            patch_infos.append({\"geometry\": geometry, \"id\": pid, \"time\": time})\n        else:\n            patch_infos.append({\"geometry\": geometry, \"id\": pid})\n\n    gdf = gpd.GeoDataFrame(patch_infos, crs=self.extent.crs.to_wkt())\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.download_patch","title":"download_patch","text":"<pre><code>download_patch(idx: PatchIndex) -&gt; xr.Dataset\n</code></pre> <p>Download the data for the given patch.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded patch data.</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/tctrend.py</code> <pre><code>def download_patch(self, idx: PatchIndex) -&gt; xr.Dataset:\n    \"\"\"Download the data for the given patch.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        idx (PatchIndex): The reference patch to download the data for.\n\n    Returns:\n        xr.Dataset: The downloaded patch data.\n\n    \"\"\"\n    patch = super().download_patch(idx)\n\n    # ?: The following code handles the occurance of nan values when using mosaics\n    # Save original min-max values for each band for clipping later\n    clip_values = {\n        band: (patch[band].min().values.item(), patch[band].max().values.item()) for band in patch.data_vars\n    }\n\n    # Interpolate missing values (there are very few, so we actually can interpolate them)\n    patch.rio.set_spatial_dims(x_dim=\"x\", y_dim=\"y\", inplace=True)\n    for band in patch.data_vars:\n        patch[band] = patch[band].rio.write_nodata(np.nan).rio.interpolate_na()\n\n    # Convert to uint8\n    for band in patch.data_vars:\n        band_min, band_max = clip_values[band]\n        patch[band] = patch[band].clip(band_min, band_max, keep_attrs=True).astype(\"uint8\").rio.write_nodata(None)\n\n    return patch\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.download_patch(idx)","title":"<code>idx</code>","text":"(<code>PatchIndex</code>)           \u2013            <p>The reference patch to download the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.load","title":"load","text":"<pre><code>load(\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load(\n    self,\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        aoi (Geometry | GeoBox): The reference geometry to load the data for. If a Geobox is provided,\n            it will use the extent of the geobox.\n        toi (TOI): The temporal slice to load. Defaults to None.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    if toi is not None:\n        self.assert_temporal_cube()\n\n    if isinstance(aoi, GeoBox):\n        aoi = aoi.extent\n\n    with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        aligned_aoi = aoi.to_crs(self.extent.crs)\n        with self.stopuhr(f\"{_geometry_repr(aoi)}: Procedural download in blocking mode\"):\n            self.procedural_download(aligned_aoi, toi)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get temporal slice if time is provided\n        if toi is not None:\n            xrcube = xrcube.sel(time=toi)\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(aligned_aoi, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.load(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry | GeoBox</code>)           \u2013            <p>The reference geometry to load the data for. If a Geobox is provided, it will use the extent of the geobox.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.load(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>, default:                   <code>None</code> )           \u2013            <p>The temporal slice to load. Defaults to None.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    toi = None\n    if \"time\" in ref.coords and self.temporal_extent is not None:\n        toi = ref.get_index(\"time\")\n    return self.load(ref.geobox, toi=toi, **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.loaded_patches","title":"loaded_patches","text":"<pre><code>loaded_patches() -&gt; list[str]\n</code></pre> <p>Get the ids of already (down-)loaded patches.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>list[str]: A list of already loaded patch ids.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def loaded_patches(self) -&gt; list[str]:\n    \"\"\"Get the ids of already (down-)loaded patches.\n\n    Returns:\n        list[str]: A list of already loaded patch ids.\n\n    \"\"\"\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube.attrs.get(\"loaded_patches\", []).copy()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    return self.backend.open_xarray()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    return self.backend.open_zarr()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Post create actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_create(self):\n    \"\"\"Post create actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.post_init","title":"post_init","text":"<pre><code>post_init()\n</code></pre> <p>Post init actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_init(self):\n    \"\"\"Post init actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(aoi: Geometry, toi: TOI)\n</code></pre> <p>Download tiles procedurally.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If not all downloads were successful.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def procedural_download(self, aoi: Geometry, toi: TOI):\n    \"\"\"Download tiles procedurally.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        aoi (Geometry): The geometry of the aoi to download.\n        toi (TOI): The time of interest to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If not all downloads were successful.\n\n    \"\"\"\n    adjacent_patches = self.adjacent_patches(aoi, toi)\n    # interest-string\n    soi = f\"{_geometry_repr(aoi)}\" + (f\" @ {_repr_toi(toi)}\" if toi is not None else \"\")\n    if not adjacent_patches:\n        logger.error(f\"{soi}: No adjacent patches found: {adjacent_patches=}\")\n        raise ValueError(\"No adjacent patches found - is the provided aoi and toi correct?\")\n\n    loaded_patches = self.loaded_patches()\n\n    new_patches = [patch for patch in adjacent_patches if patch.id not in loaded_patches]\n\n    logger.debug(f\"{soi}:  {len(adjacent_patches)=} &amp; {len(loaded_patches)=} -&gt; {len(new_patches)=} to download\")\n    if not new_patches:\n        return\n\n    # This raises Errors if anything goes wrong -&gt; we want to propagate\n    self.backend.submit(new_patches)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.procedural_download(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry</code>)           \u2013            <p>The geometry of the aoi to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.procedural_download(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/tctrend.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    import cartopy.crs as ccrs\n    import cartopy.feature as cfeature\n    import matplotlib.pyplot as plt\n\n    tile_info = self.current_state()\n\n    if tile_info is None:\n        raise ValueError(\"Datacube is not created or loaded yet. Can't visualize!\")\n\n    # Define the projection\n    projection = ccrs.PlateCarree()\n\n    # Create a figure\n    fig = None\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": projection})\n\n    # Set the extent to show the whole world\n    ax.set_extent([-180, 180, -90, 90], crs=ccrs.PlateCarree())\n\n    # Add features\n    ax.add_feature(cfeature.LAND, zorder=0, edgecolor=\"black\", facecolor=\"white\")\n    ax.add_feature(cfeature.OCEAN, zorder=0, facecolor=\"lightgrey\")\n    ax.add_feature(cfeature.COASTLINE)\n    ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n    ax.add_feature(cfeature.LAKES, alpha=0.5)\n    ax.add_feature(cfeature.RIVERS)\n\n    # Add gridlines\n    gl = ax.gridlines(draw_labels=True)\n    gl.top_labels = False\n    gl.right_labels = False\n\n    tile_info.plot(\n        \"id\",\n        ax=ax,\n        transform=ccrs.PlateCarree(),\n        edgecolor=\"black\",\n        categorical=True,\n        aspect=\"equal\",\n        alpha=0.5,\n    )\n\n    if fig is not None:\n        return fig\n    else:\n        return ax\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2019.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020","title":"TCTrend2020","text":"<pre><code>TCTrend2020(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n)\n</code></pre> <p>               Bases: <code>TCTrendABC</code></p> <p>Accessor for TCTrend data derived from 2001-2020.</p> <p>Attributes:</p> <ul> <li> <code>collection</code>               (<code>str</code>)           \u2013            <p>The collection ID of the datacube.</p> </li> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the zarr array. Should be equal to the extent geobox.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_patches</code>             \u2013              <p>Get the adjacent patches for the given geobox.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>assert_temporal_cube</code>             \u2013              <p>Assert that the datacube has a temporal dimension.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_patch</code>             \u2013              <p>Download the data for the given patch.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>loaded_patches</code>             \u2013              <p>Get the ids of already (down-)loaded patches.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Post create actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>post_init</code>             \u2013              <p>Post init actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download tiles procedurally.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n        backend (Literal[\"threaded\", \"simple\"], optional): The backend to use for downloading data.\n            Currently, only \"threaded\" is supported. Defaults to \"threaded\".\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = Chronometer(logger.debug)\n\n    if backend == \"threaded\":\n        if not _check_python_version(3, 13):\n            raise NotImplementedError(\n                \"The 'threaded' backend is only fully supported in Python 3.13 and above.\"\n                \" Please consider using the 'simple' backend in a multiprocessing environment\"\n                \" or upgrade your Python version.\"\n            )\n        self.backend = ThreadedBackend(self.repo, self.download_patch)\n    elif backend == \"simple\":\n        self.backend = SimpleBackend(self.repo, self.download_patch)\n    else:\n        raise ValueError(f\"Unknown backend {backend}\")\n\n    self.post_init()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020(backend)","title":"<code>backend</code>","text":"(<code>Literal['threaded', 'simple']</code>, default:                   <code>'threaded'</code> )           \u2013            <p>The backend to use for downloading data. Currently, only \"threaded\" is supported. Defaults to \"threaded\".</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre> <p>Check if the datacube already exists in the storage.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.is_temporal","title":"is_temporal  <code>property</code>","text":"<pre><code>is_temporal: bool\n</code></pre> <p>Check if the datacube has a temporal dimension.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube has a temporal dimension.</p> </li> </ul>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.adjacent_patches","title":"adjacent_patches","text":"<pre><code>adjacent_patches(\n    roi: Geometry | GeoBox | GeoDataFrame, toi: TOI\n) -&gt; list[Item]\n</code></pre> <p>Get the adjacent patches for the given geobox.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[Item]</code>           \u2013            <p>list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the ROI type is invalid.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If the datacube is not temporal, but a time of interest is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def adjacent_patches(self, roi: Geometry | GeoBox | gpd.GeoDataFrame, toi: TOI) -&gt; list[Item]:\n    \"\"\"Get the adjacent patches for the given geobox.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        roi (Geometry | GeoBox | gpd.GeoDataFrame): The reference geometry, geobox or reference geodataframe\n        toi (TOI): The time of interest to download.\n\n    Returns:\n        list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.\n\n    Raises:\n        ValueError: If the ROI type is invalid.\n        ValueError: If the datacube is not temporal, but a time of interest is provided.\n\n    \"\"\"\n    if toi is not None and not self.is_temporal:\n        raise ValueError(\"Datacube is not temporal, but time of interest is provided.\")\n\n    if isinstance(roi, gpd.GeoDataFrame):\n        adjacent_geometries = (\n            gpd.sjoin(self._tile_geometries, roi.to_crs(self.extent.crs.wkt), how=\"inner\", predicate=\"intersects\")\n            .reset_index()\n            .drop_duplicates(subset=\"index\", keep=\"first\")\n            .set_index(\"index\")\n        )\n        spatial_idxs: list[tuple[int, int]] = list(adjacent_geometries[\"idx\"])\n    elif isinstance(roi, GeoBox):\n        spatial_idxs: list[tuple[int, int]] = list(self._extent_tiles.tiles(roi.extent))\n    elif isinstance(roi, Geometry):\n        spatial_idxs: list[tuple[int, int]] = list(self._extent_tiles.tiles(roi))\n    else:\n        raise ValueError(\"Invalid ROI type.\")\n\n    if not self.is_temporal:\n        return [\n            PatchIndex(\n                self._stringify_index(spatial_idx),\n                self._extent_tiles[spatial_idx].geographic_extent,\n                None,\n                Item(self._extent_tiles[spatial_idx], None),\n            )\n            for spatial_idx in spatial_idxs\n        ]\n\n    # Now datacube is temporal\n    toi = normalize_toi(self.temporal_extent, toi)\n    patch_idxs = []\n    for time in toi:\n        time_idx = self.temporal_extent.get_loc(time)\n        assert isinstance(time_idx, int), \"Non-Unique temporal extents are not supported!\"\n        for spatial_idx in spatial_idxs:\n            patch_idxs.append(\n                PatchIndex(\n                    self._stringify_index(spatial_idx, time_idx),\n                    self._extent_tiles[spatial_idx].geographic_extent,\n                    time,\n                    Item(self._extent_tiles[spatial_idx], time),\n                )\n            )\n    return patch_idxs\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.adjacent_patches(roi)","title":"<code>roi</code>","text":"(<code>Geometry | GeoBox | GeoDataFrame</code>)           \u2013            <p>The reference geometry, geobox or reference geodataframe</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.adjacent_patches(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\"\"\"\n    self.backend.assert_created()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.assert_temporal_cube","title":"assert_temporal_cube","text":"<pre><code>assert_temporal_cube()\n</code></pre> <p>Assert that the datacube has a temporal dimension.</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube has no temporal dimension.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_temporal_cube(self):\n    \"\"\"Assert that the datacube has a temporal dimension.\n\n    Raises:\n        ValueError: If the datacube has no temporal dimension.\n\n    \"\"\"\n    if self.temporal_extent is None:\n        msg = f\"Datacube {self.title} has no temporal dimension.\"\n        logger.error(msg)\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.create","title":"create","text":"<pre><code>create(overwrite: bool = False, exists_ok: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location and exists_ok is False.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def create(self, overwrite: bool = False, exists_ok: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube.\n            Has no effect if exists_ok is True. Defaults to False.\n        exists_ok (bool, optional): Do not raise an error if the datacube already exists.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location and exists_ok is False.\n\n    \"\"\"\n    if exists_ok and self.created:\n        logger.debug(\"Datacube was already created.\")\n        return\n\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Expand to temporal dimension if defined\n        if self.temporal_extent is not None:\n            ds = ds.expand_dims(time=self.temporal_extent)\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        if self.temporal_extent is not None:\n            coords_encoding[\"time\"] = {\"chunks\": ds.time.shape, **optimize_temporal_encoding(self.temporal_extent)}\n        chunks = (\n            (1, self.chunk_size, self.chunk_size)\n            if self.temporal_extent is not None\n            else (self.chunk_size, self.chunk_size)\n        )\n        var_encoding = {\n            name: {\n                \"chunks\": chunks,\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Has no effect if exists_ok is True. Defaults to False.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.create(exists_ok)","title":"<code>exists_ok</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Do not raise an error if the datacube already exists.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.\n\n    \"\"\"\n    import geopandas as gpd\n\n    if not self.created:\n        return None\n\n    loaded_patches = self.loaded_patches()\n\n    if len(loaded_patches) == 0:\n        return None\n\n    patch_infos = []\n    for pid in loaded_patches:\n        spatial_idx, temporal_idx = self._parse_index(pid)\n        geometry = self._extent_tiles[spatial_idx].extent.geom\n        if self.is_temporal:\n            time = self.temporal_extent[temporal_idx]\n            patch_infos.append({\"geometry\": geometry, \"id\": pid, \"time\": time})\n        else:\n            patch_infos.append({\"geometry\": geometry, \"id\": pid})\n\n    gdf = gpd.GeoDataFrame(patch_infos, crs=self.extent.crs.to_wkt())\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.download_patch","title":"download_patch","text":"<pre><code>download_patch(idx: PatchIndex) -&gt; xr.Dataset\n</code></pre> <p>Download the data for the given patch.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded patch data.</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/tctrend.py</code> <pre><code>def download_patch(self, idx: PatchIndex) -&gt; xr.Dataset:\n    \"\"\"Download the data for the given patch.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        idx (PatchIndex): The reference patch to download the data for.\n\n    Returns:\n        xr.Dataset: The downloaded patch data.\n\n    \"\"\"\n    patch = super().download_patch(idx)\n\n    # ?: The following code handles the occurance of nan values when using mosaics\n    # Save original min-max values for each band for clipping later\n    clip_values = {\n        band: (patch[band].min().values.item(), patch[band].max().values.item()) for band in patch.data_vars\n    }\n\n    # Interpolate missing values (there are very few, so we actually can interpolate them)\n    patch.rio.set_spatial_dims(x_dim=\"x\", y_dim=\"y\", inplace=True)\n    for band in patch.data_vars:\n        patch[band] = patch[band].rio.write_nodata(np.nan).rio.interpolate_na()\n\n    # Convert to uint8\n    for band in patch.data_vars:\n        band_min, band_max = clip_values[band]\n        patch[band] = patch[band].clip(band_min, band_max, keep_attrs=True).astype(\"uint8\").rio.write_nodata(None)\n\n    return patch\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.download_patch(idx)","title":"<code>idx</code>","text":"(<code>PatchIndex</code>)           \u2013            <p>The reference patch to download the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.load","title":"load","text":"<pre><code>load(\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load(\n    self,\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        aoi (Geometry | GeoBox): The reference geometry to load the data for. If a Geobox is provided,\n            it will use the extent of the geobox.\n        toi (TOI): The temporal slice to load. Defaults to None.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    if toi is not None:\n        self.assert_temporal_cube()\n\n    if isinstance(aoi, GeoBox):\n        aoi = aoi.extent\n\n    with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        aligned_aoi = aoi.to_crs(self.extent.crs)\n        with self.stopuhr(f\"{_geometry_repr(aoi)}: Procedural download in blocking mode\"):\n            self.procedural_download(aligned_aoi, toi)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get temporal slice if time is provided\n        if toi is not None:\n            xrcube = xrcube.sel(time=toi)\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(aligned_aoi, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.load(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry | GeoBox</code>)           \u2013            <p>The reference geometry to load the data for. If a Geobox is provided, it will use the extent of the geobox.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.load(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>, default:                   <code>None</code> )           \u2013            <p>The temporal slice to load. Defaults to None.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    toi = None\n    if \"time\" in ref.coords and self.temporal_extent is not None:\n        toi = ref.get_index(\"time\")\n    return self.load(ref.geobox, toi=toi, **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.loaded_patches","title":"loaded_patches","text":"<pre><code>loaded_patches() -&gt; list[str]\n</code></pre> <p>Get the ids of already (down-)loaded patches.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>list[str]: A list of already loaded patch ids.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def loaded_patches(self) -&gt; list[str]:\n    \"\"\"Get the ids of already (down-)loaded patches.\n\n    Returns:\n        list[str]: A list of already loaded patch ids.\n\n    \"\"\"\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube.attrs.get(\"loaded_patches\", []).copy()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    return self.backend.open_xarray()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    return self.backend.open_zarr()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Post create actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_create(self):\n    \"\"\"Post create actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.post_init","title":"post_init","text":"<pre><code>post_init()\n</code></pre> <p>Post init actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_init(self):\n    \"\"\"Post init actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(aoi: Geometry, toi: TOI)\n</code></pre> <p>Download tiles procedurally.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If not all downloads were successful.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def procedural_download(self, aoi: Geometry, toi: TOI):\n    \"\"\"Download tiles procedurally.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        aoi (Geometry): The geometry of the aoi to download.\n        toi (TOI): The time of interest to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If not all downloads were successful.\n\n    \"\"\"\n    adjacent_patches = self.adjacent_patches(aoi, toi)\n    # interest-string\n    soi = f\"{_geometry_repr(aoi)}\" + (f\" @ {_repr_toi(toi)}\" if toi is not None else \"\")\n    if not adjacent_patches:\n        logger.error(f\"{soi}: No adjacent patches found: {adjacent_patches=}\")\n        raise ValueError(\"No adjacent patches found - is the provided aoi and toi correct?\")\n\n    loaded_patches = self.loaded_patches()\n\n    new_patches = [patch for patch in adjacent_patches if patch.id not in loaded_patches]\n\n    logger.debug(f\"{soi}:  {len(adjacent_patches)=} &amp; {len(loaded_patches)=} -&gt; {len(new_patches)=} to download\")\n    if not new_patches:\n        return\n\n    # This raises Errors if anything goes wrong -&gt; we want to propagate\n    self.backend.submit(new_patches)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.procedural_download(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry</code>)           \u2013            <p>The geometry of the aoi to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.procedural_download(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/tctrend.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    import cartopy.crs as ccrs\n    import cartopy.feature as cfeature\n    import matplotlib.pyplot as plt\n\n    tile_info = self.current_state()\n\n    if tile_info is None:\n        raise ValueError(\"Datacube is not created or loaded yet. Can't visualize!\")\n\n    # Define the projection\n    projection = ccrs.PlateCarree()\n\n    # Create a figure\n    fig = None\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": projection})\n\n    # Set the extent to show the whole world\n    ax.set_extent([-180, 180, -90, 90], crs=ccrs.PlateCarree())\n\n    # Add features\n    ax.add_feature(cfeature.LAND, zorder=0, edgecolor=\"black\", facecolor=\"white\")\n    ax.add_feature(cfeature.OCEAN, zorder=0, facecolor=\"lightgrey\")\n    ax.add_feature(cfeature.COASTLINE)\n    ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n    ax.add_feature(cfeature.LAKES, alpha=0.5)\n    ax.add_feature(cfeature.RIVERS)\n\n    # Add gridlines\n    gl = ax.gridlines(draw_labels=True)\n    gl.top_labels = False\n    gl.right_labels = False\n\n    tile_info.plot(\n        \"id\",\n        ax=ax,\n        transform=ccrs.PlateCarree(),\n        edgecolor=\"black\",\n        categorical=True,\n        aspect=\"equal\",\n        alpha=0.5,\n    )\n\n    if fig is not None:\n        return fig\n    else:\n        return ax\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2020.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022","title":"TCTrend2022","text":"<pre><code>TCTrend2022(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n)\n</code></pre> <p>               Bases: <code>TCTrendABC</code></p> <p>Accessor for TCTrend data derived from 2003-2022.</p> <p>Attributes:</p> <ul> <li> <code>collection</code>               (<code>str</code>)           \u2013            <p>The collection ID of the datacube.</p> </li> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the zarr array. Should be equal to the extent geobox.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_patches</code>             \u2013              <p>Get the adjacent patches for the given geobox.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>assert_temporal_cube</code>             \u2013              <p>Assert that the datacube has a temporal dimension.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_patch</code>             \u2013              <p>Download the data for the given patch.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>loaded_patches</code>             \u2013              <p>Get the ids of already (down-)loaded patches.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Post create actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>post_init</code>             \u2013              <p>Post init actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download tiles procedurally.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n        backend (Literal[\"threaded\", \"simple\"], optional): The backend to use for downloading data.\n            Currently, only \"threaded\" is supported. Defaults to \"threaded\".\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = Chronometer(logger.debug)\n\n    if backend == \"threaded\":\n        if not _check_python_version(3, 13):\n            raise NotImplementedError(\n                \"The 'threaded' backend is only fully supported in Python 3.13 and above.\"\n                \" Please consider using the 'simple' backend in a multiprocessing environment\"\n                \" or upgrade your Python version.\"\n            )\n        self.backend = ThreadedBackend(self.repo, self.download_patch)\n    elif backend == \"simple\":\n        self.backend = SimpleBackend(self.repo, self.download_patch)\n    else:\n        raise ValueError(f\"Unknown backend {backend}\")\n\n    self.post_init()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022(backend)","title":"<code>backend</code>","text":"(<code>Literal['threaded', 'simple']</code>, default:                   <code>'threaded'</code> )           \u2013            <p>The backend to use for downloading data. Currently, only \"threaded\" is supported. Defaults to \"threaded\".</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre> <p>Check if the datacube already exists in the storage.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.is_temporal","title":"is_temporal  <code>property</code>","text":"<pre><code>is_temporal: bool\n</code></pre> <p>Check if the datacube has a temporal dimension.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube has a temporal dimension.</p> </li> </ul>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.adjacent_patches","title":"adjacent_patches","text":"<pre><code>adjacent_patches(\n    roi: Geometry | GeoBox | GeoDataFrame, toi: TOI\n) -&gt; list[Item]\n</code></pre> <p>Get the adjacent patches for the given geobox.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[Item]</code>           \u2013            <p>list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the ROI type is invalid.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If the datacube is not temporal, but a time of interest is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def adjacent_patches(self, roi: Geometry | GeoBox | gpd.GeoDataFrame, toi: TOI) -&gt; list[Item]:\n    \"\"\"Get the adjacent patches for the given geobox.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        roi (Geometry | GeoBox | gpd.GeoDataFrame): The reference geometry, geobox or reference geodataframe\n        toi (TOI): The time of interest to download.\n\n    Returns:\n        list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.\n\n    Raises:\n        ValueError: If the ROI type is invalid.\n        ValueError: If the datacube is not temporal, but a time of interest is provided.\n\n    \"\"\"\n    if toi is not None and not self.is_temporal:\n        raise ValueError(\"Datacube is not temporal, but time of interest is provided.\")\n\n    if isinstance(roi, gpd.GeoDataFrame):\n        adjacent_geometries = (\n            gpd.sjoin(self._tile_geometries, roi.to_crs(self.extent.crs.wkt), how=\"inner\", predicate=\"intersects\")\n            .reset_index()\n            .drop_duplicates(subset=\"index\", keep=\"first\")\n            .set_index(\"index\")\n        )\n        spatial_idxs: list[tuple[int, int]] = list(adjacent_geometries[\"idx\"])\n    elif isinstance(roi, GeoBox):\n        spatial_idxs: list[tuple[int, int]] = list(self._extent_tiles.tiles(roi.extent))\n    elif isinstance(roi, Geometry):\n        spatial_idxs: list[tuple[int, int]] = list(self._extent_tiles.tiles(roi))\n    else:\n        raise ValueError(\"Invalid ROI type.\")\n\n    if not self.is_temporal:\n        return [\n            PatchIndex(\n                self._stringify_index(spatial_idx),\n                self._extent_tiles[spatial_idx].geographic_extent,\n                None,\n                Item(self._extent_tiles[spatial_idx], None),\n            )\n            for spatial_idx in spatial_idxs\n        ]\n\n    # Now datacube is temporal\n    toi = normalize_toi(self.temporal_extent, toi)\n    patch_idxs = []\n    for time in toi:\n        time_idx = self.temporal_extent.get_loc(time)\n        assert isinstance(time_idx, int), \"Non-Unique temporal extents are not supported!\"\n        for spatial_idx in spatial_idxs:\n            patch_idxs.append(\n                PatchIndex(\n                    self._stringify_index(spatial_idx, time_idx),\n                    self._extent_tiles[spatial_idx].geographic_extent,\n                    time,\n                    Item(self._extent_tiles[spatial_idx], time),\n                )\n            )\n    return patch_idxs\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.adjacent_patches(roi)","title":"<code>roi</code>","text":"(<code>Geometry | GeoBox | GeoDataFrame</code>)           \u2013            <p>The reference geometry, geobox or reference geodataframe</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.adjacent_patches(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\"\"\"\n    self.backend.assert_created()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.assert_temporal_cube","title":"assert_temporal_cube","text":"<pre><code>assert_temporal_cube()\n</code></pre> <p>Assert that the datacube has a temporal dimension.</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube has no temporal dimension.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_temporal_cube(self):\n    \"\"\"Assert that the datacube has a temporal dimension.\n\n    Raises:\n        ValueError: If the datacube has no temporal dimension.\n\n    \"\"\"\n    if self.temporal_extent is None:\n        msg = f\"Datacube {self.title} has no temporal dimension.\"\n        logger.error(msg)\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.create","title":"create","text":"<pre><code>create(overwrite: bool = False, exists_ok: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location and exists_ok is False.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def create(self, overwrite: bool = False, exists_ok: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube.\n            Has no effect if exists_ok is True. Defaults to False.\n        exists_ok (bool, optional): Do not raise an error if the datacube already exists.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location and exists_ok is False.\n\n    \"\"\"\n    if exists_ok and self.created:\n        logger.debug(\"Datacube was already created.\")\n        return\n\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Expand to temporal dimension if defined\n        if self.temporal_extent is not None:\n            ds = ds.expand_dims(time=self.temporal_extent)\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        if self.temporal_extent is not None:\n            coords_encoding[\"time\"] = {\"chunks\": ds.time.shape, **optimize_temporal_encoding(self.temporal_extent)}\n        chunks = (\n            (1, self.chunk_size, self.chunk_size)\n            if self.temporal_extent is not None\n            else (self.chunk_size, self.chunk_size)\n        )\n        var_encoding = {\n            name: {\n                \"chunks\": chunks,\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Has no effect if exists_ok is True. Defaults to False.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.create(exists_ok)","title":"<code>exists_ok</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Do not raise an error if the datacube already exists.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.\n\n    \"\"\"\n    import geopandas as gpd\n\n    if not self.created:\n        return None\n\n    loaded_patches = self.loaded_patches()\n\n    if len(loaded_patches) == 0:\n        return None\n\n    patch_infos = []\n    for pid in loaded_patches:\n        spatial_idx, temporal_idx = self._parse_index(pid)\n        geometry = self._extent_tiles[spatial_idx].extent.geom\n        if self.is_temporal:\n            time = self.temporal_extent[temporal_idx]\n            patch_infos.append({\"geometry\": geometry, \"id\": pid, \"time\": time})\n        else:\n            patch_infos.append({\"geometry\": geometry, \"id\": pid})\n\n    gdf = gpd.GeoDataFrame(patch_infos, crs=self.extent.crs.to_wkt())\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.download_patch","title":"download_patch","text":"<pre><code>download_patch(idx: PatchIndex) -&gt; xr.Dataset\n</code></pre> <p>Download the data for the given patch.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded patch data.</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/tctrend.py</code> <pre><code>def download_patch(self, idx: PatchIndex) -&gt; xr.Dataset:\n    \"\"\"Download the data for the given patch.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        idx (PatchIndex): The reference patch to download the data for.\n\n    Returns:\n        xr.Dataset: The downloaded patch data.\n\n    \"\"\"\n    patch = super().download_patch(idx)\n\n    # ?: The following code handles the occurance of nan values when using mosaics\n    # Save original min-max values for each band for clipping later\n    clip_values = {\n        band: (patch[band].min().values.item(), patch[band].max().values.item()) for band in patch.data_vars\n    }\n\n    # Interpolate missing values (there are very few, so we actually can interpolate them)\n    patch.rio.set_spatial_dims(x_dim=\"x\", y_dim=\"y\", inplace=True)\n    for band in patch.data_vars:\n        patch[band] = patch[band].rio.write_nodata(np.nan).rio.interpolate_na()\n\n    # Convert to uint8\n    for band in patch.data_vars:\n        band_min, band_max = clip_values[band]\n        patch[band] = patch[band].clip(band_min, band_max, keep_attrs=True).astype(\"uint8\").rio.write_nodata(None)\n\n    return patch\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.download_patch(idx)","title":"<code>idx</code>","text":"(<code>PatchIndex</code>)           \u2013            <p>The reference patch to download the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.load","title":"load","text":"<pre><code>load(\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load(\n    self,\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        aoi (Geometry | GeoBox): The reference geometry to load the data for. If a Geobox is provided,\n            it will use the extent of the geobox.\n        toi (TOI): The temporal slice to load. Defaults to None.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    if toi is not None:\n        self.assert_temporal_cube()\n\n    if isinstance(aoi, GeoBox):\n        aoi = aoi.extent\n\n    with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        aligned_aoi = aoi.to_crs(self.extent.crs)\n        with self.stopuhr(f\"{_geometry_repr(aoi)}: Procedural download in blocking mode\"):\n            self.procedural_download(aligned_aoi, toi)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get temporal slice if time is provided\n        if toi is not None:\n            xrcube = xrcube.sel(time=toi)\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(aligned_aoi, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.load(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry | GeoBox</code>)           \u2013            <p>The reference geometry to load the data for. If a Geobox is provided, it will use the extent of the geobox.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.load(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>, default:                   <code>None</code> )           \u2013            <p>The temporal slice to load. Defaults to None.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    toi = None\n    if \"time\" in ref.coords and self.temporal_extent is not None:\n        toi = ref.get_index(\"time\")\n    return self.load(ref.geobox, toi=toi, **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.loaded_patches","title":"loaded_patches","text":"<pre><code>loaded_patches() -&gt; list[str]\n</code></pre> <p>Get the ids of already (down-)loaded patches.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>list[str]: A list of already loaded patch ids.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def loaded_patches(self) -&gt; list[str]:\n    \"\"\"Get the ids of already (down-)loaded patches.\n\n    Returns:\n        list[str]: A list of already loaded patch ids.\n\n    \"\"\"\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube.attrs.get(\"loaded_patches\", []).copy()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    return self.backend.open_xarray()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    return self.backend.open_zarr()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Post create actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_create(self):\n    \"\"\"Post create actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.post_init","title":"post_init","text":"<pre><code>post_init()\n</code></pre> <p>Post init actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_init(self):\n    \"\"\"Post init actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(aoi: Geometry, toi: TOI)\n</code></pre> <p>Download tiles procedurally.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If not all downloads were successful.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def procedural_download(self, aoi: Geometry, toi: TOI):\n    \"\"\"Download tiles procedurally.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        aoi (Geometry): The geometry of the aoi to download.\n        toi (TOI): The time of interest to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If not all downloads were successful.\n\n    \"\"\"\n    adjacent_patches = self.adjacent_patches(aoi, toi)\n    # interest-string\n    soi = f\"{_geometry_repr(aoi)}\" + (f\" @ {_repr_toi(toi)}\" if toi is not None else \"\")\n    if not adjacent_patches:\n        logger.error(f\"{soi}: No adjacent patches found: {adjacent_patches=}\")\n        raise ValueError(\"No adjacent patches found - is the provided aoi and toi correct?\")\n\n    loaded_patches = self.loaded_patches()\n\n    new_patches = [patch for patch in adjacent_patches if patch.id not in loaded_patches]\n\n    logger.debug(f\"{soi}:  {len(adjacent_patches)=} &amp; {len(loaded_patches)=} -&gt; {len(new_patches)=} to download\")\n    if not new_patches:\n        return\n\n    # This raises Errors if anything goes wrong -&gt; we want to propagate\n    self.backend.submit(new_patches)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.procedural_download(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry</code>)           \u2013            <p>The geometry of the aoi to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.procedural_download(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/tctrend.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    import cartopy.crs as ccrs\n    import cartopy.feature as cfeature\n    import matplotlib.pyplot as plt\n\n    tile_info = self.current_state()\n\n    if tile_info is None:\n        raise ValueError(\"Datacube is not created or loaded yet. Can't visualize!\")\n\n    # Define the projection\n    projection = ccrs.PlateCarree()\n\n    # Create a figure\n    fig = None\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": projection})\n\n    # Set the extent to show the whole world\n    ax.set_extent([-180, 180, -90, 90], crs=ccrs.PlateCarree())\n\n    # Add features\n    ax.add_feature(cfeature.LAND, zorder=0, edgecolor=\"black\", facecolor=\"white\")\n    ax.add_feature(cfeature.OCEAN, zorder=0, facecolor=\"lightgrey\")\n    ax.add_feature(cfeature.COASTLINE)\n    ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n    ax.add_feature(cfeature.LAKES, alpha=0.5)\n    ax.add_feature(cfeature.RIVERS)\n\n    # Add gridlines\n    gl = ax.gridlines(draw_labels=True)\n    gl.top_labels = False\n    gl.right_labels = False\n\n    tile_info.plot(\n        \"id\",\n        ax=ax,\n        transform=ccrs.PlateCarree(),\n        edgecolor=\"black\",\n        categorical=True,\n        aspect=\"equal\",\n        alpha=0.5,\n    )\n\n    if fig is not None:\n        return fig\n    else:\n        return ax\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend2022.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/accessors/","title":"accessors","text":""},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors","title":"smart_geocubes.accessors","text":"<p>Smart-Geocubes accessor implementations.</p> <p>Modules:</p> <ul> <li> <code>gee</code>           \u2013            <p>Google Earth Engine Accessor for Smart Geocubes.</p> </li> <li> <code>stac</code>           \u2013            <p>STAC Accessor for Smart Geocubes.</p> </li> </ul> <p>Classes:</p> <ul> <li> <code>GEEMosaicAccessor</code>           \u2013            <p>Accessor for Google Earth Engine data using mosaics.</p> </li> <li> <code>STACAccessor</code>           \u2013            <p>Accessor for STAC data.</p> </li> </ul>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor","title":"GEEMosaicAccessor","text":"<pre><code>GEEMosaicAccessor(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n)\n</code></pre> <p>               Bases: <code>RemoteAccessor</code></p> <p>Accessor for Google Earth Engine data using mosaics.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the underlaying zarr array. Should be equal to the extent geobox. However, this property is used to find the target index of the downloaded data, so better save than sorry.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_patches</code>             \u2013              <p>Get the adjacent patches for the given geobox.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>assert_temporal_cube</code>             \u2013              <p>Assert that the datacube has a temporal dimension.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_patch</code>             \u2013              <p>Download the data for the given patch.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>loaded_patches</code>             \u2013              <p>Get the ids of already (down-)loaded patches.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Post create actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>post_init</code>             \u2013              <p>Post init actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download tiles procedurally.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize currently stored tiles / chunk.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n        backend (Literal[\"threaded\", \"simple\"], optional): The backend to use for downloading data.\n            Currently, only \"threaded\" is supported. Defaults to \"threaded\".\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = Chronometer(logger.debug)\n\n    if backend == \"threaded\":\n        if not _check_python_version(3, 13):\n            raise NotImplementedError(\n                \"The 'threaded' backend is only fully supported in Python 3.13 and above.\"\n                \" Please consider using the 'simple' backend in a multiprocessing environment\"\n                \" or upgrade your Python version.\"\n            )\n        self.backend = ThreadedBackend(self.repo, self.download_patch)\n    elif backend == \"simple\":\n        self.backend = SimpleBackend(self.repo, self.download_patch)\n    else:\n        raise ValueError(f\"Unknown backend {backend}\")\n\n    self.post_init()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor(backend)","title":"<code>backend</code>","text":"(<code>Literal['threaded', 'simple']</code>, default:                   <code>'threaded'</code> )           \u2013            <p>The backend to use for downloading data. Currently, only \"threaded\" is supported. Defaults to \"threaded\".</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre> <p>Check if the datacube already exists in the storage.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.is_temporal","title":"is_temporal  <code>property</code>","text":"<pre><code>is_temporal: bool\n</code></pre> <p>Check if the datacube has a temporal dimension.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube has a temporal dimension.</p> </li> </ul>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.adjacent_patches","title":"adjacent_patches","text":"<pre><code>adjacent_patches(\n    roi: Geometry | GeoBox | GeoDataFrame, toi: TOI\n) -&gt; list[Item]\n</code></pre> <p>Get the adjacent patches for the given geobox.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[Item]</code>           \u2013            <p>list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the ROI type is invalid.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If the datacube is not temporal, but a time of interest is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def adjacent_patches(self, roi: Geometry | GeoBox | gpd.GeoDataFrame, toi: TOI) -&gt; list[Item]:\n    \"\"\"Get the adjacent patches for the given geobox.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        roi (Geometry | GeoBox | gpd.GeoDataFrame): The reference geometry, geobox or reference geodataframe\n        toi (TOI): The time of interest to download.\n\n    Returns:\n        list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.\n\n    Raises:\n        ValueError: If the ROI type is invalid.\n        ValueError: If the datacube is not temporal, but a time of interest is provided.\n\n    \"\"\"\n    if toi is not None and not self.is_temporal:\n        raise ValueError(\"Datacube is not temporal, but time of interest is provided.\")\n\n    if isinstance(roi, gpd.GeoDataFrame):\n        adjacent_geometries = (\n            gpd.sjoin(self._tile_geometries, roi.to_crs(self.extent.crs.wkt), how=\"inner\", predicate=\"intersects\")\n            .reset_index()\n            .drop_duplicates(subset=\"index\", keep=\"first\")\n            .set_index(\"index\")\n        )\n        spatial_idxs: list[tuple[int, int]] = list(adjacent_geometries[\"idx\"])\n    elif isinstance(roi, GeoBox):\n        spatial_idxs: list[tuple[int, int]] = list(self._extent_tiles.tiles(roi.extent))\n    elif isinstance(roi, Geometry):\n        spatial_idxs: list[tuple[int, int]] = list(self._extent_tiles.tiles(roi))\n    else:\n        raise ValueError(\"Invalid ROI type.\")\n\n    if not self.is_temporal:\n        return [\n            PatchIndex(\n                self._stringify_index(spatial_idx),\n                self._extent_tiles[spatial_idx].geographic_extent,\n                None,\n                Item(self._extent_tiles[spatial_idx], None),\n            )\n            for spatial_idx in spatial_idxs\n        ]\n\n    # Now datacube is temporal\n    toi = normalize_toi(self.temporal_extent, toi)\n    patch_idxs = []\n    for time in toi:\n        time_idx = self.temporal_extent.get_loc(time)\n        assert isinstance(time_idx, int), \"Non-Unique temporal extents are not supported!\"\n        for spatial_idx in spatial_idxs:\n            patch_idxs.append(\n                PatchIndex(\n                    self._stringify_index(spatial_idx, time_idx),\n                    self._extent_tiles[spatial_idx].geographic_extent,\n                    time,\n                    Item(self._extent_tiles[spatial_idx], time),\n                )\n            )\n    return patch_idxs\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.adjacent_patches(roi)","title":"<code>roi</code>","text":"(<code>Geometry | GeoBox | GeoDataFrame</code>)           \u2013            <p>The reference geometry, geobox or reference geodataframe</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.adjacent_patches(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\"\"\"\n    self.backend.assert_created()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.assert_temporal_cube","title":"assert_temporal_cube","text":"<pre><code>assert_temporal_cube()\n</code></pre> <p>Assert that the datacube has a temporal dimension.</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube has no temporal dimension.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_temporal_cube(self):\n    \"\"\"Assert that the datacube has a temporal dimension.\n\n    Raises:\n        ValueError: If the datacube has no temporal dimension.\n\n    \"\"\"\n    if self.temporal_extent is None:\n        msg = f\"Datacube {self.title} has no temporal dimension.\"\n        logger.error(msg)\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.create","title":"create","text":"<pre><code>create(overwrite: bool = False, exists_ok: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location and exists_ok is False.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def create(self, overwrite: bool = False, exists_ok: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube.\n            Has no effect if exists_ok is True. Defaults to False.\n        exists_ok (bool, optional): Do not raise an error if the datacube already exists.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location and exists_ok is False.\n\n    \"\"\"\n    if exists_ok and self.created:\n        logger.debug(\"Datacube was already created.\")\n        return\n\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Expand to temporal dimension if defined\n        if self.temporal_extent is not None:\n            ds = ds.expand_dims(time=self.temporal_extent)\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        if self.temporal_extent is not None:\n            coords_encoding[\"time\"] = {\"chunks\": ds.time.shape, **optimize_temporal_encoding(self.temporal_extent)}\n        chunks = (\n            (1, self.chunk_size, self.chunk_size)\n            if self.temporal_extent is not None\n            else (self.chunk_size, self.chunk_size)\n        )\n        var_encoding = {\n            name: {\n                \"chunks\": chunks,\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Has no effect if exists_ok is True. Defaults to False.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.create(exists_ok)","title":"<code>exists_ok</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Do not raise an error if the datacube already exists.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.\n\n    \"\"\"\n    import geopandas as gpd\n\n    if not self.created:\n        return None\n\n    loaded_patches = self.loaded_patches()\n\n    if len(loaded_patches) == 0:\n        return None\n\n    patch_infos = []\n    for pid in loaded_patches:\n        spatial_idx, temporal_idx = self._parse_index(pid)\n        geometry = self._extent_tiles[spatial_idx].extent.geom\n        if self.is_temporal:\n            time = self.temporal_extent[temporal_idx]\n            patch_infos.append({\"geometry\": geometry, \"id\": pid, \"time\": time})\n        else:\n            patch_infos.append({\"geometry\": geometry, \"id\": pid})\n\n    gdf = gpd.GeoDataFrame(patch_infos, crs=self.extent.crs.to_wkt())\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.download_patch","title":"download_patch","text":"<pre><code>download_patch(idx: PatchIndex[Item]) -&gt; xr.Dataset\n</code></pre> <p>Download the data for the given patch.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded patch data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def download_patch(self, idx: PatchIndex[Item]) -&gt; xr.Dataset:\n    \"\"\"Download the data for the given patch.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        idx (PatchIndex[Item]): The reference patch to download the data for.\n\n    Returns:\n        xr.Dataset: The downloaded patch data.\n\n    \"\"\"\n    import ee\n    import rioxarray  # noqa: F401\n    import xee  # noqa: F401\n\n    # Note: This is a little bit weird: First we create an own grid which overlaps to the chunks\n    # of the zarr array. Then we create a mosaic of the data and clip it to a single chunk.\n    # We could load the images from the collection directly instead of creating a mosaic.\n    # However, this would require more testing and probably results a lot of manual computation\n    # of slices etc. like in the stac variant. So for now, we just use the mosaic.\n    logging.getLogger(\"urllib3.connectionpool\").disabled = True\n\n    ee_col = ee.ImageCollection(self.collection)\n    if self.is_temporal:\n        ee_col = ee_col.filterDate(idx.item.time)\n    geom = ee.Geometry.Rectangle(idx.item.geobox.geographic_extent.boundingbox)\n    ee_img = ee_col.mosaic().clip(geom)\n\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=UserWarning, message=EE_WARN_MSG)\n        patch = xr.open_dataset(\n            ee_img,\n            engine=\"ee\",\n            geometry=geom,\n            crs=f\"epsg:{self.extent.crs.to_epsg()}\",\n            scale=self.extent.resolution.x,\n        )\n\n    # Do a mosaic if time axis are returned for non-temporal data\n    if \"time\" in patch.dims and not self.is_temporal:\n        patch = patch.max(\"time\")\n\n    patch = patch.rename({\"lon\": \"x\", \"lat\": \"y\"})\n    if \"time\" in patch.dims:\n        patch[\"time\"] = [idx.item.time]\n        patch = patch.transpose(\"time\", \"y\", \"x\")\n    else:\n        patch = patch.transpose(\"y\", \"x\")\n\n    # Download the data\n    logger.debug(f\"{idx.id=}: Trigger GEE download)\")\n    patch.load()\n    logger.debug(f\"{idx.id=}: Finished GEE download\")\n    logging.getLogger(\"urllib3.connectionpool\").disabled = False\n\n    # Flip y-axis, because convention is x in positive direction and y in negative, but gee use positive for both\n    patch = patch.isel(y=slice(None, None, -1))\n\n    # For some reason xee does not always set the crs\n    patch = patch.odc.assign_crs(self.extent.crs)\n\n    # Recrop the data to the tile, since gee does not always return the exact extent\n    patch = patch.odc.crop(idx.item.geobox.extent)\n\n    return patch\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.download_patch(idx)","title":"<code>idx</code>","text":"(<code>PatchIndex[Item]</code>)           \u2013            <p>The reference patch to download the data for.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.load","title":"load","text":"<pre><code>load(\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load(\n    self,\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        aoi (Geometry | GeoBox): The reference geometry to load the data for. If a Geobox is provided,\n            it will use the extent of the geobox.\n        toi (TOI): The temporal slice to load. Defaults to None.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    if toi is not None:\n        self.assert_temporal_cube()\n\n    if isinstance(aoi, GeoBox):\n        aoi = aoi.extent\n\n    with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        aligned_aoi = aoi.to_crs(self.extent.crs)\n        with self.stopuhr(f\"{_geometry_repr(aoi)}: Procedural download in blocking mode\"):\n            self.procedural_download(aligned_aoi, toi)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get temporal slice if time is provided\n        if toi is not None:\n            xrcube = xrcube.sel(time=toi)\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(aligned_aoi, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.load(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry | GeoBox</code>)           \u2013            <p>The reference geometry to load the data for. If a Geobox is provided, it will use the extent of the geobox.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.load(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>, default:                   <code>None</code> )           \u2013            <p>The temporal slice to load. Defaults to None.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    toi = None\n    if \"time\" in ref.coords and self.temporal_extent is not None:\n        toi = ref.get_index(\"time\")\n    return self.load(ref.geobox, toi=toi, **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.loaded_patches","title":"loaded_patches","text":"<pre><code>loaded_patches() -&gt; list[str]\n</code></pre> <p>Get the ids of already (down-)loaded patches.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>list[str]: A list of already loaded patch ids.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def loaded_patches(self) -&gt; list[str]:\n    \"\"\"Get the ids of already (down-)loaded patches.\n\n    Returns:\n        list[str]: A list of already loaded patch ids.\n\n    \"\"\"\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube.attrs.get(\"loaded_patches\", []).copy()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    return self.backend.open_xarray()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    return self.backend.open_zarr()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Post create actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_create(self):\n    \"\"\"Post create actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.post_init","title":"post_init","text":"<pre><code>post_init()\n</code></pre> <p>Post init actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_init(self):\n    \"\"\"Post init actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(aoi: Geometry, toi: TOI)\n</code></pre> <p>Download tiles procedurally.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If not all downloads were successful.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def procedural_download(self, aoi: Geometry, toi: TOI):\n    \"\"\"Download tiles procedurally.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        aoi (Geometry): The geometry of the aoi to download.\n        toi (TOI): The time of interest to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If not all downloads were successful.\n\n    \"\"\"\n    adjacent_patches = self.adjacent_patches(aoi, toi)\n    # interest-string\n    soi = f\"{_geometry_repr(aoi)}\" + (f\" @ {_repr_toi(toi)}\" if toi is not None else \"\")\n    if not adjacent_patches:\n        logger.error(f\"{soi}: No adjacent patches found: {adjacent_patches=}\")\n        raise ValueError(\"No adjacent patches found - is the provided aoi and toi correct?\")\n\n    loaded_patches = self.loaded_patches()\n\n    new_patches = [patch for patch in adjacent_patches if patch.id not in loaded_patches]\n\n    logger.debug(f\"{soi}:  {len(adjacent_patches)=} &amp; {len(loaded_patches)=} -&gt; {len(new_patches)=} to download\")\n    if not new_patches:\n        return\n\n    # This raises Errors if anything goes wrong -&gt; we want to propagate\n    self.backend.submit(new_patches)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.procedural_download(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry</code>)           \u2013            <p>The geometry of the aoi to download.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.procedural_download(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.visualize_state","title":"visualize_state  <code>abstractmethod</code>","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize currently stored tiles / chunk.</p> <p>Must be implemented by the DatasetAccessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>@abstractmethod\ndef visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize currently stored tiles / chunk.\n\n    Must be implemented by the DatasetAccessor.\n\n    Args:\n        ax (plt.Axes | None, optional): The axes drawn to. If None, will create a new figure and axes.\n            Defaults to None.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization\n\n    \"\"\"\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEMosaicAccessor.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes. Defaults to None.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor","title":"STACAccessor","text":"<pre><code>STACAccessor(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n)\n</code></pre> <p>               Bases: <code>RemoteAccessor</code></p> <p>Accessor for STAC data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the underlaying zarr array. Should be equal to the extent geobox. However, this property is used to find the target index of the downloaded data, so better save than sorry.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_patches</code>             \u2013              <p>Get the adjacent patches for the given geobox.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>assert_temporal_cube</code>             \u2013              <p>Assert that the datacube has a temporal dimension.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_patch</code>             \u2013              <p>Download the data for the given patch.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>loaded_patches</code>             \u2013              <p>Get the ids of already (down-)loaded patches.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Post create actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>post_init</code>             \u2013              <p>Post init actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download tiles procedurally.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize currently stored tiles / chunk.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n        backend (Literal[\"threaded\", \"simple\"], optional): The backend to use for downloading data.\n            Currently, only \"threaded\" is supported. Defaults to \"threaded\".\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = Chronometer(logger.debug)\n\n    if backend == \"threaded\":\n        if not _check_python_version(3, 13):\n            raise NotImplementedError(\n                \"The 'threaded' backend is only fully supported in Python 3.13 and above.\"\n                \" Please consider using the 'simple' backend in a multiprocessing environment\"\n                \" or upgrade your Python version.\"\n            )\n        self.backend = ThreadedBackend(self.repo, self.download_patch)\n    elif backend == \"simple\":\n        self.backend = SimpleBackend(self.repo, self.download_patch)\n    else:\n        raise ValueError(f\"Unknown backend {backend}\")\n\n    self.post_init()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor(backend)","title":"<code>backend</code>","text":"(<code>Literal['threaded', 'simple']</code>, default:                   <code>'threaded'</code> )           \u2013            <p>The backend to use for downloading data. Currently, only \"threaded\" is supported. Defaults to \"threaded\".</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre> <p>Check if the datacube already exists in the storage.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.is_temporal","title":"is_temporal  <code>property</code>","text":"<pre><code>is_temporal: bool\n</code></pre> <p>Check if the datacube has a temporal dimension.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube has a temporal dimension.</p> </li> </ul>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.adjacent_patches","title":"adjacent_patches","text":"<pre><code>adjacent_patches(\n    roi: Geometry | GeoBox | GeoDataFrame, toi: TOI | None\n) -&gt; list[PatchIndex[Item]]\n</code></pre> <p>Get the adjacent patches for the given geobox.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[PatchIndex[Item]]</code>           \u2013            <p>list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the ROI type is invalid.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def adjacent_patches(self, roi: Geometry | GeoBox | gpd.GeoDataFrame, toi: TOI | None) -&gt; list[PatchIndex[\"Item\"]]:\n    \"\"\"Get the adjacent patches for the given geobox.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        roi (Geometry | GeoBox | gpd.GeoDataFrame): The reference geometry, geobox or reference geodataframe\n        toi (TOI): The time of interest to download.\n\n    Returns:\n        list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.\n\n    Raises:\n        ValueError: If the ROI type is invalid.\n\n    \"\"\"\n    import pystac_client\n\n    if self.is_temporal:\n        toi = extract_toi_range(self.temporal_extent, toi)\n\n    catalog = pystac_client.Client.open(self.stac_api_url)\n    if isinstance(roi, gpd.GeoDataFrame):\n        geom = roi\n    elif isinstance(roi, GeoBox):\n        geom = roi.to_crs(\"EPSG:4326\").extent.geom\n    elif isinstance(roi, Geometry):\n        geom = roi.to_crs(\"EPSG:4326\").geom\n    else:\n        raise ValueError(\"Invalid ROI type.\")\n\n    search = catalog.search(collections=[self.collection], intersects=geom, datetime=toi)\n    items = list(search.items())\n\n    patch_idxs = []\n    for item in items:\n        geom = Geometry(item.geometry, crs=\"EPSG:4326\")\n        if self.is_temporal:\n            if item.datetime is not None:\n                idx = PatchIndex(item.id, geom, item.datetime, item)\n            else:\n                idx = PatchIndex(\n                    item.id, geom, (item.common_metadata.start_datetime, item.common_metadata.end_datetime), item\n                )\n        else:\n            idx = PatchIndex(item.id, geom, None, item)\n        patch_idxs.append(idx)\n    return patch_idxs\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.adjacent_patches(roi)","title":"<code>roi</code>","text":"(<code>Geometry | GeoBox | GeoDataFrame</code>)           \u2013            <p>The reference geometry, geobox or reference geodataframe</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.adjacent_patches(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\"\"\"\n    self.backend.assert_created()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.assert_temporal_cube","title":"assert_temporal_cube","text":"<pre><code>assert_temporal_cube()\n</code></pre> <p>Assert that the datacube has a temporal dimension.</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube has no temporal dimension.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_temporal_cube(self):\n    \"\"\"Assert that the datacube has a temporal dimension.\n\n    Raises:\n        ValueError: If the datacube has no temporal dimension.\n\n    \"\"\"\n    if self.temporal_extent is None:\n        msg = f\"Datacube {self.title} has no temporal dimension.\"\n        logger.error(msg)\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.create","title":"create","text":"<pre><code>create(overwrite: bool = False, exists_ok: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location and exists_ok is False.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def create(self, overwrite: bool = False, exists_ok: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube.\n            Has no effect if exists_ok is True. Defaults to False.\n        exists_ok (bool, optional): Do not raise an error if the datacube already exists.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location and exists_ok is False.\n\n    \"\"\"\n    if exists_ok and self.created:\n        logger.debug(\"Datacube was already created.\")\n        return\n\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Expand to temporal dimension if defined\n        if self.temporal_extent is not None:\n            ds = ds.expand_dims(time=self.temporal_extent)\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        if self.temporal_extent is not None:\n            coords_encoding[\"time\"] = {\"chunks\": ds.time.shape, **optimize_temporal_encoding(self.temporal_extent)}\n        chunks = (\n            (1, self.chunk_size, self.chunk_size)\n            if self.temporal_extent is not None\n            else (self.chunk_size, self.chunk_size)\n        )\n        var_encoding = {\n            name: {\n                \"chunks\": chunks,\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Has no effect if exists_ok is True. Defaults to False.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.create(exists_ok)","title":"<code>exists_ok</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Do not raise an error if the datacube already exists.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.\n\n    \"\"\"\n    import geopandas as gpd\n    import pystac_client\n\n    if not self.created:\n        return None\n\n    loaded_patches = self.loaded_patches()\n\n    if len(loaded_patches) == 0:\n        return None\n\n    catalog = pystac_client.Client.open(self.stac_api_url)\n    search = catalog.search(collections=[self.collection], ids=loaded_patches)\n    stac_json = search.item_collection_as_dict()\n\n    gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.download_patch","title":"download_patch","text":"<pre><code>download_patch(idx: PatchIndex[Item]) -&gt; xr.Dataset\n</code></pre> <p>Download the data for the given patch.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded patch data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def download_patch(self, idx: PatchIndex[\"Item\"]) -&gt; xr.Dataset:\n    \"\"\"Download the data for the given patch.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        idx (PatchIndex[Item]): The reference patch to download the data for.\n\n    Returns:\n        xr.Dataset: The downloaded patch data.\n\n    \"\"\"\n    from odc.stac import stac_load\n\n    patch = stac_load([idx.item], bands=self.channels, chunks=None, progress=None)\n\n    # Do a mosaic if multiple items are returned for non-temporal data\n    if \"time\" in patch.dims and self.temporal_extent is None:\n        patch = patch.max(\"time\")\n\n    return patch\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.download_patch(idx)","title":"<code>idx</code>","text":"(<code>PatchIndex[Item]</code>)           \u2013            <p>The reference patch to download the data for.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.load","title":"load","text":"<pre><code>load(\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load(\n    self,\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        aoi (Geometry | GeoBox): The reference geometry to load the data for. If a Geobox is provided,\n            it will use the extent of the geobox.\n        toi (TOI): The temporal slice to load. Defaults to None.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    if toi is not None:\n        self.assert_temporal_cube()\n\n    if isinstance(aoi, GeoBox):\n        aoi = aoi.extent\n\n    with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        aligned_aoi = aoi.to_crs(self.extent.crs)\n        with self.stopuhr(f\"{_geometry_repr(aoi)}: Procedural download in blocking mode\"):\n            self.procedural_download(aligned_aoi, toi)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get temporal slice if time is provided\n        if toi is not None:\n            xrcube = xrcube.sel(time=toi)\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(aligned_aoi, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.load(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry | GeoBox</code>)           \u2013            <p>The reference geometry to load the data for. If a Geobox is provided, it will use the extent of the geobox.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.load(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>, default:                   <code>None</code> )           \u2013            <p>The temporal slice to load. Defaults to None.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    toi = None\n    if \"time\" in ref.coords and self.temporal_extent is not None:\n        toi = ref.get_index(\"time\")\n    return self.load(ref.geobox, toi=toi, **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.loaded_patches","title":"loaded_patches","text":"<pre><code>loaded_patches() -&gt; list[str]\n</code></pre> <p>Get the ids of already (down-)loaded patches.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>list[str]: A list of already loaded patch ids.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def loaded_patches(self) -&gt; list[str]:\n    \"\"\"Get the ids of already (down-)loaded patches.\n\n    Returns:\n        list[str]: A list of already loaded patch ids.\n\n    \"\"\"\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube.attrs.get(\"loaded_patches\", []).copy()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    return self.backend.open_xarray()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    return self.backend.open_zarr()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Post create actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_create(self):\n    \"\"\"Post create actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.post_init","title":"post_init","text":"<pre><code>post_init()\n</code></pre> <p>Post init actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_init(self):\n    \"\"\"Post init actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(aoi: Geometry, toi: TOI)\n</code></pre> <p>Download tiles procedurally.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If not all downloads were successful.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def procedural_download(self, aoi: Geometry, toi: TOI):\n    \"\"\"Download tiles procedurally.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        aoi (Geometry): The geometry of the aoi to download.\n        toi (TOI): The time of interest to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If not all downloads were successful.\n\n    \"\"\"\n    adjacent_patches = self.adjacent_patches(aoi, toi)\n    # interest-string\n    soi = f\"{_geometry_repr(aoi)}\" + (f\" @ {_repr_toi(toi)}\" if toi is not None else \"\")\n    if not adjacent_patches:\n        logger.error(f\"{soi}: No adjacent patches found: {adjacent_patches=}\")\n        raise ValueError(\"No adjacent patches found - is the provided aoi and toi correct?\")\n\n    loaded_patches = self.loaded_patches()\n\n    new_patches = [patch for patch in adjacent_patches if patch.id not in loaded_patches]\n\n    logger.debug(f\"{soi}:  {len(adjacent_patches)=} &amp; {len(loaded_patches)=} -&gt; {len(new_patches)=} to download\")\n    if not new_patches:\n        return\n\n    # This raises Errors if anything goes wrong -&gt; we want to propagate\n    self.backend.submit(new_patches)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.procedural_download(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry</code>)           \u2013            <p>The geometry of the aoi to download.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.procedural_download(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.visualize_state","title":"visualize_state  <code>abstractmethod</code>","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize currently stored tiles / chunk.</p> <p>Must be implemented by the DatasetAccessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>@abstractmethod\ndef visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize currently stored tiles / chunk.\n\n    Must be implemented by the DatasetAccessor.\n\n    Args:\n        ax (plt.Axes | None, optional): The axes drawn to. If None, will create a new figure and axes.\n            Defaults to None.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization\n\n    \"\"\"\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes. Defaults to None.</p>"},{"location":"reference/smart_geocubes/accessors/gee/","title":"gee","text":""},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee","title":"smart_geocubes.accessors.gee","text":"<p>Google Earth Engine Accessor for Smart Geocubes.</p> <p>Classes:</p> <ul> <li> <code>GEEMosaicAccessor</code>           \u2013            <p>Accessor for Google Earth Engine data using mosaics.</p> </li> <li> <code>Item</code>           \u2013            <p>Simple wrapper over what accessor returns as item.</p> </li> </ul>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor","title":"GEEMosaicAccessor","text":"<pre><code>GEEMosaicAccessor(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n)\n</code></pre> <p>               Bases: <code>RemoteAccessor</code></p> <p>Accessor for Google Earth Engine data using mosaics.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the underlaying zarr array. Should be equal to the extent geobox. However, this property is used to find the target index of the downloaded data, so better save than sorry.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_patches</code>             \u2013              <p>Get the adjacent patches for the given geobox.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>assert_temporal_cube</code>             \u2013              <p>Assert that the datacube has a temporal dimension.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_patch</code>             \u2013              <p>Download the data for the given patch.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>loaded_patches</code>             \u2013              <p>Get the ids of already (down-)loaded patches.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Post create actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>post_init</code>             \u2013              <p>Post init actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download tiles procedurally.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize currently stored tiles / chunk.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n        backend (Literal[\"threaded\", \"simple\"], optional): The backend to use for downloading data.\n            Currently, only \"threaded\" is supported. Defaults to \"threaded\".\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = Chronometer(logger.debug)\n\n    if backend == \"threaded\":\n        if not _check_python_version(3, 13):\n            raise NotImplementedError(\n                \"The 'threaded' backend is only fully supported in Python 3.13 and above.\"\n                \" Please consider using the 'simple' backend in a multiprocessing environment\"\n                \" or upgrade your Python version.\"\n            )\n        self.backend = ThreadedBackend(self.repo, self.download_patch)\n    elif backend == \"simple\":\n        self.backend = SimpleBackend(self.repo, self.download_patch)\n    else:\n        raise ValueError(f\"Unknown backend {backend}\")\n\n    self.post_init()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor(backend)","title":"<code>backend</code>","text":"(<code>Literal['threaded', 'simple']</code>, default:                   <code>'threaded'</code> )           \u2013            <p>The backend to use for downloading data. Currently, only \"threaded\" is supported. Defaults to \"threaded\".</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre> <p>Check if the datacube already exists in the storage.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.is_temporal","title":"is_temporal  <code>property</code>","text":"<pre><code>is_temporal: bool\n</code></pre> <p>Check if the datacube has a temporal dimension.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube has a temporal dimension.</p> </li> </ul>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.adjacent_patches","title":"adjacent_patches","text":"<pre><code>adjacent_patches(\n    roi: Geometry | GeoBox | GeoDataFrame, toi: TOI\n) -&gt; list[Item]\n</code></pre> <p>Get the adjacent patches for the given geobox.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[Item]</code>           \u2013            <p>list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the ROI type is invalid.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If the datacube is not temporal, but a time of interest is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def adjacent_patches(self, roi: Geometry | GeoBox | gpd.GeoDataFrame, toi: TOI) -&gt; list[Item]:\n    \"\"\"Get the adjacent patches for the given geobox.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        roi (Geometry | GeoBox | gpd.GeoDataFrame): The reference geometry, geobox or reference geodataframe\n        toi (TOI): The time of interest to download.\n\n    Returns:\n        list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.\n\n    Raises:\n        ValueError: If the ROI type is invalid.\n        ValueError: If the datacube is not temporal, but a time of interest is provided.\n\n    \"\"\"\n    if toi is not None and not self.is_temporal:\n        raise ValueError(\"Datacube is not temporal, but time of interest is provided.\")\n\n    if isinstance(roi, gpd.GeoDataFrame):\n        adjacent_geometries = (\n            gpd.sjoin(self._tile_geometries, roi.to_crs(self.extent.crs.wkt), how=\"inner\", predicate=\"intersects\")\n            .reset_index()\n            .drop_duplicates(subset=\"index\", keep=\"first\")\n            .set_index(\"index\")\n        )\n        spatial_idxs: list[tuple[int, int]] = list(adjacent_geometries[\"idx\"])\n    elif isinstance(roi, GeoBox):\n        spatial_idxs: list[tuple[int, int]] = list(self._extent_tiles.tiles(roi.extent))\n    elif isinstance(roi, Geometry):\n        spatial_idxs: list[tuple[int, int]] = list(self._extent_tiles.tiles(roi))\n    else:\n        raise ValueError(\"Invalid ROI type.\")\n\n    if not self.is_temporal:\n        return [\n            PatchIndex(\n                self._stringify_index(spatial_idx),\n                self._extent_tiles[spatial_idx].geographic_extent,\n                None,\n                Item(self._extent_tiles[spatial_idx], None),\n            )\n            for spatial_idx in spatial_idxs\n        ]\n\n    # Now datacube is temporal\n    toi = normalize_toi(self.temporal_extent, toi)\n    patch_idxs = []\n    for time in toi:\n        time_idx = self.temporal_extent.get_loc(time)\n        assert isinstance(time_idx, int), \"Non-Unique temporal extents are not supported!\"\n        for spatial_idx in spatial_idxs:\n            patch_idxs.append(\n                PatchIndex(\n                    self._stringify_index(spatial_idx, time_idx),\n                    self._extent_tiles[spatial_idx].geographic_extent,\n                    time,\n                    Item(self._extent_tiles[spatial_idx], time),\n                )\n            )\n    return patch_idxs\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.adjacent_patches(roi)","title":"<code>roi</code>","text":"(<code>Geometry | GeoBox | GeoDataFrame</code>)           \u2013            <p>The reference geometry, geobox or reference geodataframe</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.adjacent_patches(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\"\"\"\n    self.backend.assert_created()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.assert_temporal_cube","title":"assert_temporal_cube","text":"<pre><code>assert_temporal_cube()\n</code></pre> <p>Assert that the datacube has a temporal dimension.</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube has no temporal dimension.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_temporal_cube(self):\n    \"\"\"Assert that the datacube has a temporal dimension.\n\n    Raises:\n        ValueError: If the datacube has no temporal dimension.\n\n    \"\"\"\n    if self.temporal_extent is None:\n        msg = f\"Datacube {self.title} has no temporal dimension.\"\n        logger.error(msg)\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.create","title":"create","text":"<pre><code>create(overwrite: bool = False, exists_ok: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location and exists_ok is False.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def create(self, overwrite: bool = False, exists_ok: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube.\n            Has no effect if exists_ok is True. Defaults to False.\n        exists_ok (bool, optional): Do not raise an error if the datacube already exists.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location and exists_ok is False.\n\n    \"\"\"\n    if exists_ok and self.created:\n        logger.debug(\"Datacube was already created.\")\n        return\n\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Expand to temporal dimension if defined\n        if self.temporal_extent is not None:\n            ds = ds.expand_dims(time=self.temporal_extent)\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        if self.temporal_extent is not None:\n            coords_encoding[\"time\"] = {\"chunks\": ds.time.shape, **optimize_temporal_encoding(self.temporal_extent)}\n        chunks = (\n            (1, self.chunk_size, self.chunk_size)\n            if self.temporal_extent is not None\n            else (self.chunk_size, self.chunk_size)\n        )\n        var_encoding = {\n            name: {\n                \"chunks\": chunks,\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Has no effect if exists_ok is True. Defaults to False.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.create(exists_ok)","title":"<code>exists_ok</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Do not raise an error if the datacube already exists.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.\n\n    \"\"\"\n    import geopandas as gpd\n\n    if not self.created:\n        return None\n\n    loaded_patches = self.loaded_patches()\n\n    if len(loaded_patches) == 0:\n        return None\n\n    patch_infos = []\n    for pid in loaded_patches:\n        spatial_idx, temporal_idx = self._parse_index(pid)\n        geometry = self._extent_tiles[spatial_idx].extent.geom\n        if self.is_temporal:\n            time = self.temporal_extent[temporal_idx]\n            patch_infos.append({\"geometry\": geometry, \"id\": pid, \"time\": time})\n        else:\n            patch_infos.append({\"geometry\": geometry, \"id\": pid})\n\n    gdf = gpd.GeoDataFrame(patch_infos, crs=self.extent.crs.to_wkt())\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.download_patch","title":"download_patch","text":"<pre><code>download_patch(idx: PatchIndex[Item]) -&gt; xr.Dataset\n</code></pre> <p>Download the data for the given patch.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded patch data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def download_patch(self, idx: PatchIndex[Item]) -&gt; xr.Dataset:\n    \"\"\"Download the data for the given patch.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        idx (PatchIndex[Item]): The reference patch to download the data for.\n\n    Returns:\n        xr.Dataset: The downloaded patch data.\n\n    \"\"\"\n    import ee\n    import rioxarray  # noqa: F401\n    import xee  # noqa: F401\n\n    # Note: This is a little bit weird: First we create an own grid which overlaps to the chunks\n    # of the zarr array. Then we create a mosaic of the data and clip it to a single chunk.\n    # We could load the images from the collection directly instead of creating a mosaic.\n    # However, this would require more testing and probably results a lot of manual computation\n    # of slices etc. like in the stac variant. So for now, we just use the mosaic.\n    logging.getLogger(\"urllib3.connectionpool\").disabled = True\n\n    ee_col = ee.ImageCollection(self.collection)\n    if self.is_temporal:\n        ee_col = ee_col.filterDate(idx.item.time)\n    geom = ee.Geometry.Rectangle(idx.item.geobox.geographic_extent.boundingbox)\n    ee_img = ee_col.mosaic().clip(geom)\n\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=UserWarning, message=EE_WARN_MSG)\n        patch = xr.open_dataset(\n            ee_img,\n            engine=\"ee\",\n            geometry=geom,\n            crs=f\"epsg:{self.extent.crs.to_epsg()}\",\n            scale=self.extent.resolution.x,\n        )\n\n    # Do a mosaic if time axis are returned for non-temporal data\n    if \"time\" in patch.dims and not self.is_temporal:\n        patch = patch.max(\"time\")\n\n    patch = patch.rename({\"lon\": \"x\", \"lat\": \"y\"})\n    if \"time\" in patch.dims:\n        patch[\"time\"] = [idx.item.time]\n        patch = patch.transpose(\"time\", \"y\", \"x\")\n    else:\n        patch = patch.transpose(\"y\", \"x\")\n\n    # Download the data\n    logger.debug(f\"{idx.id=}: Trigger GEE download)\")\n    patch.load()\n    logger.debug(f\"{idx.id=}: Finished GEE download\")\n    logging.getLogger(\"urllib3.connectionpool\").disabled = False\n\n    # Flip y-axis, because convention is x in positive direction and y in negative, but gee use positive for both\n    patch = patch.isel(y=slice(None, None, -1))\n\n    # For some reason xee does not always set the crs\n    patch = patch.odc.assign_crs(self.extent.crs)\n\n    # Recrop the data to the tile, since gee does not always return the exact extent\n    patch = patch.odc.crop(idx.item.geobox.extent)\n\n    return patch\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.download_patch(idx)","title":"<code>idx</code>","text":"(<code>PatchIndex[Item]</code>)           \u2013            <p>The reference patch to download the data for.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.load","title":"load","text":"<pre><code>load(\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load(\n    self,\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        aoi (Geometry | GeoBox): The reference geometry to load the data for. If a Geobox is provided,\n            it will use the extent of the geobox.\n        toi (TOI): The temporal slice to load. Defaults to None.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    if toi is not None:\n        self.assert_temporal_cube()\n\n    if isinstance(aoi, GeoBox):\n        aoi = aoi.extent\n\n    with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        aligned_aoi = aoi.to_crs(self.extent.crs)\n        with self.stopuhr(f\"{_geometry_repr(aoi)}: Procedural download in blocking mode\"):\n            self.procedural_download(aligned_aoi, toi)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get temporal slice if time is provided\n        if toi is not None:\n            xrcube = xrcube.sel(time=toi)\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(aligned_aoi, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.load(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry | GeoBox</code>)           \u2013            <p>The reference geometry to load the data for. If a Geobox is provided, it will use the extent of the geobox.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.load(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>, default:                   <code>None</code> )           \u2013            <p>The temporal slice to load. Defaults to None.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    toi = None\n    if \"time\" in ref.coords and self.temporal_extent is not None:\n        toi = ref.get_index(\"time\")\n    return self.load(ref.geobox, toi=toi, **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.loaded_patches","title":"loaded_patches","text":"<pre><code>loaded_patches() -&gt; list[str]\n</code></pre> <p>Get the ids of already (down-)loaded patches.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>list[str]: A list of already loaded patch ids.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def loaded_patches(self) -&gt; list[str]:\n    \"\"\"Get the ids of already (down-)loaded patches.\n\n    Returns:\n        list[str]: A list of already loaded patch ids.\n\n    \"\"\"\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube.attrs.get(\"loaded_patches\", []).copy()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    return self.backend.open_xarray()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    return self.backend.open_zarr()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Post create actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_create(self):\n    \"\"\"Post create actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.post_init","title":"post_init","text":"<pre><code>post_init()\n</code></pre> <p>Post init actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_init(self):\n    \"\"\"Post init actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(aoi: Geometry, toi: TOI)\n</code></pre> <p>Download tiles procedurally.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If not all downloads were successful.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def procedural_download(self, aoi: Geometry, toi: TOI):\n    \"\"\"Download tiles procedurally.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        aoi (Geometry): The geometry of the aoi to download.\n        toi (TOI): The time of interest to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If not all downloads were successful.\n\n    \"\"\"\n    adjacent_patches = self.adjacent_patches(aoi, toi)\n    # interest-string\n    soi = f\"{_geometry_repr(aoi)}\" + (f\" @ {_repr_toi(toi)}\" if toi is not None else \"\")\n    if not adjacent_patches:\n        logger.error(f\"{soi}: No adjacent patches found: {adjacent_patches=}\")\n        raise ValueError(\"No adjacent patches found - is the provided aoi and toi correct?\")\n\n    loaded_patches = self.loaded_patches()\n\n    new_patches = [patch for patch in adjacent_patches if patch.id not in loaded_patches]\n\n    logger.debug(f\"{soi}:  {len(adjacent_patches)=} &amp; {len(loaded_patches)=} -&gt; {len(new_patches)=} to download\")\n    if not new_patches:\n        return\n\n    # This raises Errors if anything goes wrong -&gt; we want to propagate\n    self.backend.submit(new_patches)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.procedural_download(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry</code>)           \u2013            <p>The geometry of the aoi to download.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.procedural_download(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.visualize_state","title":"visualize_state  <code>abstractmethod</code>","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize currently stored tiles / chunk.</p> <p>Must be implemented by the DatasetAccessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>@abstractmethod\ndef visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize currently stored tiles / chunk.\n\n    Must be implemented by the DatasetAccessor.\n\n    Args:\n        ax (plt.Axes | None, optional): The axes drawn to. If None, will create a new figure and axes.\n            Defaults to None.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization\n\n    \"\"\"\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEMosaicAccessor.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes. Defaults to None.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.Item","title":"Item  <code>dataclass</code>","text":"<pre><code>Item(geobox: GeoBox, time: Timestamp | None = None)\n</code></pre> <p>Simple wrapper over what accessor returns as item.</p>"},{"location":"reference/smart_geocubes/accessors/stac/","title":"stac","text":""},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac","title":"smart_geocubes.accessors.stac","text":"<p>STAC Accessor for Smart Geocubes.</p> <p>Classes:</p> <ul> <li> <code>STACAccessor</code>           \u2013            <p>Accessor for STAC data.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>correct_bounds</code>             \u2013              <p>Correct the bounds of a tile to fit within a GeoBox.</p> </li> </ul>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor","title":"STACAccessor","text":"<pre><code>STACAccessor(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n)\n</code></pre> <p>               Bases: <code>RemoteAccessor</code></p> <p>Accessor for STAC data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the underlaying zarr array. Should be equal to the extent geobox. However, this property is used to find the target index of the downloaded data, so better save than sorry.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_patches</code>             \u2013              <p>Get the adjacent patches for the given geobox.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>assert_temporal_cube</code>             \u2013              <p>Assert that the datacube has a temporal dimension.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_patch</code>             \u2013              <p>Download the data for the given patch.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>loaded_patches</code>             \u2013              <p>Get the ids of already (down-)loaded patches.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Post create actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>post_init</code>             \u2013              <p>Post init actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download tiles procedurally.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize currently stored tiles / chunk.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n        backend (Literal[\"threaded\", \"simple\"], optional): The backend to use for downloading data.\n            Currently, only \"threaded\" is supported. Defaults to \"threaded\".\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = Chronometer(logger.debug)\n\n    if backend == \"threaded\":\n        if not _check_python_version(3, 13):\n            raise NotImplementedError(\n                \"The 'threaded' backend is only fully supported in Python 3.13 and above.\"\n                \" Please consider using the 'simple' backend in a multiprocessing environment\"\n                \" or upgrade your Python version.\"\n            )\n        self.backend = ThreadedBackend(self.repo, self.download_patch)\n    elif backend == \"simple\":\n        self.backend = SimpleBackend(self.repo, self.download_patch)\n    else:\n        raise ValueError(f\"Unknown backend {backend}\")\n\n    self.post_init()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor(backend)","title":"<code>backend</code>","text":"(<code>Literal['threaded', 'simple']</code>, default:                   <code>'threaded'</code> )           \u2013            <p>The backend to use for downloading data. Currently, only \"threaded\" is supported. Defaults to \"threaded\".</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre> <p>Check if the datacube already exists in the storage.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.is_temporal","title":"is_temporal  <code>property</code>","text":"<pre><code>is_temporal: bool\n</code></pre> <p>Check if the datacube has a temporal dimension.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube has a temporal dimension.</p> </li> </ul>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.adjacent_patches","title":"adjacent_patches","text":"<pre><code>adjacent_patches(\n    roi: Geometry | GeoBox | GeoDataFrame, toi: TOI | None\n) -&gt; list[PatchIndex[Item]]\n</code></pre> <p>Get the adjacent patches for the given geobox.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[PatchIndex[Item]]</code>           \u2013            <p>list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the ROI type is invalid.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def adjacent_patches(self, roi: Geometry | GeoBox | gpd.GeoDataFrame, toi: TOI | None) -&gt; list[PatchIndex[\"Item\"]]:\n    \"\"\"Get the adjacent patches for the given geobox.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        roi (Geometry | GeoBox | gpd.GeoDataFrame): The reference geometry, geobox or reference geodataframe\n        toi (TOI): The time of interest to download.\n\n    Returns:\n        list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.\n\n    Raises:\n        ValueError: If the ROI type is invalid.\n\n    \"\"\"\n    import pystac_client\n\n    if self.is_temporal:\n        toi = extract_toi_range(self.temporal_extent, toi)\n\n    catalog = pystac_client.Client.open(self.stac_api_url)\n    if isinstance(roi, gpd.GeoDataFrame):\n        geom = roi\n    elif isinstance(roi, GeoBox):\n        geom = roi.to_crs(\"EPSG:4326\").extent.geom\n    elif isinstance(roi, Geometry):\n        geom = roi.to_crs(\"EPSG:4326\").geom\n    else:\n        raise ValueError(\"Invalid ROI type.\")\n\n    search = catalog.search(collections=[self.collection], intersects=geom, datetime=toi)\n    items = list(search.items())\n\n    patch_idxs = []\n    for item in items:\n        geom = Geometry(item.geometry, crs=\"EPSG:4326\")\n        if self.is_temporal:\n            if item.datetime is not None:\n                idx = PatchIndex(item.id, geom, item.datetime, item)\n            else:\n                idx = PatchIndex(\n                    item.id, geom, (item.common_metadata.start_datetime, item.common_metadata.end_datetime), item\n                )\n        else:\n            idx = PatchIndex(item.id, geom, None, item)\n        patch_idxs.append(idx)\n    return patch_idxs\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.adjacent_patches(roi)","title":"<code>roi</code>","text":"(<code>Geometry | GeoBox | GeoDataFrame</code>)           \u2013            <p>The reference geometry, geobox or reference geodataframe</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.adjacent_patches(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\"\"\"\n    self.backend.assert_created()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.assert_temporal_cube","title":"assert_temporal_cube","text":"<pre><code>assert_temporal_cube()\n</code></pre> <p>Assert that the datacube has a temporal dimension.</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube has no temporal dimension.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_temporal_cube(self):\n    \"\"\"Assert that the datacube has a temporal dimension.\n\n    Raises:\n        ValueError: If the datacube has no temporal dimension.\n\n    \"\"\"\n    if self.temporal_extent is None:\n        msg = f\"Datacube {self.title} has no temporal dimension.\"\n        logger.error(msg)\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.create","title":"create","text":"<pre><code>create(overwrite: bool = False, exists_ok: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location and exists_ok is False.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def create(self, overwrite: bool = False, exists_ok: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube.\n            Has no effect if exists_ok is True. Defaults to False.\n        exists_ok (bool, optional): Do not raise an error if the datacube already exists.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location and exists_ok is False.\n\n    \"\"\"\n    if exists_ok and self.created:\n        logger.debug(\"Datacube was already created.\")\n        return\n\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Expand to temporal dimension if defined\n        if self.temporal_extent is not None:\n            ds = ds.expand_dims(time=self.temporal_extent)\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        if self.temporal_extent is not None:\n            coords_encoding[\"time\"] = {\"chunks\": ds.time.shape, **optimize_temporal_encoding(self.temporal_extent)}\n        chunks = (\n            (1, self.chunk_size, self.chunk_size)\n            if self.temporal_extent is not None\n            else (self.chunk_size, self.chunk_size)\n        )\n        var_encoding = {\n            name: {\n                \"chunks\": chunks,\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Has no effect if exists_ok is True. Defaults to False.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.create(exists_ok)","title":"<code>exists_ok</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Do not raise an error if the datacube already exists.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.\n\n    \"\"\"\n    import geopandas as gpd\n    import pystac_client\n\n    if not self.created:\n        return None\n\n    loaded_patches = self.loaded_patches()\n\n    if len(loaded_patches) == 0:\n        return None\n\n    catalog = pystac_client.Client.open(self.stac_api_url)\n    search = catalog.search(collections=[self.collection], ids=loaded_patches)\n    stac_json = search.item_collection_as_dict()\n\n    gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.download_patch","title":"download_patch","text":"<pre><code>download_patch(idx: PatchIndex[Item]) -&gt; xr.Dataset\n</code></pre> <p>Download the data for the given patch.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded patch data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def download_patch(self, idx: PatchIndex[\"Item\"]) -&gt; xr.Dataset:\n    \"\"\"Download the data for the given patch.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        idx (PatchIndex[Item]): The reference patch to download the data for.\n\n    Returns:\n        xr.Dataset: The downloaded patch data.\n\n    \"\"\"\n    from odc.stac import stac_load\n\n    patch = stac_load([idx.item], bands=self.channels, chunks=None, progress=None)\n\n    # Do a mosaic if multiple items are returned for non-temporal data\n    if \"time\" in patch.dims and self.temporal_extent is None:\n        patch = patch.max(\"time\")\n\n    return patch\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.download_patch(idx)","title":"<code>idx</code>","text":"(<code>PatchIndex[Item]</code>)           \u2013            <p>The reference patch to download the data for.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.load","title":"load","text":"<pre><code>load(\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load(\n    self,\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        aoi (Geometry | GeoBox): The reference geometry to load the data for. If a Geobox is provided,\n            it will use the extent of the geobox.\n        toi (TOI): The temporal slice to load. Defaults to None.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    if toi is not None:\n        self.assert_temporal_cube()\n\n    if isinstance(aoi, GeoBox):\n        aoi = aoi.extent\n\n    with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        aligned_aoi = aoi.to_crs(self.extent.crs)\n        with self.stopuhr(f\"{_geometry_repr(aoi)}: Procedural download in blocking mode\"):\n            self.procedural_download(aligned_aoi, toi)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get temporal slice if time is provided\n        if toi is not None:\n            xrcube = xrcube.sel(time=toi)\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(aligned_aoi, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.load(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry | GeoBox</code>)           \u2013            <p>The reference geometry to load the data for. If a Geobox is provided, it will use the extent of the geobox.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.load(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>, default:                   <code>None</code> )           \u2013            <p>The temporal slice to load. Defaults to None.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    toi = None\n    if \"time\" in ref.coords and self.temporal_extent is not None:\n        toi = ref.get_index(\"time\")\n    return self.load(ref.geobox, toi=toi, **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.loaded_patches","title":"loaded_patches","text":"<pre><code>loaded_patches() -&gt; list[str]\n</code></pre> <p>Get the ids of already (down-)loaded patches.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>list[str]: A list of already loaded patch ids.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def loaded_patches(self) -&gt; list[str]:\n    \"\"\"Get the ids of already (down-)loaded patches.\n\n    Returns:\n        list[str]: A list of already loaded patch ids.\n\n    \"\"\"\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube.attrs.get(\"loaded_patches\", []).copy()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    return self.backend.open_xarray()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    return self.backend.open_zarr()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Post create actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_create(self):\n    \"\"\"Post create actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.post_init","title":"post_init","text":"<pre><code>post_init()\n</code></pre> <p>Post init actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_init(self):\n    \"\"\"Post init actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(aoi: Geometry, toi: TOI)\n</code></pre> <p>Download tiles procedurally.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If not all downloads were successful.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def procedural_download(self, aoi: Geometry, toi: TOI):\n    \"\"\"Download tiles procedurally.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        aoi (Geometry): The geometry of the aoi to download.\n        toi (TOI): The time of interest to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If not all downloads were successful.\n\n    \"\"\"\n    adjacent_patches = self.adjacent_patches(aoi, toi)\n    # interest-string\n    soi = f\"{_geometry_repr(aoi)}\" + (f\" @ {_repr_toi(toi)}\" if toi is not None else \"\")\n    if not adjacent_patches:\n        logger.error(f\"{soi}: No adjacent patches found: {adjacent_patches=}\")\n        raise ValueError(\"No adjacent patches found - is the provided aoi and toi correct?\")\n\n    loaded_patches = self.loaded_patches()\n\n    new_patches = [patch for patch in adjacent_patches if patch.id not in loaded_patches]\n\n    logger.debug(f\"{soi}:  {len(adjacent_patches)=} &amp; {len(loaded_patches)=} -&gt; {len(new_patches)=} to download\")\n    if not new_patches:\n        return\n\n    # This raises Errors if anything goes wrong -&gt; we want to propagate\n    self.backend.submit(new_patches)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.procedural_download(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry</code>)           \u2013            <p>The geometry of the aoi to download.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.procedural_download(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.visualize_state","title":"visualize_state  <code>abstractmethod</code>","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize currently stored tiles / chunk.</p> <p>Must be implemented by the DatasetAccessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>@abstractmethod\ndef visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize currently stored tiles / chunk.\n\n    Must be implemented by the DatasetAccessor.\n\n    Args:\n        ax (plt.Axes | None, optional): The axes drawn to. If None, will create a new figure and axes.\n            Defaults to None.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization\n\n    \"\"\"\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes. Defaults to None.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.correct_bounds","title":"correct_bounds","text":"<pre><code>correct_bounds(\n    tile: Dataset, zgeobox: GeoBox\n) -&gt; xr.Dataset\n</code></pre> <p>Correct the bounds of a tile to fit within a GeoBox.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the tile is out of the geobox's bounds.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The corrected tile.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def correct_bounds(tile: xr.Dataset, zgeobox: GeoBox) -&gt; xr.Dataset:\n    \"\"\"Correct the bounds of a tile to fit within a GeoBox.\n\n    Args:\n        tile (xr.Dataset): The tile to correct.\n        zgeobox (GeoBox): The GeoBox to correct the tile to.\n\n    Raises:\n        ValueError: If the tile is out of the geobox's bounds.\n\n    Returns:\n        xr.Dataset: The corrected tile.\n\n    \"\"\"\n    yslice, xslice = tile.odc.geobox.overlap_roi(zgeobox)\n    yslice_is_valid = yslice.start &gt;= 0 and yslice.start &lt; yslice.stop and yslice.stop &lt;= tile.sizes[\"y\"]\n    xslice_is_valid = xslice.start &gt;= 0 and xslice.start &lt; xslice.stop and xslice.stop &lt;= tile.sizes[\"x\"]\n    if not yslice_is_valid or not xslice_is_valid:\n        logger.error(f\"Tile is out of bounds! {yslice=} {xslice=} {tile.sizes=} {zgeobox=}\")\n        raise ValueError(\"Tile is out of bounds!\")\n    if yslice.start != 0 or xslice.start != 0 or yslice.stop != tile.sizes[\"y\"] or xslice.stop != tile.sizes[\"x\"]:\n        logger.warning(\n            f\"Correcting tile bounds. This is an indicator that the datacube extent is to narrow.\"\n            f\" This will crop the tile to fit the datacube. {yslice=} {xslice=} {tile.sizes=} {zgeobox=}\"\n        )\n        tile = tile.isel(x=xslice, y=yslice)\n    # TODO: do the same for time dimension\n    return tile\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.correct_bounds(tile)","title":"<code>tile</code>","text":"(<code>Dataset</code>)           \u2013            <p>The tile to correct.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.correct_bounds(zgeobox)","title":"<code>zgeobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The GeoBox to correct the tile to.</p>"},{"location":"reference/smart_geocubes/backends/","title":"backends","text":""},{"location":"reference/smart_geocubes/backends/#smart_geocubes.backends","title":"smart_geocubes.backends","text":"<p>Download backends for smart-geocubes.</p> <p>Modules:</p> <ul> <li> <code>simple</code>           \u2013            <p>Write specific backends.</p> </li> <li> <code>threaded</code>           \u2013            <p>Write specific backends.</p> </li> </ul>"},{"location":"reference/smart_geocubes/backends/simple/","title":"simple","text":""},{"location":"reference/smart_geocubes/backends/simple/#smart_geocubes.backends.simple","title":"smart_geocubes.backends.simple","text":"<p>Write specific backends.</p> <p>Classes:</p> <ul> <li> <code>SimpleBackend</code>           \u2013            <p>Simple, blocking backend for downloading patches.</p> </li> </ul>"},{"location":"reference/smart_geocubes/backends/simple/#smart_geocubes.backends.simple.SimpleBackend","title":"SimpleBackend","text":"<pre><code>SimpleBackend(\n    repo: Repository, f: Callable[[PatchIndex], Dataset]\n)\n</code></pre> <p>               Bases: <code>DownloadBackend</code></p> <p>Simple, blocking backend for downloading patches.</p> <p>Initialize the ThreadedBackend.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>close</code>             \u2013              <p>Close the backend.</p> </li> <li> <code>loaded_patches</code>             \u2013              <p>Get a list of all loaded patch ids.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>submit</code>             \u2013              <p>Submit a patch download request to the backend.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>Check if the datacube already exists in the storage.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/backend.py</code> <pre><code>def __init__(self, repo: icechunk.Repository, f: Callable[[PatchIndex], xr.Dataset]):\n    \"\"\"Initialize the ThreadedBackend.\n\n    Args:\n        repo (icechunk.Repository): The icechunk repository.\n        f (callable[[PatchIndex], xr.Dataset]): A function that takes a PatchIndex and returns an xr.Dataset.\n            This should be implemented by the specific source backend.\n\n    \"\"\"\n    self.repo = repo\n    self.download_from_source = f\n</code></pre>"},{"location":"reference/smart_geocubes/backends/simple/#smart_geocubes.backends.simple.SimpleBackend(repo)","title":"<code>repo</code>","text":"(<code>Repository</code>)           \u2013            <p>The icechunk repository.</p>"},{"location":"reference/smart_geocubes/backends/simple/#smart_geocubes.backends.simple.SimpleBackend(f)","title":"<code>f</code>","text":"(<code>callable[[PatchIndex], Dataset]</code>)           \u2013            <p>A function that takes a PatchIndex and returns an xr.Dataset. This should be implemented by the specific source backend.</p>"},{"location":"reference/smart_geocubes/backends/simple/#smart_geocubes.backends.simple.SimpleBackend.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre> <p>Check if the datacube already exists in the storage.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul>"},{"location":"reference/smart_geocubes/backends/simple/#smart_geocubes.backends.simple.SimpleBackend.assert_created","title":"assert_created","text":"<pre><code>assert_created(session: Session | None = None)\n</code></pre> <p>Assert that the datacube exists in the storage.</p> <p>Raises:</p> <ul> <li> <code>FileNotFoundError</code>             \u2013            <p>If the datacube does not exist.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/backend.py</code> <pre><code>def assert_created(self, session: icechunk.Session | None = None):\n    \"\"\"Assert that the datacube exists in the storage.\n\n    Raises:\n        FileNotFoundError: If the datacube does not exist.\n\n    \"\"\"\n    if session is None:\n        session = self.repo.readonly_session(\"main\")\n    if sync(session.store.is_empty(\"\")):\n        msg = \"Datacube does not exist.\"\n        \" Please use the `create` method or pass `create=True` to `load`.\"\n        logger.error(msg)\n        raise FileNotFoundError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/backends/simple/#smart_geocubes.backends.simple.SimpleBackend.close","title":"close","text":"<pre><code>close() -&gt; bool\n</code></pre> <p>Close the backend.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the backend was closed successfully, False otherwise.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/backend.py</code> <pre><code>def close(self) -&gt; bool:\n    \"\"\"Close the backend.\n\n    Returns:\n        bool: True if the backend was closed successfully, False otherwise.\n\n    \"\"\"\n    # Base implementation does nothing\n    return True\n</code></pre>"},{"location":"reference/smart_geocubes/backends/simple/#smart_geocubes.backends.simple.SimpleBackend.loaded_patches","title":"loaded_patches","text":"<pre><code>loaded_patches(session: Session | None = None) -&gt; list[str]\n</code></pre> <p>Get a list of all loaded patch ids.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>list[str]: A list of all loaded patch ids.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/backend.py</code> <pre><code>def loaded_patches(self, session: icechunk.Session | None = None) -&gt; list[str]:\n    \"\"\"Get a list of all loaded patch ids.\n\n    Returns:\n        list[str]: A list of all loaded patch ids.\n\n    \"\"\"\n    zcube = self.open_zarr(session)\n    loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n    return loaded_tiles\n</code></pre>"},{"location":"reference/smart_geocubes/backends/simple/#smart_geocubes.backends.simple.SimpleBackend.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray(session: Session | None = None) -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/backend.py</code> <pre><code>def open_xarray(self, session: icechunk.Session | None = None) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    if session is None:\n        session = self.repo.readonly_session(\"main\")\n    self.assert_created(session)\n    xcube = xr.open_zarr(session.store, mask_and_scale=False, consolidated=False).set_coords(\"spatial_ref\")\n    return xcube\n</code></pre>"},{"location":"reference/smart_geocubes/backends/simple/#smart_geocubes.backends.simple.SimpleBackend.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr(session: Session | None = None) -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/backend.py</code> <pre><code>def open_zarr(self, session: icechunk.Session | None = None) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    if session is None:\n        session = self.repo.readonly_session(\"main\")\n    self.assert_created(session)\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube\n</code></pre>"},{"location":"reference/smart_geocubes/backends/simple/#smart_geocubes.backends.simple.SimpleBackend.submit","title":"submit","text":"<pre><code>submit(idx: PatchIndex | list[PatchIndex])\n</code></pre> <p>Submit a patch download request to the backend.</p> <p>Parameters:</p> Source code in <code>src/smart_geocubes/backends/simple.py</code> <pre><code>def submit(self, idx: PatchIndex | list[PatchIndex]):\n    \"\"\"Submit a patch download request to the backend.\n\n    Args:\n        idx (PatchIndex | list[PatchIndex]): The index or multiple indices of the patch(es) to download.\n\n    \"\"\"\n    if isinstance(idx, PatchIndex):\n        idx = [idx]\n    for i in idx:\n        patch = self._download_from_source_with_retries(i)\n        self._write_patch(patch)\n</code></pre>"},{"location":"reference/smart_geocubes/backends/simple/#smart_geocubes.backends.simple.SimpleBackend.submit(idx)","title":"<code>idx</code>","text":"(<code>PatchIndex | list[PatchIndex]</code>)           \u2013            <p>The index or multiple indices of the patch(es) to download.</p>"},{"location":"reference/smart_geocubes/backends/threaded/","title":"threaded","text":""},{"location":"reference/smart_geocubes/backends/threaded/#smart_geocubes.backends.threaded","title":"smart_geocubes.backends.threaded","text":"<p>Write specific backends.</p> <p>Classes:</p> <ul> <li> <code>ThreadedBackend</code>           \u2013            <p>Threaded backend for downloading patches.</p> </li> </ul>"},{"location":"reference/smart_geocubes/backends/threaded/#smart_geocubes.backends.threaded.ThreadedBackend","title":"ThreadedBackend","text":"<pre><code>ThreadedBackend(\n    repo: Repository,\n    f: Callable[[PatchIndex], Dataset],\n    concurrent_downloads: int = 2,\n)\n</code></pre> <p>               Bases: <code>DownloadBackend</code></p> <p>Threaded backend for downloading patches.</p> <p>Initialize the ThreadedBackend.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>close</code>             \u2013              <p>Close the backend.</p> </li> <li> <code>loaded_patches</code>             \u2013              <p>Get a list of all loaded patch ids.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>submit</code>             \u2013              <p>Submit a patch download request to the backend.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>Check if the datacube already exists in the storage.</p> </li> </ul> Source code in <code>src/smart_geocubes/backends/threaded.py</code> <pre><code>def __init__(self, repo: icechunk.Repository, f: Callable[[PatchIndex], xr.Dataset], concurrent_downloads: int = 2):\n    \"\"\"Initialize the ThreadedBackend.\n\n    Args:\n        repo (icechunk.Repository): The icechunk repository.\n        f (callable[[PatchIndex], xr.Dataset]): A function that takes a PatchIndex and returns an xr.Dataset.\n            This should be implemented by the specific source backend.\n        concurrent_downloads (int, optional): The number of concurrent downloads. Defaults to 2.\n\n    \"\"\"\n    super().__init__(repo, f)\n\n    self.download_pool = ThreadPoolExecutor(max_workers=concurrent_downloads)\n\n    # The writer allows for asynchronous download and writing\n    # The writing_pool allows for concurrent writes within the writer thread\n    # The write_queue is blocking with a maxsize of 2 to prevent too many successful downloads\n    # from piling up in memory\n    self.writer = Thread(target=self._writer, daemon=True, name=\"WriterThread\")\n    self.write_queue: Queue[xr.Dataset] = Queue(maxsize=2)\n    self.writing_pool = ThreadPoolExecutor(max_workers=4)\n    self.writer.start()\n</code></pre>"},{"location":"reference/smart_geocubes/backends/threaded/#smart_geocubes.backends.threaded.ThreadedBackend(repo)","title":"<code>repo</code>","text":"(<code>Repository</code>)           \u2013            <p>The icechunk repository.</p>"},{"location":"reference/smart_geocubes/backends/threaded/#smart_geocubes.backends.threaded.ThreadedBackend(f)","title":"<code>f</code>","text":"(<code>callable[[PatchIndex], Dataset]</code>)           \u2013            <p>A function that takes a PatchIndex and returns an xr.Dataset. This should be implemented by the specific source backend.</p>"},{"location":"reference/smart_geocubes/backends/threaded/#smart_geocubes.backends.threaded.ThreadedBackend(concurrent_downloads)","title":"<code>concurrent_downloads</code>","text":"(<code>int</code>, default:                   <code>2</code> )           \u2013            <p>The number of concurrent downloads. Defaults to 2.</p>"},{"location":"reference/smart_geocubes/backends/threaded/#smart_geocubes.backends.threaded.ThreadedBackend.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre> <p>Check if the datacube already exists in the storage.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul>"},{"location":"reference/smart_geocubes/backends/threaded/#smart_geocubes.backends.threaded.ThreadedBackend.assert_created","title":"assert_created","text":"<pre><code>assert_created(session: Session | None = None)\n</code></pre> <p>Assert that the datacube exists in the storage.</p> <p>Raises:</p> <ul> <li> <code>FileNotFoundError</code>             \u2013            <p>If the datacube does not exist.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/backend.py</code> <pre><code>def assert_created(self, session: icechunk.Session | None = None):\n    \"\"\"Assert that the datacube exists in the storage.\n\n    Raises:\n        FileNotFoundError: If the datacube does not exist.\n\n    \"\"\"\n    if session is None:\n        session = self.repo.readonly_session(\"main\")\n    if sync(session.store.is_empty(\"\")):\n        msg = \"Datacube does not exist.\"\n        \" Please use the `create` method or pass `create=True` to `load`.\"\n        logger.error(msg)\n        raise FileNotFoundError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/backends/threaded/#smart_geocubes.backends.threaded.ThreadedBackend.close","title":"close","text":"<pre><code>close() -&gt; bool\n</code></pre> <p>Close the backend.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the backend was closed successfully, False otherwise.</p> </li> </ul> Source code in <code>src/smart_geocubes/backends/threaded.py</code> <pre><code>def close(self) -&gt; bool:\n    \"\"\"Close the backend.\n\n    Returns:\n        bool: True if the backend was closed successfully, False otherwise.\n\n    \"\"\"\n    logger.debug(\"Closing Backend...\")\n\n    self.download_pool.shutdown(wait=False, cancel_futures=True)\n    logger.debug(\"Download pool shut down.\")\n\n    self.write_queue.shutdown(immediate=True)\n    logger.debug(\"Write queue shut down.\")\n\n    self.writer.join()\n    logger.debug(\"Writer thread joined.\")\n\n    self.writing_pool.shutdown(wait=True, cancel_futures=False)\n    logger.debug(\"Writing pool shut down.\")\n\n    logger.info(\"Backend closed.\")\n    return True\n</code></pre>"},{"location":"reference/smart_geocubes/backends/threaded/#smart_geocubes.backends.threaded.ThreadedBackend.loaded_patches","title":"loaded_patches","text":"<pre><code>loaded_patches(session: Session | None = None) -&gt; list[str]\n</code></pre> <p>Get a list of all loaded patch ids.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>list[str]: A list of all loaded patch ids.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/backend.py</code> <pre><code>def loaded_patches(self, session: icechunk.Session | None = None) -&gt; list[str]:\n    \"\"\"Get a list of all loaded patch ids.\n\n    Returns:\n        list[str]: A list of all loaded patch ids.\n\n    \"\"\"\n    zcube = self.open_zarr(session)\n    loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n    return loaded_tiles\n</code></pre>"},{"location":"reference/smart_geocubes/backends/threaded/#smart_geocubes.backends.threaded.ThreadedBackend.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray(session: Session | None = None) -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/backend.py</code> <pre><code>def open_xarray(self, session: icechunk.Session | None = None) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    if session is None:\n        session = self.repo.readonly_session(\"main\")\n    self.assert_created(session)\n    xcube = xr.open_zarr(session.store, mask_and_scale=False, consolidated=False).set_coords(\"spatial_ref\")\n    return xcube\n</code></pre>"},{"location":"reference/smart_geocubes/backends/threaded/#smart_geocubes.backends.threaded.ThreadedBackend.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr(session: Session | None = None) -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/backend.py</code> <pre><code>def open_zarr(self, session: icechunk.Session | None = None) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    if session is None:\n        session = self.repo.readonly_session(\"main\")\n    self.assert_created(session)\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube\n</code></pre>"},{"location":"reference/smart_geocubes/backends/threaded/#smart_geocubes.backends.threaded.ThreadedBackend.submit","title":"submit","text":"<pre><code>submit(idx: PatchIndex | list[PatchIndex])\n</code></pre> <p>Submit a patch download request to the backend.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>RuntimeError</code>             \u2013            <p>If the writer thread is not alive or if downloading failed for any patches.</p> </li> </ul> Source code in <code>src/smart_geocubes/backends/threaded.py</code> <pre><code>def submit(self, idx: PatchIndex | list[PatchIndex]):\n    \"\"\"Submit a patch download request to the backend.\n\n    Args:\n        idx (PatchIndex | list[PatchIndex]): The index or multiple indices of the patch(es) to download.\n\n    Raises:\n        RuntimeError: If the writer thread is not alive or if downloading failed for any patches.\n\n    \"\"\"\n    if isinstance(idx, PatchIndex):\n        idx = [idx]\n\n    # Check if the writer thread is still alive\n    if not self.writer.is_alive():\n        raise RuntimeError(\"Writer thread is not alive. This happens if the writer thread crashes.\")\n\n    futures = [self.download_pool.submit(self._download_in_pool, i) for i in idx]\n\n    _, failed = wait(futures)\n    if len(failed) &gt; 0:\n        raise RuntimeError(f\"Downloading failed for {len(failed)} patches.\")\n\n    # Check if the queue is still alive\n    if self.write_queue.is_shutdown:\n        raise RuntimeError(\n            \"Write queue is not alive. This happens if the writer thread crashes or the backend is closed.\"\n        )\n    with self.write_queue.mutex:\n        self.write_queue.all_tasks_done.wait()\n    logger.debug(\"All submitted patches downloaded and written.\")\n</code></pre>"},{"location":"reference/smart_geocubes/backends/threaded/#smart_geocubes.backends.threaded.ThreadedBackend.submit(idx)","title":"<code>idx</code>","text":"(<code>PatchIndex | list[PatchIndex]</code>)           \u2013            <p>The index or multiple indices of the patch(es) to download.</p>"},{"location":"reference/smart_geocubes/core/","title":"core","text":""},{"location":"reference/smart_geocubes/core/#smart_geocubes.core","title":"smart_geocubes.core","text":"<p>Core functionality of smart-geocubes.</p> <p>Modules:</p> <ul> <li> <code>accessor</code>           \u2013            <p>Base class for remote accessors.</p> </li> <li> <code>backend</code>           \u2013            <p>Write specific backends.</p> </li> <li> <code>patches</code>           \u2013            <p>Metadata for a single patch in a data cube.</p> </li> <li> <code>storage</code>           \u2013            <p>Local zarr-storage related functions.</p> </li> <li> <code>toi</code>           \u2013            <p>Time of Interest (TOI) utilities.</p> </li> <li> <code>utils</code>           \u2013            <p>Utility functions for smart geocubes.</p> </li> </ul>"},{"location":"reference/smart_geocubes/core/accessor/","title":"accessor","text":""},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor","title":"smart_geocubes.core.accessor","text":"<p>Base class for remote accessors.</p> <p>Classes:</p> <ul> <li> <code>LoadParams</code>           \u2013            <p>TypedDict for the load function parameters.</p> </li> <li> <code>RemoteAccessor</code>           \u2013            <p>Base class for remote accessors.</p> </li> </ul>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.LoadParams","title":"LoadParams","text":"<p>               Bases: <code>TypedDict</code></p> <p>TypedDict for the load function parameters.</p>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor","title":"RemoteAccessor","text":"<pre><code>RemoteAccessor(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Base class for remote accessors.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>Chronometer</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_patches</code>             \u2013              <p>Get the adjacent patches for the given geobox.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>assert_temporal_cube</code>             \u2013              <p>Assert that the datacube has a temporal dimension.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles / chunk.</p> </li> <li> <code>download_patch</code>             \u2013              <p>Download the data for the given patch.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>loaded_patches</code>             \u2013              <p>Get the ids of already (down-)loaded patches.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Post create actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>post_init</code>             \u2013              <p>Post init actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download tiles procedurally.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize currently stored tiles / chunk.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n        backend (Literal[\"threaded\", \"simple\"], optional): The backend to use for downloading data.\n            Currently, only \"threaded\" is supported. Defaults to \"threaded\".\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = Chronometer(logger.debug)\n\n    if backend == \"threaded\":\n        if not _check_python_version(3, 13):\n            raise NotImplementedError(\n                \"The 'threaded' backend is only fully supported in Python 3.13 and above.\"\n                \" Please consider using the 'simple' backend in a multiprocessing environment\"\n                \" or upgrade your Python version.\"\n            )\n        self.backend = ThreadedBackend(self.repo, self.download_patch)\n    elif backend == \"simple\":\n        self.backend = SimpleBackend(self.repo, self.download_patch)\n    else:\n        raise ValueError(f\"Unknown backend {backend}\")\n\n    self.post_init()\n</code></pre>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor(backend)","title":"<code>backend</code>","text":"(<code>Literal['threaded', 'simple']</code>, default:                   <code>'threaded'</code> )           \u2013            <p>The backend to use for downloading data. Currently, only \"threaded\" is supported. Defaults to \"threaded\".</p>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre> <p>Check if the datacube already exists in the storage.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.is_temporal","title":"is_temporal  <code>property</code>","text":"<pre><code>is_temporal: bool\n</code></pre> <p>Check if the datacube has a temporal dimension.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube has a temporal dimension.</p> </li> </ul>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.adjacent_patches","title":"adjacent_patches  <code>abstractmethod</code>","text":"<pre><code>adjacent_patches(\n    roi: Geometry | GeoBox | GeoDataFrame, toi: TOI\n) -&gt; list[PatchIndex]\n</code></pre> <p>Get the adjacent patches for the given geobox.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[PatchIndex]</code>           \u2013            <p>list[PatchIndex]: The adjacent patch(-id)s for the given geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>@abstractmethod\ndef adjacent_patches(self, roi: Geometry | GeoBox | gpd.GeoDataFrame, toi: TOI) -&gt; list[PatchIndex]:\n    \"\"\"Get the adjacent patches for the given geobox.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        roi (Geometry | GeoBox | gpd.GeoDataFrame): The reference geometry, geobox or reference geodataframe\n        toi (TOI): The time of interest to download.\n\n    Returns:\n        list[PatchIndex]: The adjacent patch(-id)s for the given geobox.\n\n    \"\"\"\n</code></pre>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.adjacent_patches(roi)","title":"<code>roi</code>","text":"(<code>Geometry | GeoBox | GeoDataFrame</code>)           \u2013            <p>The reference geometry, geobox or reference geodataframe</p>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.adjacent_patches(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\"\"\"\n    self.backend.assert_created()\n</code></pre>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.assert_temporal_cube","title":"assert_temporal_cube","text":"<pre><code>assert_temporal_cube()\n</code></pre> <p>Assert that the datacube has a temporal dimension.</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube has no temporal dimension.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_temporal_cube(self):\n    \"\"\"Assert that the datacube has a temporal dimension.\n\n    Raises:\n        ValueError: If the datacube has no temporal dimension.\n\n    \"\"\"\n    if self.temporal_extent is None:\n        msg = f\"Datacube {self.title} has no temporal dimension.\"\n        logger.error(msg)\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.create","title":"create","text":"<pre><code>create(overwrite: bool = False, exists_ok: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location and exists_ok is False.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def create(self, overwrite: bool = False, exists_ok: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube.\n            Has no effect if exists_ok is True. Defaults to False.\n        exists_ok (bool, optional): Do not raise an error if the datacube already exists.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location and exists_ok is False.\n\n    \"\"\"\n    if exists_ok and self.created:\n        logger.debug(\"Datacube was already created.\")\n        return\n\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Expand to temporal dimension if defined\n        if self.temporal_extent is not None:\n            ds = ds.expand_dims(time=self.temporal_extent)\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        if self.temporal_extent is not None:\n            coords_encoding[\"time\"] = {\"chunks\": ds.time.shape, **optimize_temporal_encoding(self.temporal_extent)}\n        chunks = (\n            (1, self.chunk_size, self.chunk_size)\n            if self.temporal_extent is not None\n            else (self.chunk_size, self.chunk_size)\n        )\n        var_encoding = {\n            name: {\n                \"chunks\": chunks,\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Has no effect if exists_ok is True. Defaults to False.</p>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.create(exists_ok)","title":"<code>exists_ok</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Do not raise an error if the datacube already exists.</p>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.current_state","title":"current_state  <code>abstractmethod</code>","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles / chunk.</p> <p>Must be implemented by the Accessor.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame | None: Tile or Chunk info.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>@abstractmethod\ndef current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles / chunk.\n\n    Must be implemented by the Accessor.\n\n    Returns:\n        gpd.GeoDataFrame | None: Tile or Chunk info.\n\n    \"\"\"\n</code></pre>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.download_patch","title":"download_patch  <code>abstractmethod</code>","text":"<pre><code>download_patch(idx: PatchIndex) -&gt; xr.Dataset\n</code></pre> <p>Download the data for the given patch.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded patch data.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>@abstractmethod\ndef download_patch(self, idx: PatchIndex) -&gt; xr.Dataset:\n    \"\"\"Download the data for the given patch.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        idx (PatchIndex): The reference patch to download the data for.\n\n    Returns:\n        xr.Dataset: The downloaded patch data.\n\n    \"\"\"\n</code></pre>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.download_patch(idx)","title":"<code>idx</code>","text":"(<code>PatchIndex</code>)           \u2013            <p>The reference patch to download the data for.</p>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.load","title":"load","text":"<pre><code>load(\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load(\n    self,\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        aoi (Geometry | GeoBox): The reference geometry to load the data for. If a Geobox is provided,\n            it will use the extent of the geobox.\n        toi (TOI): The temporal slice to load. Defaults to None.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    if toi is not None:\n        self.assert_temporal_cube()\n\n    if isinstance(aoi, GeoBox):\n        aoi = aoi.extent\n\n    with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        aligned_aoi = aoi.to_crs(self.extent.crs)\n        with self.stopuhr(f\"{_geometry_repr(aoi)}: Procedural download in blocking mode\"):\n            self.procedural_download(aligned_aoi, toi)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get temporal slice if time is provided\n        if toi is not None:\n            xrcube = xrcube.sel(time=toi)\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(aligned_aoi, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.load(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry | GeoBox</code>)           \u2013            <p>The reference geometry to load the data for. If a Geobox is provided, it will use the extent of the geobox.</p>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.load(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>, default:                   <code>None</code> )           \u2013            <p>The temporal slice to load. Defaults to None.</p>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    toi = None\n    if \"time\" in ref.coords and self.temporal_extent is not None:\n        toi = ref.get_index(\"time\")\n    return self.load(ref.geobox, toi=toi, **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.loaded_patches","title":"loaded_patches","text":"<pre><code>loaded_patches() -&gt; list[str]\n</code></pre> <p>Get the ids of already (down-)loaded patches.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>list[str]: A list of already loaded patch ids.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def loaded_patches(self) -&gt; list[str]:\n    \"\"\"Get the ids of already (down-)loaded patches.\n\n    Returns:\n        list[str]: A list of already loaded patch ids.\n\n    \"\"\"\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube.attrs.get(\"loaded_patches\", []).copy()\n</code></pre>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    return self.backend.open_xarray()\n</code></pre>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    return self.backend.open_zarr()\n</code></pre>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Post create actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_create(self):\n    \"\"\"Post create actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.post_init","title":"post_init","text":"<pre><code>post_init()\n</code></pre> <p>Post init actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_init(self):\n    \"\"\"Post init actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(aoi: Geometry, toi: TOI)\n</code></pre> <p>Download tiles procedurally.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If not all downloads were successful.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def procedural_download(self, aoi: Geometry, toi: TOI):\n    \"\"\"Download tiles procedurally.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        aoi (Geometry): The geometry of the aoi to download.\n        toi (TOI): The time of interest to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If not all downloads were successful.\n\n    \"\"\"\n    adjacent_patches = self.adjacent_patches(aoi, toi)\n    # interest-string\n    soi = f\"{_geometry_repr(aoi)}\" + (f\" @ {_repr_toi(toi)}\" if toi is not None else \"\")\n    if not adjacent_patches:\n        logger.error(f\"{soi}: No adjacent patches found: {adjacent_patches=}\")\n        raise ValueError(\"No adjacent patches found - is the provided aoi and toi correct?\")\n\n    loaded_patches = self.loaded_patches()\n\n    new_patches = [patch for patch in adjacent_patches if patch.id not in loaded_patches]\n\n    logger.debug(f\"{soi}:  {len(adjacent_patches)=} &amp; {len(loaded_patches)=} -&gt; {len(new_patches)=} to download\")\n    if not new_patches:\n        return\n\n    # This raises Errors if anything goes wrong -&gt; we want to propagate\n    self.backend.submit(new_patches)\n</code></pre>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.procedural_download(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry</code>)           \u2013            <p>The geometry of the aoi to download.</p>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.procedural_download(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.visualize_state","title":"visualize_state  <code>abstractmethod</code>","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize currently stored tiles / chunk.</p> <p>Must be implemented by the DatasetAccessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>@abstractmethod\ndef visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize currently stored tiles / chunk.\n\n    Must be implemented by the DatasetAccessor.\n\n    Args:\n        ax (plt.Axes | None, optional): The axes drawn to. If None, will create a new figure and axes.\n            Defaults to None.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization\n\n    \"\"\"\n</code></pre>"},{"location":"reference/smart_geocubes/core/accessor/#smart_geocubes.core.accessor.RemoteAccessor.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes. Defaults to None.</p>"},{"location":"reference/smart_geocubes/core/backend/","title":"backend","text":""},{"location":"reference/smart_geocubes/core/backend/#smart_geocubes.core.backend","title":"smart_geocubes.core.backend","text":"<p>Write specific backends.</p> <p>Classes:</p> <ul> <li> <code>DownloadBackend</code>           \u2013            <p>Base class for download backends.</p> </li> </ul>"},{"location":"reference/smart_geocubes/core/backend/#smart_geocubes.core.backend.DownloadBackend","title":"DownloadBackend","text":"<pre><code>DownloadBackend(\n    repo: Repository, f: Callable[[PatchIndex], Dataset]\n)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Base class for download backends.</p> <p>Initialize the ThreadedBackend.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>close</code>             \u2013              <p>Close the backend.</p> </li> <li> <code>loaded_patches</code>             \u2013              <p>Get a list of all loaded patch ids.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>submit</code>             \u2013              <p>Submit a patch download request to the backend.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>Check if the datacube already exists in the storage.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/backend.py</code> <pre><code>def __init__(self, repo: icechunk.Repository, f: Callable[[PatchIndex], xr.Dataset]):\n    \"\"\"Initialize the ThreadedBackend.\n\n    Args:\n        repo (icechunk.Repository): The icechunk repository.\n        f (callable[[PatchIndex], xr.Dataset]): A function that takes a PatchIndex and returns an xr.Dataset.\n            This should be implemented by the specific source backend.\n\n    \"\"\"\n    self.repo = repo\n    self.download_from_source = f\n</code></pre>"},{"location":"reference/smart_geocubes/core/backend/#smart_geocubes.core.backend.DownloadBackend(repo)","title":"<code>repo</code>","text":"(<code>Repository</code>)           \u2013            <p>The icechunk repository.</p>"},{"location":"reference/smart_geocubes/core/backend/#smart_geocubes.core.backend.DownloadBackend(f)","title":"<code>f</code>","text":"(<code>callable[[PatchIndex], Dataset]</code>)           \u2013            <p>A function that takes a PatchIndex and returns an xr.Dataset. This should be implemented by the specific source backend.</p>"},{"location":"reference/smart_geocubes/core/backend/#smart_geocubes.core.backend.DownloadBackend.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre> <p>Check if the datacube already exists in the storage.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul>"},{"location":"reference/smart_geocubes/core/backend/#smart_geocubes.core.backend.DownloadBackend.assert_created","title":"assert_created","text":"<pre><code>assert_created(session: Session | None = None)\n</code></pre> <p>Assert that the datacube exists in the storage.</p> <p>Raises:</p> <ul> <li> <code>FileNotFoundError</code>             \u2013            <p>If the datacube does not exist.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/backend.py</code> <pre><code>def assert_created(self, session: icechunk.Session | None = None):\n    \"\"\"Assert that the datacube exists in the storage.\n\n    Raises:\n        FileNotFoundError: If the datacube does not exist.\n\n    \"\"\"\n    if session is None:\n        session = self.repo.readonly_session(\"main\")\n    if sync(session.store.is_empty(\"\")):\n        msg = \"Datacube does not exist.\"\n        \" Please use the `create` method or pass `create=True` to `load`.\"\n        logger.error(msg)\n        raise FileNotFoundError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/core/backend/#smart_geocubes.core.backend.DownloadBackend.close","title":"close","text":"<pre><code>close() -&gt; bool\n</code></pre> <p>Close the backend.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the backend was closed successfully, False otherwise.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/backend.py</code> <pre><code>def close(self) -&gt; bool:\n    \"\"\"Close the backend.\n\n    Returns:\n        bool: True if the backend was closed successfully, False otherwise.\n\n    \"\"\"\n    # Base implementation does nothing\n    return True\n</code></pre>"},{"location":"reference/smart_geocubes/core/backend/#smart_geocubes.core.backend.DownloadBackend.loaded_patches","title":"loaded_patches","text":"<pre><code>loaded_patches(session: Session | None = None) -&gt; list[str]\n</code></pre> <p>Get a list of all loaded patch ids.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>list[str]: A list of all loaded patch ids.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/backend.py</code> <pre><code>def loaded_patches(self, session: icechunk.Session | None = None) -&gt; list[str]:\n    \"\"\"Get a list of all loaded patch ids.\n\n    Returns:\n        list[str]: A list of all loaded patch ids.\n\n    \"\"\"\n    zcube = self.open_zarr(session)\n    loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n    return loaded_tiles\n</code></pre>"},{"location":"reference/smart_geocubes/core/backend/#smart_geocubes.core.backend.DownloadBackend.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray(session: Session | None = None) -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/backend.py</code> <pre><code>def open_xarray(self, session: icechunk.Session | None = None) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    if session is None:\n        session = self.repo.readonly_session(\"main\")\n    self.assert_created(session)\n    xcube = xr.open_zarr(session.store, mask_and_scale=False, consolidated=False).set_coords(\"spatial_ref\")\n    return xcube\n</code></pre>"},{"location":"reference/smart_geocubes/core/backend/#smart_geocubes.core.backend.DownloadBackend.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr(session: Session | None = None) -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/backend.py</code> <pre><code>def open_zarr(self, session: icechunk.Session | None = None) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    if session is None:\n        session = self.repo.readonly_session(\"main\")\n    self.assert_created(session)\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube\n</code></pre>"},{"location":"reference/smart_geocubes/core/backend/#smart_geocubes.core.backend.DownloadBackend.submit","title":"submit  <code>abstractmethod</code>","text":"<pre><code>submit(idx: PatchIndex | list[PatchIndex])\n</code></pre> <p>Submit a patch download request to the backend.</p> <p>Parameters:</p> Source code in <code>src/smart_geocubes/core/backend.py</code> <pre><code>@abc.abstractmethod\ndef submit(self, idx: PatchIndex | list[PatchIndex]):\n    \"\"\"Submit a patch download request to the backend.\n\n    Args:\n        idx (PatchIndex | list[PatchIndex]): The index or multiple indices of the patch(es) to download.\n\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/core/backend/#smart_geocubes.core.backend.DownloadBackend.submit(idx)","title":"<code>idx</code>","text":"(<code>PatchIndex | list[PatchIndex]</code>)           \u2013            <p>The index or multiple indices of the patch(es) to download.</p>"},{"location":"reference/smart_geocubes/core/patches/","title":"patches","text":""},{"location":"reference/smart_geocubes/core/patches/#smart_geocubes.core.patches","title":"smart_geocubes.core.patches","text":"<p>Metadata for a single patch in a data cube.</p> <p>Classes:</p> <ul> <li> <code>PatchIndex</code>           \u2013            <p>Metadata for a single patch in a data cube.</p> </li> </ul>"},{"location":"reference/smart_geocubes/core/patches/#smart_geocubes.core.patches.PatchIndex","title":"PatchIndex  <code>dataclass</code>","text":"<pre><code>PatchIndex(\n    id: str,\n    geometry: Geometry,\n    time: tuple[str, str]\n    | tuple[datetime, datetime]\n    | str\n    | datetime\n    | None = None,\n    item: PatchItem | None = None,\n)\n</code></pre> <p>               Bases: <code>Generic[PatchItem]</code></p> <p>Metadata for a single patch in a data cube.</p> <p>Attributes:</p> <ul> <li> <code>geometry</code>               (<code>Geometry</code>)           \u2013            <p>The time of the patch, if applicable.</p> </li> <li> <code>id</code>               (<code>str</code>)           \u2013            <p>The Geometry defining the spatial extent in EPSG:4326.</p> </li> <li> <code>time</code>               (<code>tuple[str, str] | tuple[datetime, datetime] | str | datetime | None</code>)           \u2013            <p>An associated item or metadata object useful for other operations.</p> </li> </ul>"},{"location":"reference/smart_geocubes/core/patches/#smart_geocubes.core.patches.PatchIndex.geometry","title":"geometry  <code>instance-attribute</code>","text":"<pre><code>geometry: Geometry\n</code></pre> <p>The time of the patch, if applicable.</p>"},{"location":"reference/smart_geocubes/core/patches/#smart_geocubes.core.patches.PatchIndex.id","title":"id  <code>instance-attribute</code>","text":"<pre><code>id: str\n</code></pre> <p>The Geometry defining the spatial extent in EPSG:4326.</p>"},{"location":"reference/smart_geocubes/core/patches/#smart_geocubes.core.patches.PatchIndex.time","title":"time  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>time: (\n    tuple[str, str]\n    | tuple[datetime, datetime]\n    | str\n    | datetime\n    | None\n) = None\n</code></pre> <p>An associated item or metadata object useful for other operations.</p>"},{"location":"reference/smart_geocubes/core/storage/","title":"storage","text":""},{"location":"reference/smart_geocubes/core/storage/#smart_geocubes.core.storage","title":"smart_geocubes.core.storage","text":"<p>Local zarr-storage related functions.</p> <p>Classes:</p> <ul> <li> <code>CoordEncoding</code>           \u2013            <p>TypedDict for the encoding of regularly spaced coordinates.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>optimize_coord_encoding</code>             \u2013              <p>Optimize zarr encoding of regularly spaced coordinates.</p> </li> <li> <code>optimize_temporal_encoding</code>             \u2013              <p>Optimize the encoding of temporal data.</p> </li> </ul>"},{"location":"reference/smart_geocubes/core/storage/#smart_geocubes.core.storage.CoordEncoding","title":"CoordEncoding","text":"<p>               Bases: <code>TypedDict</code></p> <p>TypedDict for the encoding of regularly spaced coordinates.</p>"},{"location":"reference/smart_geocubes/core/storage/#smart_geocubes.core.storage.optimize_coord_encoding","title":"optimize_coord_encoding","text":"<pre><code>optimize_coord_encoding(\n    values: ndarray, dx: int\n) -&gt; CoordEncoding\n</code></pre> <p>Optimize zarr encoding of regularly spaced coordinates.</p> <p>Taken from https://github.com/earth-mover/serverless-datacube-demo/blob/a15423b9734898f52468bebc441e29ccf3789410/src/lib.py#L280</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>CoordEncoding</code> (              <code>CoordEncoding</code> )          \u2013            <p>A dictionary containing the zarr compressors and filters to use for encoding the coordinates.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/storage.py</code> <pre><code>def optimize_coord_encoding(values: np.ndarray, dx: int) -&gt; CoordEncoding:\n    \"\"\"Optimize zarr encoding of regularly spaced coordinates.\n\n    Taken from https://github.com/earth-mover/serverless-datacube-demo/blob/a15423b9734898f52468bebc441e29ccf3789410/src/lib.py#L280\n\n    Args:\n        values (np.ndarray): The coordinates to encode\n        dx (int): The spacing between the coordinates\n\n    Returns:\n        CoordEncoding: A dictionary containing the zarr compressors and filters to use for encoding the coordinates.\n\n    \"\"\"\n    compressor = BloscCodec()\n    return {\"compressors\": [compressor]}\n</code></pre>"},{"location":"reference/smart_geocubes/core/storage/#smart_geocubes.core.storage.optimize_coord_encoding(values)","title":"<code>values</code>","text":"(<code>ndarray</code>)           \u2013            <p>The coordinates to encode</p>"},{"location":"reference/smart_geocubes/core/storage/#smart_geocubes.core.storage.optimize_coord_encoding(dx)","title":"<code>dx</code>","text":"(<code>int</code>)           \u2013            <p>The spacing between the coordinates</p>"},{"location":"reference/smart_geocubes/core/storage/#smart_geocubes.core.storage.optimize_temporal_encoding","title":"optimize_temporal_encoding","text":"<pre><code>optimize_temporal_encoding(\n    temporal_extent: DatetimeIndex,\n) -&gt; dict\n</code></pre> <p>Optimize the encoding of temporal data.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>dict</code> (              <code>dict</code> )          \u2013            <p>A dictionary containing the zarr compressors and filters to use for encoding the temporal data.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/storage.py</code> <pre><code>def optimize_temporal_encoding(temporal_extent: pd.DatetimeIndex) -&gt; dict:\n    \"\"\"Optimize the encoding of temporal data.\n\n    Args:\n        temporal_extent (pd.DatetimeIndex): The temporal extent to encode.\n\n    Returns:\n        dict: A dictionary containing the zarr compressors and filters to use for encoding the temporal data.\n\n    \"\"\"\n    compressor = BloscCodec()\n    return {\"compressors\": [compressor]}\n</code></pre>"},{"location":"reference/smart_geocubes/core/storage/#smart_geocubes.core.storage.optimize_temporal_encoding(temporal_extent)","title":"<code>temporal_extent</code>","text":"(<code>DatetimeIndex</code>)           \u2013            <p>The temporal extent to encode.</p>"},{"location":"reference/smart_geocubes/core/toi/","title":"toi","text":""},{"location":"reference/smart_geocubes/core/toi/#smart_geocubes.core.toi","title":"smart_geocubes.core.toi","text":"<p>Time of Interest (TOI) utilities.</p> <p>Functions:</p> <ul> <li> <code>extract_toi_range</code>             \u2013              <p>Extract the datetime range or a specific datetime from the time of interest (toi).</p> </li> <li> <code>normalize_toi</code>             \u2013              <p>Normalize the time of interest (toi) to the given temporal extent.</p> </li> </ul>"},{"location":"reference/smart_geocubes/core/toi/#smart_geocubes.core.toi.extract_toi_range","title":"extract_toi_range","text":"<pre><code>extract_toi_range(\n    toi: TOI,\n) -&gt; (\n    str\n    | datetime\n    | tuple[str, str]\n    | tuple[datetime | datetime]\n    | None\n)\n</code></pre> <p>Extract the datetime range or a specific datetime from the time of interest (toi).</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>str | datetime | tuple[str, str] | tuple[datetime | datetime] | None</code>           \u2013            <p>str | datetime | tuple[str, str] | tuple[datetime, datetime] | None: The extracted datetime or datetime range.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the time of interest is of an invalid type.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/toi.py</code> <pre><code>def extract_toi_range(toi: TOI) -&gt; str | datetime | tuple[str, str] | tuple[datetime | datetime] | None:\n    \"\"\"Extract the datetime range or a specific datetime from the time of interest (toi).\n\n    Args:\n        toi (TOI): The time of interest.\n\n    Returns:\n        str | datetime | tuple[str, str] | tuple[datetime, datetime] | None: The extracted datetime or datetime range.\n\n    Raises:\n        ValueError: If the time of interest is of an invalid type.\n\n    \"\"\"\n    if toi is None or isinstance(toi, str | datetime):\n        return toi\n    elif isinstance(toi, pd.Timestamp):\n        return toi.to_pydatetime()\n    elif isinstance(toi, slice):\n        return toi.start, toi.stop\n    else:\n        raise ValueError(f\"Cannot extract range from toi of type {type(toi)}.\")\n</code></pre>"},{"location":"reference/smart_geocubes/core/toi/#smart_geocubes.core.toi.extract_toi_range(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest.</p>"},{"location":"reference/smart_geocubes/core/toi/#smart_geocubes.core.toi.normalize_toi","title":"normalize_toi","text":"<pre><code>normalize_toi(\n    extent: DatetimeIndex, toi: TOI, method=\"nearest\"\n) -&gt; pd.DatetimeIndex\n</code></pre> <p>Normalize the time of interest (toi) to the given temporal extent.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DatetimeIndex</code>           \u2013            <p>pd.DatetimeIndex: The normalized time of interest.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the time of interest is not found in the temporal extent.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/toi.py</code> <pre><code>def normalize_toi(extent: pd.DatetimeIndex, toi: TOI, method=\"nearest\") -&gt; pd.DatetimeIndex:\n    \"\"\"Normalize the time of interest (toi) to the given temporal extent.\n\n    Args:\n        extent (pd.DatetimeIndex): The temporal extent to normalize against.\n        toi (TOI): The time of interest to normalize.\n        method (str, optional): The method to use for normalization. Defaults to \"nearest\".\n            Other options are \"pad\", \"backfill\", \"ffill\", \"bfill\".\n\n    Returns:\n        pd.DatetimeIndex: The normalized time of interest.\n\n    Raises:\n        ValueError: If the time of interest is not found in the temporal extent.\n\n    \"\"\"\n    # Normalize the extent\n    extent = extent.normalize()\n\n    if toi is None:\n        return extent\n\n    if isinstance(toi, str | datetime | pd.Timestamp):\n        idxr = extent.get_indexer([toi], method=method)\n    elif isinstance(toi, slice):\n        idxr = extent.slice_indexer(toi.start, toi.stop)\n    elif isinstance(toi, list):\n        idxr = extent.get_indexer(toi, method=method)\n\n    toi_norm = extent[idxr]\n    if len(toi_norm) == 0:\n        raise ValueError(f\"Time {toi} not found in temporal extent.\")\n    return toi_norm\n</code></pre>"},{"location":"reference/smart_geocubes/core/toi/#smart_geocubes.core.toi.normalize_toi(extent)","title":"<code>extent</code>","text":"(<code>DatetimeIndex</code>)           \u2013            <p>The temporal extent to normalize against.</p>"},{"location":"reference/smart_geocubes/core/toi/#smart_geocubes.core.toi.normalize_toi(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to normalize.</p>"},{"location":"reference/smart_geocubes/core/toi/#smart_geocubes.core.toi.normalize_toi(method)","title":"<code>method</code>","text":"(<code>str</code>, default:                   <code>'nearest'</code> )           \u2013            <p>The method to use for normalization. Defaults to \"nearest\". Other options are \"pad\", \"backfill\", \"ffill\", \"bfill\".</p>"},{"location":"reference/smart_geocubes/core/utils/","title":"utils","text":""},{"location":"reference/smart_geocubes/core/utils/#smart_geocubes.core.utils","title":"smart_geocubes.core.utils","text":"<p>Utility functions for smart geocubes.</p>"},{"location":"reference/smart_geocubes/datasets/","title":"datasets","text":""},{"location":"reference/smart_geocubes/datasets/#smart_geocubes.datasets","title":"smart_geocubes.datasets","text":"<p>Predefined datasets for the SmartGeocubes package.</p> <p>Modules:</p> <ul> <li> <code>alphaearth</code>           \u2013            <p>Predefined accessor for TCTrend data.</p> </li> <li> <code>arcticdem</code>           \u2013            <p>Predefined accessor for ArcticDEM 32m, 10m and 2m data.</p> </li> <li> <code>tctrend</code>           \u2013            <p>Predefined accessor for TCTrend data.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/alphaearth/","title":"alphaearth","text":""},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth","title":"smart_geocubes.datasets.alphaearth","text":"<p>Predefined accessor for TCTrend data.</p> <p>Classes:</p> <ul> <li> <code>AlphaEarthEmbeddings</code>           \u2013            <p>Accessor for AlphaEarth Embeddings data.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings","title":"AlphaEarthEmbeddings","text":"<pre><code>AlphaEarthEmbeddings(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n)\n</code></pre> <p>               Bases: <code>GEEMosaicAccessor</code></p> <p>Accessor for AlphaEarth Embeddings data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the zarr array. Should be equal to the extent geobox.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_patches</code>             \u2013              <p>Get the adjacent patches for the given geobox.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>assert_temporal_cube</code>             \u2013              <p>Assert that the datacube has a temporal dimension.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_patch</code>             \u2013              <p>Download the data for the given patch.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>loaded_patches</code>             \u2013              <p>Get the ids of already (down-)loaded patches.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Post create actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>post_init</code>             \u2013              <p>Post init actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download tiles procedurally.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n        backend (Literal[\"threaded\", \"simple\"], optional): The backend to use for downloading data.\n            Currently, only \"threaded\" is supported. Defaults to \"threaded\".\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = Chronometer(logger.debug)\n\n    if backend == \"threaded\":\n        if not _check_python_version(3, 13):\n            raise NotImplementedError(\n                \"The 'threaded' backend is only fully supported in Python 3.13 and above.\"\n                \" Please consider using the 'simple' backend in a multiprocessing environment\"\n                \" or upgrade your Python version.\"\n            )\n        self.backend = ThreadedBackend(self.repo, self.download_patch)\n    elif backend == \"simple\":\n        self.backend = SimpleBackend(self.repo, self.download_patch)\n    else:\n        raise ValueError(f\"Unknown backend {backend}\")\n\n    self.post_init()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings(backend)","title":"<code>backend</code>","text":"(<code>Literal['threaded', 'simple']</code>, default:                   <code>'threaded'</code> )           \u2013            <p>The backend to use for downloading data. Currently, only \"threaded\" is supported. Defaults to \"threaded\".</p>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre> <p>Check if the datacube already exists in the storage.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.is_temporal","title":"is_temporal  <code>property</code>","text":"<pre><code>is_temporal: bool\n</code></pre> <p>Check if the datacube has a temporal dimension.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube has a temporal dimension.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.adjacent_patches","title":"adjacent_patches","text":"<pre><code>adjacent_patches(\n    roi: Geometry | GeoBox | GeoDataFrame, toi: TOI\n) -&gt; list[Item]\n</code></pre> <p>Get the adjacent patches for the given geobox.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[Item]</code>           \u2013            <p>list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the ROI type is invalid.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If the datacube is not temporal, but a time of interest is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def adjacent_patches(self, roi: Geometry | GeoBox | gpd.GeoDataFrame, toi: TOI) -&gt; list[Item]:\n    \"\"\"Get the adjacent patches for the given geobox.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        roi (Geometry | GeoBox | gpd.GeoDataFrame): The reference geometry, geobox or reference geodataframe\n        toi (TOI): The time of interest to download.\n\n    Returns:\n        list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.\n\n    Raises:\n        ValueError: If the ROI type is invalid.\n        ValueError: If the datacube is not temporal, but a time of interest is provided.\n\n    \"\"\"\n    if toi is not None and not self.is_temporal:\n        raise ValueError(\"Datacube is not temporal, but time of interest is provided.\")\n\n    if isinstance(roi, gpd.GeoDataFrame):\n        adjacent_geometries = (\n            gpd.sjoin(self._tile_geometries, roi.to_crs(self.extent.crs.wkt), how=\"inner\", predicate=\"intersects\")\n            .reset_index()\n            .drop_duplicates(subset=\"index\", keep=\"first\")\n            .set_index(\"index\")\n        )\n        spatial_idxs: list[tuple[int, int]] = list(adjacent_geometries[\"idx\"])\n    elif isinstance(roi, GeoBox):\n        spatial_idxs: list[tuple[int, int]] = list(self._extent_tiles.tiles(roi.extent))\n    elif isinstance(roi, Geometry):\n        spatial_idxs: list[tuple[int, int]] = list(self._extent_tiles.tiles(roi))\n    else:\n        raise ValueError(\"Invalid ROI type.\")\n\n    if not self.is_temporal:\n        return [\n            PatchIndex(\n                self._stringify_index(spatial_idx),\n                self._extent_tiles[spatial_idx].geographic_extent,\n                None,\n                Item(self._extent_tiles[spatial_idx], None),\n            )\n            for spatial_idx in spatial_idxs\n        ]\n\n    # Now datacube is temporal\n    toi = normalize_toi(self.temporal_extent, toi)\n    patch_idxs = []\n    for time in toi:\n        time_idx = self.temporal_extent.get_loc(time)\n        assert isinstance(time_idx, int), \"Non-Unique temporal extents are not supported!\"\n        for spatial_idx in spatial_idxs:\n            patch_idxs.append(\n                PatchIndex(\n                    self._stringify_index(spatial_idx, time_idx),\n                    self._extent_tiles[spatial_idx].geographic_extent,\n                    time,\n                    Item(self._extent_tiles[spatial_idx], time),\n                )\n            )\n    return patch_idxs\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.adjacent_patches(roi)","title":"<code>roi</code>","text":"(<code>Geometry | GeoBox | GeoDataFrame</code>)           \u2013            <p>The reference geometry, geobox or reference geodataframe</p>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.adjacent_patches(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\"\"\"\n    self.backend.assert_created()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.assert_temporal_cube","title":"assert_temporal_cube","text":"<pre><code>assert_temporal_cube()\n</code></pre> <p>Assert that the datacube has a temporal dimension.</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube has no temporal dimension.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_temporal_cube(self):\n    \"\"\"Assert that the datacube has a temporal dimension.\n\n    Raises:\n        ValueError: If the datacube has no temporal dimension.\n\n    \"\"\"\n    if self.temporal_extent is None:\n        msg = f\"Datacube {self.title} has no temporal dimension.\"\n        logger.error(msg)\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.create","title":"create","text":"<pre><code>create(overwrite: bool = False, exists_ok: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location and exists_ok is False.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def create(self, overwrite: bool = False, exists_ok: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube.\n            Has no effect if exists_ok is True. Defaults to False.\n        exists_ok (bool, optional): Do not raise an error if the datacube already exists.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location and exists_ok is False.\n\n    \"\"\"\n    if exists_ok and self.created:\n        logger.debug(\"Datacube was already created.\")\n        return\n\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Expand to temporal dimension if defined\n        if self.temporal_extent is not None:\n            ds = ds.expand_dims(time=self.temporal_extent)\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        if self.temporal_extent is not None:\n            coords_encoding[\"time\"] = {\"chunks\": ds.time.shape, **optimize_temporal_encoding(self.temporal_extent)}\n        chunks = (\n            (1, self.chunk_size, self.chunk_size)\n            if self.temporal_extent is not None\n            else (self.chunk_size, self.chunk_size)\n        )\n        var_encoding = {\n            name: {\n                \"chunks\": chunks,\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Has no effect if exists_ok is True. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.create(exists_ok)","title":"<code>exists_ok</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Do not raise an error if the datacube already exists.</p>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.\n\n    \"\"\"\n    import geopandas as gpd\n\n    if not self.created:\n        return None\n\n    loaded_patches = self.loaded_patches()\n\n    if len(loaded_patches) == 0:\n        return None\n\n    patch_infos = []\n    for pid in loaded_patches:\n        spatial_idx, temporal_idx = self._parse_index(pid)\n        geometry = self._extent_tiles[spatial_idx].extent.geom\n        if self.is_temporal:\n            time = self.temporal_extent[temporal_idx]\n            patch_infos.append({\"geometry\": geometry, \"id\": pid, \"time\": time})\n        else:\n            patch_infos.append({\"geometry\": geometry, \"id\": pid})\n\n    gdf = gpd.GeoDataFrame(patch_infos, crs=self.extent.crs.to_wkt())\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.download_patch","title":"download_patch","text":"<pre><code>download_patch(idx: PatchIndex[Item]) -&gt; xr.Dataset\n</code></pre> <p>Download the data for the given patch.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded patch data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def download_patch(self, idx: PatchIndex[Item]) -&gt; xr.Dataset:\n    \"\"\"Download the data for the given patch.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        idx (PatchIndex[Item]): The reference patch to download the data for.\n\n    Returns:\n        xr.Dataset: The downloaded patch data.\n\n    \"\"\"\n    import ee\n    import rioxarray  # noqa: F401\n    import xee  # noqa: F401\n\n    # Note: This is a little bit weird: First we create an own grid which overlaps to the chunks\n    # of the zarr array. Then we create a mosaic of the data and clip it to a single chunk.\n    # We could load the images from the collection directly instead of creating a mosaic.\n    # However, this would require more testing and probably results a lot of manual computation\n    # of slices etc. like in the stac variant. So for now, we just use the mosaic.\n    logging.getLogger(\"urllib3.connectionpool\").disabled = True\n\n    ee_col = ee.ImageCollection(self.collection)\n    if self.is_temporal:\n        ee_col = ee_col.filterDate(idx.item.time)\n    geom = ee.Geometry.Rectangle(idx.item.geobox.geographic_extent.boundingbox)\n    ee_img = ee_col.mosaic().clip(geom)\n\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=UserWarning, message=EE_WARN_MSG)\n        patch = xr.open_dataset(\n            ee_img,\n            engine=\"ee\",\n            geometry=geom,\n            crs=f\"epsg:{self.extent.crs.to_epsg()}\",\n            scale=self.extent.resolution.x,\n        )\n\n    # Do a mosaic if time axis are returned for non-temporal data\n    if \"time\" in patch.dims and not self.is_temporal:\n        patch = patch.max(\"time\")\n\n    patch = patch.rename({\"lon\": \"x\", \"lat\": \"y\"})\n    if \"time\" in patch.dims:\n        patch[\"time\"] = [idx.item.time]\n        patch = patch.transpose(\"time\", \"y\", \"x\")\n    else:\n        patch = patch.transpose(\"y\", \"x\")\n\n    # Download the data\n    logger.debug(f\"{idx.id=}: Trigger GEE download)\")\n    patch.load()\n    logger.debug(f\"{idx.id=}: Finished GEE download\")\n    logging.getLogger(\"urllib3.connectionpool\").disabled = False\n\n    # Flip y-axis, because convention is x in positive direction and y in negative, but gee use positive for both\n    patch = patch.isel(y=slice(None, None, -1))\n\n    # For some reason xee does not always set the crs\n    patch = patch.odc.assign_crs(self.extent.crs)\n\n    # Recrop the data to the tile, since gee does not always return the exact extent\n    patch = patch.odc.crop(idx.item.geobox.extent)\n\n    return patch\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.download_patch(idx)","title":"<code>idx</code>","text":"(<code>PatchIndex[Item]</code>)           \u2013            <p>The reference patch to download the data for.</p>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.load","title":"load","text":"<pre><code>load(\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load(\n    self,\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        aoi (Geometry | GeoBox): The reference geometry to load the data for. If a Geobox is provided,\n            it will use the extent of the geobox.\n        toi (TOI): The temporal slice to load. Defaults to None.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    if toi is not None:\n        self.assert_temporal_cube()\n\n    if isinstance(aoi, GeoBox):\n        aoi = aoi.extent\n\n    with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        aligned_aoi = aoi.to_crs(self.extent.crs)\n        with self.stopuhr(f\"{_geometry_repr(aoi)}: Procedural download in blocking mode\"):\n            self.procedural_download(aligned_aoi, toi)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get temporal slice if time is provided\n        if toi is not None:\n            xrcube = xrcube.sel(time=toi)\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(aligned_aoi, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.load(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry | GeoBox</code>)           \u2013            <p>The reference geometry to load the data for. If a Geobox is provided, it will use the extent of the geobox.</p>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.load(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>, default:                   <code>None</code> )           \u2013            <p>The temporal slice to load. Defaults to None.</p>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    toi = None\n    if \"time\" in ref.coords and self.temporal_extent is not None:\n        toi = ref.get_index(\"time\")\n    return self.load(ref.geobox, toi=toi, **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.loaded_patches","title":"loaded_patches","text":"<pre><code>loaded_patches() -&gt; list[str]\n</code></pre> <p>Get the ids of already (down-)loaded patches.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>list[str]: A list of already loaded patch ids.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def loaded_patches(self) -&gt; list[str]:\n    \"\"\"Get the ids of already (down-)loaded patches.\n\n    Returns:\n        list[str]: A list of already loaded patch ids.\n\n    \"\"\"\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube.attrs.get(\"loaded_patches\", []).copy()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    return self.backend.open_xarray()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    return self.backend.open_zarr()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Post create actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_create(self):\n    \"\"\"Post create actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.post_init","title":"post_init","text":"<pre><code>post_init()\n</code></pre> <p>Post init actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_init(self):\n    \"\"\"Post init actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(aoi: Geometry, toi: TOI)\n</code></pre> <p>Download tiles procedurally.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If not all downloads were successful.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def procedural_download(self, aoi: Geometry, toi: TOI):\n    \"\"\"Download tiles procedurally.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        aoi (Geometry): The geometry of the aoi to download.\n        toi (TOI): The time of interest to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If not all downloads were successful.\n\n    \"\"\"\n    adjacent_patches = self.adjacent_patches(aoi, toi)\n    # interest-string\n    soi = f\"{_geometry_repr(aoi)}\" + (f\" @ {_repr_toi(toi)}\" if toi is not None else \"\")\n    if not adjacent_patches:\n        logger.error(f\"{soi}: No adjacent patches found: {adjacent_patches=}\")\n        raise ValueError(\"No adjacent patches found - is the provided aoi and toi correct?\")\n\n    loaded_patches = self.loaded_patches()\n\n    new_patches = [patch for patch in adjacent_patches if patch.id not in loaded_patches]\n\n    logger.debug(f\"{soi}:  {len(adjacent_patches)=} &amp; {len(loaded_patches)=} -&gt; {len(new_patches)=} to download\")\n    if not new_patches:\n        return\n\n    # This raises Errors if anything goes wrong -&gt; we want to propagate\n    self.backend.submit(new_patches)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.procedural_download(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry</code>)           \u2013            <p>The geometry of the aoi to download.</p>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.procedural_download(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/alphaearth.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    raise NotImplementedError(\"Visualization not implemented yet for AlphaEarth Embeddings datacube.\")\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/alphaearth/#smart_geocubes.datasets.alphaearth.AlphaEarthEmbeddings.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/","title":"arcticdem","text":""},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem","title":"smart_geocubes.datasets.arcticdem","text":"<p>Predefined accessor for ArcticDEM 32m, 10m and 2m data.</p> <p>Classes:</p> <ul> <li> <code>ArcticDEM10m</code>           \u2013            <p>Accessor for ArcticDEM 10m data.</p> </li> <li> <code>ArcticDEM2m</code>           \u2013            <p>Accessor for ArcticDEM 2m data.</p> </li> <li> <code>ArcticDEM32m</code>           \u2013            <p>Accessor for ArcticDEM 32m data.</p> </li> <li> <code>ArcticDEMABC</code>           \u2013            <p>ABC for Arcticdem data.</p> </li> <li> <code>LazyStacPatchIndex</code>           \u2013            <p>Lazy wrapper for a PatchIndex containing a STAC Item.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m","title":"ArcticDEM10m","text":"<pre><code>ArcticDEM10m(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n)\n</code></pre> <p>               Bases: <code>ArcticDEMABC</code></p> <p>Accessor for ArcticDEM 10m data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the underlaying zarr array. Should be equal to the extent geobox. However, this property is used to find the target index of the downloaded data, so better save than sorry.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_patches</code>             \u2013              <p>Get adjacent patch indexes from a STAC API.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>assert_temporal_cube</code>             \u2013              <p>Assert that the datacube has a temporal dimension.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_patch</code>             \u2013              <p>Download the data for the given patch.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>loaded_patches</code>             \u2013              <p>Get the ids of already (down-)loaded patches.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> </li> <li> <code>post_init</code>             \u2013              <p>Check if the ArcticDEM mosaic extent info is already downloaded and downlaod if not.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download tiles procedurally.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n        backend (Literal[\"threaded\", \"simple\"], optional): The backend to use for downloading data.\n            Currently, only \"threaded\" is supported. Defaults to \"threaded\".\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = Chronometer(logger.debug)\n\n    if backend == \"threaded\":\n        if not _check_python_version(3, 13):\n            raise NotImplementedError(\n                \"The 'threaded' backend is only fully supported in Python 3.13 and above.\"\n                \" Please consider using the 'simple' backend in a multiprocessing environment\"\n                \" or upgrade your Python version.\"\n            )\n        self.backend = ThreadedBackend(self.repo, self.download_patch)\n    elif backend == \"simple\":\n        self.backend = SimpleBackend(self.repo, self.download_patch)\n    else:\n        raise ValueError(f\"Unknown backend {backend}\")\n\n    self.post_init()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m(backend)","title":"<code>backend</code>","text":"(<code>Literal['threaded', 'simple']</code>, default:                   <code>'threaded'</code> )           \u2013            <p>The backend to use for downloading data. Currently, only \"threaded\" is supported. Defaults to \"threaded\".</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre> <p>Check if the datacube already exists in the storage.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.is_temporal","title":"is_temporal  <code>property</code>","text":"<pre><code>is_temporal: bool\n</code></pre> <p>Check if the datacube has a temporal dimension.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube has a temporal dimension.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.adjacent_patches","title":"adjacent_patches","text":"<pre><code>adjacent_patches(\n    roi: Geometry | GeoBox | GeoDataFrame, toi: TOI\n) -&gt; list[PatchIndex]\n</code></pre> <p>Get adjacent patch indexes from a STAC API.</p> <p>Overwrite the default implementation from the STAC accessor to use pre-downloaded extent files instead of querying the STAC API. This results in a faster loading time, but requires the extent files to be downloaded beforehand. This is done in the post_create step.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[PatchIndex]</code>           \u2013            <p>list[PatchIndex]: List of adjacent patches, wrapped in own datastructure for easier processing.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the roi is not a GeoBox or a GeoDataFrame.</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def adjacent_patches(self, roi: Geometry | GeoBox | gpd.GeoDataFrame, toi: TOI) -&gt; list[PatchIndex]:\n    \"\"\"Get adjacent patch indexes from a STAC API.\n\n    Overwrite the default implementation from the STAC accessor\n    to use pre-downloaded extent files instead of querying the STAC API.\n    This results in a faster loading time, but requires the extent files to be downloaded beforehand.\n    This is done in the post_create step.\n\n    Args:\n        roi (Geometry | GeoBox | gpd.GeoDataFrame): The reference geometry, geobox or reference geodataframe\n        toi (TOI): The time of interest to download.\n            Not used in this implementation since ArcticDEM is not temporal.\n\n    Returns:\n        list[PatchIndex]: List of adjacent patches, wrapped in own datastructure for easier processing.\n\n    Raises:\n        ValueError: If the roi is not a GeoBox or a GeoDataFrame.\n\n    \"\"\"\n    # Assumes that the extent files are already present and the datacube is already created\n    self.assert_created()\n\n    resolution = f\"{int(self.extent.resolution.x)}m\"\n    extent_info = gpd.read_parquet(self._aux_dir / f\"ArcticDEM_Mosaic_Index_v4_1_{resolution}.parquet\")\n    if isinstance(roi, gpd.GeoDataFrame):\n        adjacent_tiles = (\n            gpd.sjoin(\n                extent_info,\n                roi[[\"geometry\"]].to_crs(self.extent.crs.wkt),\n                how=\"inner\",\n                predicate=\"intersects\",\n            )\n            .reset_index()\n            .drop_duplicates(subset=\"index\", keep=\"first\", ignore_index=True)\n        )\n    elif isinstance(roi, GeoBox):\n        adjacent_tiles = extent_info.loc[extent_info.intersects(roi.boundingbox.polygon.geom)].copy()\n    elif isinstance(roi, Geometry):\n        adjacent_tiles = extent_info.loc[extent_info.intersects(roi.geom)].copy()\n    else:\n        raise ValueError(\"roi must be a GeoBox or a GeoDataFrame\")\n    if adjacent_tiles.empty:\n        return []\n    return [\n        LazyStacPatchIndex(tile.dem_id, _get_stac_url(tile.dem_id, resolution))\n        for tile in adjacent_tiles.itertuples()\n    ]\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.adjacent_patches(roi)","title":"<code>roi</code>","text":"(<code>Geometry | GeoBox | GeoDataFrame</code>)           \u2013            <p>The reference geometry, geobox or reference geodataframe</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.adjacent_patches(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download. Not used in this implementation since ArcticDEM is not temporal.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\"\"\"\n    self.backend.assert_created()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.assert_temporal_cube","title":"assert_temporal_cube","text":"<pre><code>assert_temporal_cube()\n</code></pre> <p>Assert that the datacube has a temporal dimension.</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube has no temporal dimension.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_temporal_cube(self):\n    \"\"\"Assert that the datacube has a temporal dimension.\n\n    Raises:\n        ValueError: If the datacube has no temporal dimension.\n\n    \"\"\"\n    if self.temporal_extent is None:\n        msg = f\"Datacube {self.title} has no temporal dimension.\"\n        logger.error(msg)\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.create","title":"create","text":"<pre><code>create(overwrite: bool = False, exists_ok: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location and exists_ok is False.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def create(self, overwrite: bool = False, exists_ok: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube.\n            Has no effect if exists_ok is True. Defaults to False.\n        exists_ok (bool, optional): Do not raise an error if the datacube already exists.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location and exists_ok is False.\n\n    \"\"\"\n    if exists_ok and self.created:\n        logger.debug(\"Datacube was already created.\")\n        return\n\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Expand to temporal dimension if defined\n        if self.temporal_extent is not None:\n            ds = ds.expand_dims(time=self.temporal_extent)\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        if self.temporal_extent is not None:\n            coords_encoding[\"time\"] = {\"chunks\": ds.time.shape, **optimize_temporal_encoding(self.temporal_extent)}\n        chunks = (\n            (1, self.chunk_size, self.chunk_size)\n            if self.temporal_extent is not None\n            else (self.chunk_size, self.chunk_size)\n        )\n        var_encoding = {\n            name: {\n                \"chunks\": chunks,\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Has no effect if exists_ok is True. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.create(exists_ok)","title":"<code>exists_ok</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Do not raise an error if the datacube already exists.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.\n\n    \"\"\"\n    import geopandas as gpd\n    import pystac_client\n\n    if not self.created:\n        return None\n\n    loaded_patches = self.loaded_patches()\n\n    if len(loaded_patches) == 0:\n        return None\n\n    catalog = pystac_client.Client.open(self.stac_api_url)\n    search = catalog.search(collections=[self.collection], ids=loaded_patches)\n    stac_json = search.item_collection_as_dict()\n\n    gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.download_patch","title":"download_patch","text":"<pre><code>download_patch(idx: PatchIndex[Item]) -&gt; xr.Dataset\n</code></pre> <p>Download the data for the given patch.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded patch data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def download_patch(self, idx: PatchIndex[\"Item\"]) -&gt; xr.Dataset:\n    \"\"\"Download the data for the given patch.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        idx (PatchIndex[Item]): The reference patch to download the data for.\n\n    Returns:\n        xr.Dataset: The downloaded patch data.\n\n    \"\"\"\n    from odc.stac import stac_load\n\n    patch = stac_load([idx.item], bands=self.channels, chunks=None, progress=None)\n\n    # Do a mosaic if multiple items are returned for non-temporal data\n    if \"time\" in patch.dims and self.temporal_extent is None:\n        patch = patch.max(\"time\")\n\n    return patch\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.download_patch(idx)","title":"<code>idx</code>","text":"(<code>PatchIndex[Item]</code>)           \u2013            <p>The reference patch to download the data for.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.load","title":"load","text":"<pre><code>load(\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load(\n    self,\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        aoi (Geometry | GeoBox): The reference geometry to load the data for. If a Geobox is provided,\n            it will use the extent of the geobox.\n        toi (TOI): The temporal slice to load. Defaults to None.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    if toi is not None:\n        self.assert_temporal_cube()\n\n    if isinstance(aoi, GeoBox):\n        aoi = aoi.extent\n\n    with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        aligned_aoi = aoi.to_crs(self.extent.crs)\n        with self.stopuhr(f\"{_geometry_repr(aoi)}: Procedural download in blocking mode\"):\n            self.procedural_download(aligned_aoi, toi)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get temporal slice if time is provided\n        if toi is not None:\n            xrcube = xrcube.sel(time=toi)\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(aligned_aoi, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.load(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry | GeoBox</code>)           \u2013            <p>The reference geometry to load the data for. If a Geobox is provided, it will use the extent of the geobox.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.load(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>, default:                   <code>None</code> )           \u2013            <p>The temporal slice to load. Defaults to None.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    toi = None\n    if \"time\" in ref.coords and self.temporal_extent is not None:\n        toi = ref.get_index(\"time\")\n    return self.load(ref.geobox, toi=toi, **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.loaded_patches","title":"loaded_patches","text":"<pre><code>loaded_patches() -&gt; list[str]\n</code></pre> <p>Get the ids of already (down-)loaded patches.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>list[str]: A list of already loaded patch ids.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def loaded_patches(self) -&gt; list[str]:\n    \"\"\"Get the ids of already (down-)loaded patches.\n\n    Returns:\n        list[str]: A list of already loaded patch ids.\n\n    \"\"\"\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube.attrs.get(\"loaded_patches\", []).copy()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    return self.backend.open_xarray()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    return self.backend.open_zarr()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def post_create(self):\n    \"\"\"Download the ArcticDEM mosaic extent info and store it in the datacube.\"\"\"\n    _download_arcticdem_extent(self._aux_dir)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.post_init","title":"post_init","text":"<pre><code>post_init()\n</code></pre> <p>Check if the ArcticDEM mosaic extent info is already downloaded and downlaod if not.</p> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def post_init(self):\n    \"\"\"Check if the ArcticDEM mosaic extent info is already downloaded and downlaod if not.\"\"\"\n    required_files = [self._aux_dir / f\"ArcticDEM_Mosaic_Index_v4_1_{res}.parquet\" for res in [\"2m\", \"10m\", \"32m\"]]\n    if not all(file.exists() for file in required_files):\n        _download_arcticdem_extent(self._aux_dir)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(aoi: Geometry, toi: TOI)\n</code></pre> <p>Download tiles procedurally.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If not all downloads were successful.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def procedural_download(self, aoi: Geometry, toi: TOI):\n    \"\"\"Download tiles procedurally.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        aoi (Geometry): The geometry of the aoi to download.\n        toi (TOI): The time of interest to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If not all downloads were successful.\n\n    \"\"\"\n    adjacent_patches = self.adjacent_patches(aoi, toi)\n    # interest-string\n    soi = f\"{_geometry_repr(aoi)}\" + (f\" @ {_repr_toi(toi)}\" if toi is not None else \"\")\n    if not adjacent_patches:\n        logger.error(f\"{soi}: No adjacent patches found: {adjacent_patches=}\")\n        raise ValueError(\"No adjacent patches found - is the provided aoi and toi correct?\")\n\n    loaded_patches = self.loaded_patches()\n\n    new_patches = [patch for patch in adjacent_patches if patch.id not in loaded_patches]\n\n    logger.debug(f\"{soi}:  {len(adjacent_patches)=} &amp; {len(loaded_patches)=} -&gt; {len(new_patches)=} to download\")\n    if not new_patches:\n        return\n\n    # This raises Errors if anything goes wrong -&gt; we want to propagate\n    self.backend.submit(new_patches)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.procedural_download(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry</code>)           \u2013            <p>The geometry of the aoi to download.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.procedural_download(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    import cartopy.crs as ccrs\n    import cartopy.feature as cfeature\n    import matplotlib.path as mpath\n    import matplotlib.pyplot as plt\n\n    tile_info = self.current_state()\n\n    if tile_info is None:\n        raise ValueError(\"Datacube is not created or loaded yet. Can't visualize!\")\n\n    # Define the projection\n    projection = ccrs.Stereographic(central_latitude=90, central_longitude=-45, true_scale_latitude=70)\n\n    # Create a figure\n    fig = None\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": projection})\n\n    # Set the extent to focus on the North Pole\n    ax.set_extent([-180, 180, 50, 90], crs=ccrs.PlateCarree())\n\n    # Add features\n    ax.add_feature(cfeature.LAND, zorder=0, edgecolor=\"black\", facecolor=\"white\")\n    ax.add_feature(cfeature.OCEAN, zorder=0, facecolor=\"lightgrey\")\n    ax.add_feature(cfeature.COASTLINE)\n    ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n    ax.add_feature(cfeature.LAKES, alpha=0.5)\n    ax.add_feature(cfeature.RIVERS)\n\n    # Add gridlines\n    gl = ax.gridlines(draw_labels=True)\n    gl.top_labels = False\n    gl.right_labels = False\n\n    # Compute a circle in axes coordinates, which we can use as a boundary\n    # for the map. We can pan/zoom as much as we like - the boundary will be\n    # permanently circular.\n    theta = np.linspace(0, 2 * np.pi, 100)\n    center, radius = [0.5, 0.5], 0.5\n    verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n    circle = mpath.Path(verts * radius + center)\n\n    ax.set_boundary(circle, transform=ax.transAxes)\n\n    tile_info.plot(\n        \"title\",\n        ax=ax,\n        transform=ccrs.PlateCarree(),\n        edgecolor=\"black\",\n        categorical=True,\n        aspect=\"equal\",\n        alpha=0.5,\n    )\n\n    if fig is not None:\n        return fig\n    else:\n        return ax\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m","title":"ArcticDEM2m","text":"<pre><code>ArcticDEM2m(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n)\n</code></pre> <p>               Bases: <code>ArcticDEMABC</code></p> <p>Accessor for ArcticDEM 2m data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the underlaying zarr array. Should be equal to the extent geobox. However, this property is used to find the target index of the downloaded data, so better save than sorry.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_patches</code>             \u2013              <p>Get adjacent patch indexes from a STAC API.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>assert_temporal_cube</code>             \u2013              <p>Assert that the datacube has a temporal dimension.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_patch</code>             \u2013              <p>Download the data for the given patch.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>loaded_patches</code>             \u2013              <p>Get the ids of already (down-)loaded patches.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> </li> <li> <code>post_init</code>             \u2013              <p>Check if the ArcticDEM mosaic extent info is already downloaded and downlaod if not.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download tiles procedurally.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n        backend (Literal[\"threaded\", \"simple\"], optional): The backend to use for downloading data.\n            Currently, only \"threaded\" is supported. Defaults to \"threaded\".\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = Chronometer(logger.debug)\n\n    if backend == \"threaded\":\n        if not _check_python_version(3, 13):\n            raise NotImplementedError(\n                \"The 'threaded' backend is only fully supported in Python 3.13 and above.\"\n                \" Please consider using the 'simple' backend in a multiprocessing environment\"\n                \" or upgrade your Python version.\"\n            )\n        self.backend = ThreadedBackend(self.repo, self.download_patch)\n    elif backend == \"simple\":\n        self.backend = SimpleBackend(self.repo, self.download_patch)\n    else:\n        raise ValueError(f\"Unknown backend {backend}\")\n\n    self.post_init()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m(backend)","title":"<code>backend</code>","text":"(<code>Literal['threaded', 'simple']</code>, default:                   <code>'threaded'</code> )           \u2013            <p>The backend to use for downloading data. Currently, only \"threaded\" is supported. Defaults to \"threaded\".</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre> <p>Check if the datacube already exists in the storage.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.is_temporal","title":"is_temporal  <code>property</code>","text":"<pre><code>is_temporal: bool\n</code></pre> <p>Check if the datacube has a temporal dimension.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube has a temporal dimension.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.adjacent_patches","title":"adjacent_patches","text":"<pre><code>adjacent_patches(\n    roi: Geometry | GeoBox | GeoDataFrame, toi: TOI\n) -&gt; list[PatchIndex]\n</code></pre> <p>Get adjacent patch indexes from a STAC API.</p> <p>Overwrite the default implementation from the STAC accessor to use pre-downloaded extent files instead of querying the STAC API. This results in a faster loading time, but requires the extent files to be downloaded beforehand. This is done in the post_create step.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[PatchIndex]</code>           \u2013            <p>list[PatchIndex]: List of adjacent patches, wrapped in own datastructure for easier processing.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the roi is not a GeoBox or a GeoDataFrame.</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def adjacent_patches(self, roi: Geometry | GeoBox | gpd.GeoDataFrame, toi: TOI) -&gt; list[PatchIndex]:\n    \"\"\"Get adjacent patch indexes from a STAC API.\n\n    Overwrite the default implementation from the STAC accessor\n    to use pre-downloaded extent files instead of querying the STAC API.\n    This results in a faster loading time, but requires the extent files to be downloaded beforehand.\n    This is done in the post_create step.\n\n    Args:\n        roi (Geometry | GeoBox | gpd.GeoDataFrame): The reference geometry, geobox or reference geodataframe\n        toi (TOI): The time of interest to download.\n            Not used in this implementation since ArcticDEM is not temporal.\n\n    Returns:\n        list[PatchIndex]: List of adjacent patches, wrapped in own datastructure for easier processing.\n\n    Raises:\n        ValueError: If the roi is not a GeoBox or a GeoDataFrame.\n\n    \"\"\"\n    # Assumes that the extent files are already present and the datacube is already created\n    self.assert_created()\n\n    resolution = f\"{int(self.extent.resolution.x)}m\"\n    extent_info = gpd.read_parquet(self._aux_dir / f\"ArcticDEM_Mosaic_Index_v4_1_{resolution}.parquet\")\n    if isinstance(roi, gpd.GeoDataFrame):\n        adjacent_tiles = (\n            gpd.sjoin(\n                extent_info,\n                roi[[\"geometry\"]].to_crs(self.extent.crs.wkt),\n                how=\"inner\",\n                predicate=\"intersects\",\n            )\n            .reset_index()\n            .drop_duplicates(subset=\"index\", keep=\"first\", ignore_index=True)\n        )\n    elif isinstance(roi, GeoBox):\n        adjacent_tiles = extent_info.loc[extent_info.intersects(roi.boundingbox.polygon.geom)].copy()\n    elif isinstance(roi, Geometry):\n        adjacent_tiles = extent_info.loc[extent_info.intersects(roi.geom)].copy()\n    else:\n        raise ValueError(\"roi must be a GeoBox or a GeoDataFrame\")\n    if adjacent_tiles.empty:\n        return []\n    return [\n        LazyStacPatchIndex(tile.dem_id, _get_stac_url(tile.dem_id, resolution))\n        for tile in adjacent_tiles.itertuples()\n    ]\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.adjacent_patches(roi)","title":"<code>roi</code>","text":"(<code>Geometry | GeoBox | GeoDataFrame</code>)           \u2013            <p>The reference geometry, geobox or reference geodataframe</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.adjacent_patches(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download. Not used in this implementation since ArcticDEM is not temporal.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\"\"\"\n    self.backend.assert_created()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.assert_temporal_cube","title":"assert_temporal_cube","text":"<pre><code>assert_temporal_cube()\n</code></pre> <p>Assert that the datacube has a temporal dimension.</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube has no temporal dimension.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_temporal_cube(self):\n    \"\"\"Assert that the datacube has a temporal dimension.\n\n    Raises:\n        ValueError: If the datacube has no temporal dimension.\n\n    \"\"\"\n    if self.temporal_extent is None:\n        msg = f\"Datacube {self.title} has no temporal dimension.\"\n        logger.error(msg)\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.create","title":"create","text":"<pre><code>create(overwrite: bool = False, exists_ok: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location and exists_ok is False.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def create(self, overwrite: bool = False, exists_ok: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube.\n            Has no effect if exists_ok is True. Defaults to False.\n        exists_ok (bool, optional): Do not raise an error if the datacube already exists.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location and exists_ok is False.\n\n    \"\"\"\n    if exists_ok and self.created:\n        logger.debug(\"Datacube was already created.\")\n        return\n\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Expand to temporal dimension if defined\n        if self.temporal_extent is not None:\n            ds = ds.expand_dims(time=self.temporal_extent)\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        if self.temporal_extent is not None:\n            coords_encoding[\"time\"] = {\"chunks\": ds.time.shape, **optimize_temporal_encoding(self.temporal_extent)}\n        chunks = (\n            (1, self.chunk_size, self.chunk_size)\n            if self.temporal_extent is not None\n            else (self.chunk_size, self.chunk_size)\n        )\n        var_encoding = {\n            name: {\n                \"chunks\": chunks,\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Has no effect if exists_ok is True. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.create(exists_ok)","title":"<code>exists_ok</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Do not raise an error if the datacube already exists.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.\n\n    \"\"\"\n    import geopandas as gpd\n    import pystac_client\n\n    if not self.created:\n        return None\n\n    loaded_patches = self.loaded_patches()\n\n    if len(loaded_patches) == 0:\n        return None\n\n    catalog = pystac_client.Client.open(self.stac_api_url)\n    search = catalog.search(collections=[self.collection], ids=loaded_patches)\n    stac_json = search.item_collection_as_dict()\n\n    gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.download_patch","title":"download_patch","text":"<pre><code>download_patch(idx: PatchIndex[Item]) -&gt; xr.Dataset\n</code></pre> <p>Download the data for the given patch.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded patch data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def download_patch(self, idx: PatchIndex[\"Item\"]) -&gt; xr.Dataset:\n    \"\"\"Download the data for the given patch.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        idx (PatchIndex[Item]): The reference patch to download the data for.\n\n    Returns:\n        xr.Dataset: The downloaded patch data.\n\n    \"\"\"\n    from odc.stac import stac_load\n\n    patch = stac_load([idx.item], bands=self.channels, chunks=None, progress=None)\n\n    # Do a mosaic if multiple items are returned for non-temporal data\n    if \"time\" in patch.dims and self.temporal_extent is None:\n        patch = patch.max(\"time\")\n\n    return patch\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.download_patch(idx)","title":"<code>idx</code>","text":"(<code>PatchIndex[Item]</code>)           \u2013            <p>The reference patch to download the data for.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.load","title":"load","text":"<pre><code>load(\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load(\n    self,\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        aoi (Geometry | GeoBox): The reference geometry to load the data for. If a Geobox is provided,\n            it will use the extent of the geobox.\n        toi (TOI): The temporal slice to load. Defaults to None.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    if toi is not None:\n        self.assert_temporal_cube()\n\n    if isinstance(aoi, GeoBox):\n        aoi = aoi.extent\n\n    with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        aligned_aoi = aoi.to_crs(self.extent.crs)\n        with self.stopuhr(f\"{_geometry_repr(aoi)}: Procedural download in blocking mode\"):\n            self.procedural_download(aligned_aoi, toi)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get temporal slice if time is provided\n        if toi is not None:\n            xrcube = xrcube.sel(time=toi)\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(aligned_aoi, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.load(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry | GeoBox</code>)           \u2013            <p>The reference geometry to load the data for. If a Geobox is provided, it will use the extent of the geobox.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.load(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>, default:                   <code>None</code> )           \u2013            <p>The temporal slice to load. Defaults to None.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    toi = None\n    if \"time\" in ref.coords and self.temporal_extent is not None:\n        toi = ref.get_index(\"time\")\n    return self.load(ref.geobox, toi=toi, **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.loaded_patches","title":"loaded_patches","text":"<pre><code>loaded_patches() -&gt; list[str]\n</code></pre> <p>Get the ids of already (down-)loaded patches.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>list[str]: A list of already loaded patch ids.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def loaded_patches(self) -&gt; list[str]:\n    \"\"\"Get the ids of already (down-)loaded patches.\n\n    Returns:\n        list[str]: A list of already loaded patch ids.\n\n    \"\"\"\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube.attrs.get(\"loaded_patches\", []).copy()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    return self.backend.open_xarray()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    return self.backend.open_zarr()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def post_create(self):\n    \"\"\"Download the ArcticDEM mosaic extent info and store it in the datacube.\"\"\"\n    _download_arcticdem_extent(self._aux_dir)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.post_init","title":"post_init","text":"<pre><code>post_init()\n</code></pre> <p>Check if the ArcticDEM mosaic extent info is already downloaded and downlaod if not.</p> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def post_init(self):\n    \"\"\"Check if the ArcticDEM mosaic extent info is already downloaded and downlaod if not.\"\"\"\n    required_files = [self._aux_dir / f\"ArcticDEM_Mosaic_Index_v4_1_{res}.parquet\" for res in [\"2m\", \"10m\", \"32m\"]]\n    if not all(file.exists() for file in required_files):\n        _download_arcticdem_extent(self._aux_dir)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(aoi: Geometry, toi: TOI)\n</code></pre> <p>Download tiles procedurally.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If not all downloads were successful.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def procedural_download(self, aoi: Geometry, toi: TOI):\n    \"\"\"Download tiles procedurally.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        aoi (Geometry): The geometry of the aoi to download.\n        toi (TOI): The time of interest to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If not all downloads were successful.\n\n    \"\"\"\n    adjacent_patches = self.adjacent_patches(aoi, toi)\n    # interest-string\n    soi = f\"{_geometry_repr(aoi)}\" + (f\" @ {_repr_toi(toi)}\" if toi is not None else \"\")\n    if not adjacent_patches:\n        logger.error(f\"{soi}: No adjacent patches found: {adjacent_patches=}\")\n        raise ValueError(\"No adjacent patches found - is the provided aoi and toi correct?\")\n\n    loaded_patches = self.loaded_patches()\n\n    new_patches = [patch for patch in adjacent_patches if patch.id not in loaded_patches]\n\n    logger.debug(f\"{soi}:  {len(adjacent_patches)=} &amp; {len(loaded_patches)=} -&gt; {len(new_patches)=} to download\")\n    if not new_patches:\n        return\n\n    # This raises Errors if anything goes wrong -&gt; we want to propagate\n    self.backend.submit(new_patches)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.procedural_download(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry</code>)           \u2013            <p>The geometry of the aoi to download.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.procedural_download(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    import cartopy.crs as ccrs\n    import cartopy.feature as cfeature\n    import matplotlib.path as mpath\n    import matplotlib.pyplot as plt\n\n    tile_info = self.current_state()\n\n    if tile_info is None:\n        raise ValueError(\"Datacube is not created or loaded yet. Can't visualize!\")\n\n    # Define the projection\n    projection = ccrs.Stereographic(central_latitude=90, central_longitude=-45, true_scale_latitude=70)\n\n    # Create a figure\n    fig = None\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": projection})\n\n    # Set the extent to focus on the North Pole\n    ax.set_extent([-180, 180, 50, 90], crs=ccrs.PlateCarree())\n\n    # Add features\n    ax.add_feature(cfeature.LAND, zorder=0, edgecolor=\"black\", facecolor=\"white\")\n    ax.add_feature(cfeature.OCEAN, zorder=0, facecolor=\"lightgrey\")\n    ax.add_feature(cfeature.COASTLINE)\n    ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n    ax.add_feature(cfeature.LAKES, alpha=0.5)\n    ax.add_feature(cfeature.RIVERS)\n\n    # Add gridlines\n    gl = ax.gridlines(draw_labels=True)\n    gl.top_labels = False\n    gl.right_labels = False\n\n    # Compute a circle in axes coordinates, which we can use as a boundary\n    # for the map. We can pan/zoom as much as we like - the boundary will be\n    # permanently circular.\n    theta = np.linspace(0, 2 * np.pi, 100)\n    center, radius = [0.5, 0.5], 0.5\n    verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n    circle = mpath.Path(verts * radius + center)\n\n    ax.set_boundary(circle, transform=ax.transAxes)\n\n    tile_info.plot(\n        \"title\",\n        ax=ax,\n        transform=ccrs.PlateCarree(),\n        edgecolor=\"black\",\n        categorical=True,\n        aspect=\"equal\",\n        alpha=0.5,\n    )\n\n    if fig is not None:\n        return fig\n    else:\n        return ax\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m","title":"ArcticDEM32m","text":"<pre><code>ArcticDEM32m(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n)\n</code></pre> <p>               Bases: <code>ArcticDEMABC</code></p> <p>Accessor for ArcticDEM 32m data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the underlaying zarr array. Should be equal to the extent geobox. However, this property is used to find the target index of the downloaded data, so better save than sorry.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_patches</code>             \u2013              <p>Get adjacent patch indexes from a STAC API.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>assert_temporal_cube</code>             \u2013              <p>Assert that the datacube has a temporal dimension.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_patch</code>             \u2013              <p>Download the data for the given patch.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>loaded_patches</code>             \u2013              <p>Get the ids of already (down-)loaded patches.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> </li> <li> <code>post_init</code>             \u2013              <p>Check if the ArcticDEM mosaic extent info is already downloaded and downlaod if not.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download tiles procedurally.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n        backend (Literal[\"threaded\", \"simple\"], optional): The backend to use for downloading data.\n            Currently, only \"threaded\" is supported. Defaults to \"threaded\".\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = Chronometer(logger.debug)\n\n    if backend == \"threaded\":\n        if not _check_python_version(3, 13):\n            raise NotImplementedError(\n                \"The 'threaded' backend is only fully supported in Python 3.13 and above.\"\n                \" Please consider using the 'simple' backend in a multiprocessing environment\"\n                \" or upgrade your Python version.\"\n            )\n        self.backend = ThreadedBackend(self.repo, self.download_patch)\n    elif backend == \"simple\":\n        self.backend = SimpleBackend(self.repo, self.download_patch)\n    else:\n        raise ValueError(f\"Unknown backend {backend}\")\n\n    self.post_init()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m(backend)","title":"<code>backend</code>","text":"(<code>Literal['threaded', 'simple']</code>, default:                   <code>'threaded'</code> )           \u2013            <p>The backend to use for downloading data. Currently, only \"threaded\" is supported. Defaults to \"threaded\".</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre> <p>Check if the datacube already exists in the storage.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.is_temporal","title":"is_temporal  <code>property</code>","text":"<pre><code>is_temporal: bool\n</code></pre> <p>Check if the datacube has a temporal dimension.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube has a temporal dimension.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.adjacent_patches","title":"adjacent_patches","text":"<pre><code>adjacent_patches(\n    roi: Geometry | GeoBox | GeoDataFrame, toi: TOI\n) -&gt; list[PatchIndex]\n</code></pre> <p>Get adjacent patch indexes from a STAC API.</p> <p>Overwrite the default implementation from the STAC accessor to use pre-downloaded extent files instead of querying the STAC API. This results in a faster loading time, but requires the extent files to be downloaded beforehand. This is done in the post_create step.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[PatchIndex]</code>           \u2013            <p>list[PatchIndex]: List of adjacent patches, wrapped in own datastructure for easier processing.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the roi is not a GeoBox or a GeoDataFrame.</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def adjacent_patches(self, roi: Geometry | GeoBox | gpd.GeoDataFrame, toi: TOI) -&gt; list[PatchIndex]:\n    \"\"\"Get adjacent patch indexes from a STAC API.\n\n    Overwrite the default implementation from the STAC accessor\n    to use pre-downloaded extent files instead of querying the STAC API.\n    This results in a faster loading time, but requires the extent files to be downloaded beforehand.\n    This is done in the post_create step.\n\n    Args:\n        roi (Geometry | GeoBox | gpd.GeoDataFrame): The reference geometry, geobox or reference geodataframe\n        toi (TOI): The time of interest to download.\n            Not used in this implementation since ArcticDEM is not temporal.\n\n    Returns:\n        list[PatchIndex]: List of adjacent patches, wrapped in own datastructure for easier processing.\n\n    Raises:\n        ValueError: If the roi is not a GeoBox or a GeoDataFrame.\n\n    \"\"\"\n    # Assumes that the extent files are already present and the datacube is already created\n    self.assert_created()\n\n    resolution = f\"{int(self.extent.resolution.x)}m\"\n    extent_info = gpd.read_parquet(self._aux_dir / f\"ArcticDEM_Mosaic_Index_v4_1_{resolution}.parquet\")\n    if isinstance(roi, gpd.GeoDataFrame):\n        adjacent_tiles = (\n            gpd.sjoin(\n                extent_info,\n                roi[[\"geometry\"]].to_crs(self.extent.crs.wkt),\n                how=\"inner\",\n                predicate=\"intersects\",\n            )\n            .reset_index()\n            .drop_duplicates(subset=\"index\", keep=\"first\", ignore_index=True)\n        )\n    elif isinstance(roi, GeoBox):\n        adjacent_tiles = extent_info.loc[extent_info.intersects(roi.boundingbox.polygon.geom)].copy()\n    elif isinstance(roi, Geometry):\n        adjacent_tiles = extent_info.loc[extent_info.intersects(roi.geom)].copy()\n    else:\n        raise ValueError(\"roi must be a GeoBox or a GeoDataFrame\")\n    if adjacent_tiles.empty:\n        return []\n    return [\n        LazyStacPatchIndex(tile.dem_id, _get_stac_url(tile.dem_id, resolution))\n        for tile in adjacent_tiles.itertuples()\n    ]\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.adjacent_patches(roi)","title":"<code>roi</code>","text":"(<code>Geometry | GeoBox | GeoDataFrame</code>)           \u2013            <p>The reference geometry, geobox or reference geodataframe</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.adjacent_patches(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download. Not used in this implementation since ArcticDEM is not temporal.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\"\"\"\n    self.backend.assert_created()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.assert_temporal_cube","title":"assert_temporal_cube","text":"<pre><code>assert_temporal_cube()\n</code></pre> <p>Assert that the datacube has a temporal dimension.</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube has no temporal dimension.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_temporal_cube(self):\n    \"\"\"Assert that the datacube has a temporal dimension.\n\n    Raises:\n        ValueError: If the datacube has no temporal dimension.\n\n    \"\"\"\n    if self.temporal_extent is None:\n        msg = f\"Datacube {self.title} has no temporal dimension.\"\n        logger.error(msg)\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.create","title":"create","text":"<pre><code>create(overwrite: bool = False, exists_ok: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location and exists_ok is False.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def create(self, overwrite: bool = False, exists_ok: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube.\n            Has no effect if exists_ok is True. Defaults to False.\n        exists_ok (bool, optional): Do not raise an error if the datacube already exists.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location and exists_ok is False.\n\n    \"\"\"\n    if exists_ok and self.created:\n        logger.debug(\"Datacube was already created.\")\n        return\n\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Expand to temporal dimension if defined\n        if self.temporal_extent is not None:\n            ds = ds.expand_dims(time=self.temporal_extent)\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        if self.temporal_extent is not None:\n            coords_encoding[\"time\"] = {\"chunks\": ds.time.shape, **optimize_temporal_encoding(self.temporal_extent)}\n        chunks = (\n            (1, self.chunk_size, self.chunk_size)\n            if self.temporal_extent is not None\n            else (self.chunk_size, self.chunk_size)\n        )\n        var_encoding = {\n            name: {\n                \"chunks\": chunks,\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Has no effect if exists_ok is True. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.create(exists_ok)","title":"<code>exists_ok</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Do not raise an error if the datacube already exists.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.\n\n    \"\"\"\n    import geopandas as gpd\n    import pystac_client\n\n    if not self.created:\n        return None\n\n    loaded_patches = self.loaded_patches()\n\n    if len(loaded_patches) == 0:\n        return None\n\n    catalog = pystac_client.Client.open(self.stac_api_url)\n    search = catalog.search(collections=[self.collection], ids=loaded_patches)\n    stac_json = search.item_collection_as_dict()\n\n    gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.download_patch","title":"download_patch","text":"<pre><code>download_patch(idx: PatchIndex[Item]) -&gt; xr.Dataset\n</code></pre> <p>Download the data for the given patch.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded patch data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def download_patch(self, idx: PatchIndex[\"Item\"]) -&gt; xr.Dataset:\n    \"\"\"Download the data for the given patch.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        idx (PatchIndex[Item]): The reference patch to download the data for.\n\n    Returns:\n        xr.Dataset: The downloaded patch data.\n\n    \"\"\"\n    from odc.stac import stac_load\n\n    patch = stac_load([idx.item], bands=self.channels, chunks=None, progress=None)\n\n    # Do a mosaic if multiple items are returned for non-temporal data\n    if \"time\" in patch.dims and self.temporal_extent is None:\n        patch = patch.max(\"time\")\n\n    return patch\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.download_patch(idx)","title":"<code>idx</code>","text":"(<code>PatchIndex[Item]</code>)           \u2013            <p>The reference patch to download the data for.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.load","title":"load","text":"<pre><code>load(\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load(\n    self,\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        aoi (Geometry | GeoBox): The reference geometry to load the data for. If a Geobox is provided,\n            it will use the extent of the geobox.\n        toi (TOI): The temporal slice to load. Defaults to None.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    if toi is not None:\n        self.assert_temporal_cube()\n\n    if isinstance(aoi, GeoBox):\n        aoi = aoi.extent\n\n    with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        aligned_aoi = aoi.to_crs(self.extent.crs)\n        with self.stopuhr(f\"{_geometry_repr(aoi)}: Procedural download in blocking mode\"):\n            self.procedural_download(aligned_aoi, toi)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get temporal slice if time is provided\n        if toi is not None:\n            xrcube = xrcube.sel(time=toi)\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(aligned_aoi, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.load(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry | GeoBox</code>)           \u2013            <p>The reference geometry to load the data for. If a Geobox is provided, it will use the extent of the geobox.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.load(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>, default:                   <code>None</code> )           \u2013            <p>The temporal slice to load. Defaults to None.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    toi = None\n    if \"time\" in ref.coords and self.temporal_extent is not None:\n        toi = ref.get_index(\"time\")\n    return self.load(ref.geobox, toi=toi, **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.loaded_patches","title":"loaded_patches","text":"<pre><code>loaded_patches() -&gt; list[str]\n</code></pre> <p>Get the ids of already (down-)loaded patches.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>list[str]: A list of already loaded patch ids.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def loaded_patches(self) -&gt; list[str]:\n    \"\"\"Get the ids of already (down-)loaded patches.\n\n    Returns:\n        list[str]: A list of already loaded patch ids.\n\n    \"\"\"\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube.attrs.get(\"loaded_patches\", []).copy()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    return self.backend.open_xarray()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    return self.backend.open_zarr()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def post_create(self):\n    \"\"\"Download the ArcticDEM mosaic extent info and store it in the datacube.\"\"\"\n    _download_arcticdem_extent(self._aux_dir)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.post_init","title":"post_init","text":"<pre><code>post_init()\n</code></pre> <p>Check if the ArcticDEM mosaic extent info is already downloaded and downlaod if not.</p> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def post_init(self):\n    \"\"\"Check if the ArcticDEM mosaic extent info is already downloaded and downlaod if not.\"\"\"\n    required_files = [self._aux_dir / f\"ArcticDEM_Mosaic_Index_v4_1_{res}.parquet\" for res in [\"2m\", \"10m\", \"32m\"]]\n    if not all(file.exists() for file in required_files):\n        _download_arcticdem_extent(self._aux_dir)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(aoi: Geometry, toi: TOI)\n</code></pre> <p>Download tiles procedurally.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If not all downloads were successful.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def procedural_download(self, aoi: Geometry, toi: TOI):\n    \"\"\"Download tiles procedurally.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        aoi (Geometry): The geometry of the aoi to download.\n        toi (TOI): The time of interest to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If not all downloads were successful.\n\n    \"\"\"\n    adjacent_patches = self.adjacent_patches(aoi, toi)\n    # interest-string\n    soi = f\"{_geometry_repr(aoi)}\" + (f\" @ {_repr_toi(toi)}\" if toi is not None else \"\")\n    if not adjacent_patches:\n        logger.error(f\"{soi}: No adjacent patches found: {adjacent_patches=}\")\n        raise ValueError(\"No adjacent patches found - is the provided aoi and toi correct?\")\n\n    loaded_patches = self.loaded_patches()\n\n    new_patches = [patch for patch in adjacent_patches if patch.id not in loaded_patches]\n\n    logger.debug(f\"{soi}:  {len(adjacent_patches)=} &amp; {len(loaded_patches)=} -&gt; {len(new_patches)=} to download\")\n    if not new_patches:\n        return\n\n    # This raises Errors if anything goes wrong -&gt; we want to propagate\n    self.backend.submit(new_patches)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.procedural_download(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry</code>)           \u2013            <p>The geometry of the aoi to download.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.procedural_download(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    import cartopy.crs as ccrs\n    import cartopy.feature as cfeature\n    import matplotlib.path as mpath\n    import matplotlib.pyplot as plt\n\n    tile_info = self.current_state()\n\n    if tile_info is None:\n        raise ValueError(\"Datacube is not created or loaded yet. Can't visualize!\")\n\n    # Define the projection\n    projection = ccrs.Stereographic(central_latitude=90, central_longitude=-45, true_scale_latitude=70)\n\n    # Create a figure\n    fig = None\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": projection})\n\n    # Set the extent to focus on the North Pole\n    ax.set_extent([-180, 180, 50, 90], crs=ccrs.PlateCarree())\n\n    # Add features\n    ax.add_feature(cfeature.LAND, zorder=0, edgecolor=\"black\", facecolor=\"white\")\n    ax.add_feature(cfeature.OCEAN, zorder=0, facecolor=\"lightgrey\")\n    ax.add_feature(cfeature.COASTLINE)\n    ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n    ax.add_feature(cfeature.LAKES, alpha=0.5)\n    ax.add_feature(cfeature.RIVERS)\n\n    # Add gridlines\n    gl = ax.gridlines(draw_labels=True)\n    gl.top_labels = False\n    gl.right_labels = False\n\n    # Compute a circle in axes coordinates, which we can use as a boundary\n    # for the map. We can pan/zoom as much as we like - the boundary will be\n    # permanently circular.\n    theta = np.linspace(0, 2 * np.pi, 100)\n    center, radius = [0.5, 0.5], 0.5\n    verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n    circle = mpath.Path(verts * radius + center)\n\n    ax.set_boundary(circle, transform=ax.transAxes)\n\n    tile_info.plot(\n        \"title\",\n        ax=ax,\n        transform=ccrs.PlateCarree(),\n        edgecolor=\"black\",\n        categorical=True,\n        aspect=\"equal\",\n        alpha=0.5,\n    )\n\n    if fig is not None:\n        return fig\n    else:\n        return ax\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC","title":"ArcticDEMABC","text":"<pre><code>ArcticDEMABC(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n)\n</code></pre> <p>               Bases: <code>STACAccessor</code></p> <p>ABC for Arcticdem data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the underlaying zarr array. Should be equal to the extent geobox. However, this property is used to find the target index of the downloaded data, so better save than sorry.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_patches</code>             \u2013              <p>Get adjacent patch indexes from a STAC API.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>assert_temporal_cube</code>             \u2013              <p>Assert that the datacube has a temporal dimension.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_patch</code>             \u2013              <p>Download the data for the given patch.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>loaded_patches</code>             \u2013              <p>Get the ids of already (down-)loaded patches.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> </li> <li> <code>post_init</code>             \u2013              <p>Check if the ArcticDEM mosaic extent info is already downloaded and downlaod if not.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download tiles procedurally.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n        backend (Literal[\"threaded\", \"simple\"], optional): The backend to use for downloading data.\n            Currently, only \"threaded\" is supported. Defaults to \"threaded\".\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = Chronometer(logger.debug)\n\n    if backend == \"threaded\":\n        if not _check_python_version(3, 13):\n            raise NotImplementedError(\n                \"The 'threaded' backend is only fully supported in Python 3.13 and above.\"\n                \" Please consider using the 'simple' backend in a multiprocessing environment\"\n                \" or upgrade your Python version.\"\n            )\n        self.backend = ThreadedBackend(self.repo, self.download_patch)\n    elif backend == \"simple\":\n        self.backend = SimpleBackend(self.repo, self.download_patch)\n    else:\n        raise ValueError(f\"Unknown backend {backend}\")\n\n    self.post_init()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC(backend)","title":"<code>backend</code>","text":"(<code>Literal['threaded', 'simple']</code>, default:                   <code>'threaded'</code> )           \u2013            <p>The backend to use for downloading data. Currently, only \"threaded\" is supported. Defaults to \"threaded\".</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre> <p>Check if the datacube already exists in the storage.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.is_temporal","title":"is_temporal  <code>property</code>","text":"<pre><code>is_temporal: bool\n</code></pre> <p>Check if the datacube has a temporal dimension.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube has a temporal dimension.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.adjacent_patches","title":"adjacent_patches","text":"<pre><code>adjacent_patches(\n    roi: Geometry | GeoBox | GeoDataFrame, toi: TOI\n) -&gt; list[PatchIndex]\n</code></pre> <p>Get adjacent patch indexes from a STAC API.</p> <p>Overwrite the default implementation from the STAC accessor to use pre-downloaded extent files instead of querying the STAC API. This results in a faster loading time, but requires the extent files to be downloaded beforehand. This is done in the post_create step.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[PatchIndex]</code>           \u2013            <p>list[PatchIndex]: List of adjacent patches, wrapped in own datastructure for easier processing.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the roi is not a GeoBox or a GeoDataFrame.</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def adjacent_patches(self, roi: Geometry | GeoBox | gpd.GeoDataFrame, toi: TOI) -&gt; list[PatchIndex]:\n    \"\"\"Get adjacent patch indexes from a STAC API.\n\n    Overwrite the default implementation from the STAC accessor\n    to use pre-downloaded extent files instead of querying the STAC API.\n    This results in a faster loading time, but requires the extent files to be downloaded beforehand.\n    This is done in the post_create step.\n\n    Args:\n        roi (Geometry | GeoBox | gpd.GeoDataFrame): The reference geometry, geobox or reference geodataframe\n        toi (TOI): The time of interest to download.\n            Not used in this implementation since ArcticDEM is not temporal.\n\n    Returns:\n        list[PatchIndex]: List of adjacent patches, wrapped in own datastructure for easier processing.\n\n    Raises:\n        ValueError: If the roi is not a GeoBox or a GeoDataFrame.\n\n    \"\"\"\n    # Assumes that the extent files are already present and the datacube is already created\n    self.assert_created()\n\n    resolution = f\"{int(self.extent.resolution.x)}m\"\n    extent_info = gpd.read_parquet(self._aux_dir / f\"ArcticDEM_Mosaic_Index_v4_1_{resolution}.parquet\")\n    if isinstance(roi, gpd.GeoDataFrame):\n        adjacent_tiles = (\n            gpd.sjoin(\n                extent_info,\n                roi[[\"geometry\"]].to_crs(self.extent.crs.wkt),\n                how=\"inner\",\n                predicate=\"intersects\",\n            )\n            .reset_index()\n            .drop_duplicates(subset=\"index\", keep=\"first\", ignore_index=True)\n        )\n    elif isinstance(roi, GeoBox):\n        adjacent_tiles = extent_info.loc[extent_info.intersects(roi.boundingbox.polygon.geom)].copy()\n    elif isinstance(roi, Geometry):\n        adjacent_tiles = extent_info.loc[extent_info.intersects(roi.geom)].copy()\n    else:\n        raise ValueError(\"roi must be a GeoBox or a GeoDataFrame\")\n    if adjacent_tiles.empty:\n        return []\n    return [\n        LazyStacPatchIndex(tile.dem_id, _get_stac_url(tile.dem_id, resolution))\n        for tile in adjacent_tiles.itertuples()\n    ]\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.adjacent_patches(roi)","title":"<code>roi</code>","text":"(<code>Geometry | GeoBox | GeoDataFrame</code>)           \u2013            <p>The reference geometry, geobox or reference geodataframe</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.adjacent_patches(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download. Not used in this implementation since ArcticDEM is not temporal.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\"\"\"\n    self.backend.assert_created()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.assert_temporal_cube","title":"assert_temporal_cube","text":"<pre><code>assert_temporal_cube()\n</code></pre> <p>Assert that the datacube has a temporal dimension.</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube has no temporal dimension.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_temporal_cube(self):\n    \"\"\"Assert that the datacube has a temporal dimension.\n\n    Raises:\n        ValueError: If the datacube has no temporal dimension.\n\n    \"\"\"\n    if self.temporal_extent is None:\n        msg = f\"Datacube {self.title} has no temporal dimension.\"\n        logger.error(msg)\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.create","title":"create","text":"<pre><code>create(overwrite: bool = False, exists_ok: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location and exists_ok is False.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def create(self, overwrite: bool = False, exists_ok: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube.\n            Has no effect if exists_ok is True. Defaults to False.\n        exists_ok (bool, optional): Do not raise an error if the datacube already exists.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location and exists_ok is False.\n\n    \"\"\"\n    if exists_ok and self.created:\n        logger.debug(\"Datacube was already created.\")\n        return\n\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Expand to temporal dimension if defined\n        if self.temporal_extent is not None:\n            ds = ds.expand_dims(time=self.temporal_extent)\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        if self.temporal_extent is not None:\n            coords_encoding[\"time\"] = {\"chunks\": ds.time.shape, **optimize_temporal_encoding(self.temporal_extent)}\n        chunks = (\n            (1, self.chunk_size, self.chunk_size)\n            if self.temporal_extent is not None\n            else (self.chunk_size, self.chunk_size)\n        )\n        var_encoding = {\n            name: {\n                \"chunks\": chunks,\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Has no effect if exists_ok is True. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.create(exists_ok)","title":"<code>exists_ok</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Do not raise an error if the datacube already exists.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.\n\n    \"\"\"\n    import geopandas as gpd\n    import pystac_client\n\n    if not self.created:\n        return None\n\n    loaded_patches = self.loaded_patches()\n\n    if len(loaded_patches) == 0:\n        return None\n\n    catalog = pystac_client.Client.open(self.stac_api_url)\n    search = catalog.search(collections=[self.collection], ids=loaded_patches)\n    stac_json = search.item_collection_as_dict()\n\n    gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.download_patch","title":"download_patch","text":"<pre><code>download_patch(idx: PatchIndex[Item]) -&gt; xr.Dataset\n</code></pre> <p>Download the data for the given patch.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded patch data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def download_patch(self, idx: PatchIndex[\"Item\"]) -&gt; xr.Dataset:\n    \"\"\"Download the data for the given patch.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        idx (PatchIndex[Item]): The reference patch to download the data for.\n\n    Returns:\n        xr.Dataset: The downloaded patch data.\n\n    \"\"\"\n    from odc.stac import stac_load\n\n    patch = stac_load([idx.item], bands=self.channels, chunks=None, progress=None)\n\n    # Do a mosaic if multiple items are returned for non-temporal data\n    if \"time\" in patch.dims and self.temporal_extent is None:\n        patch = patch.max(\"time\")\n\n    return patch\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.download_patch(idx)","title":"<code>idx</code>","text":"(<code>PatchIndex[Item]</code>)           \u2013            <p>The reference patch to download the data for.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.load","title":"load","text":"<pre><code>load(\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load(\n    self,\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        aoi (Geometry | GeoBox): The reference geometry to load the data for. If a Geobox is provided,\n            it will use the extent of the geobox.\n        toi (TOI): The temporal slice to load. Defaults to None.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    if toi is not None:\n        self.assert_temporal_cube()\n\n    if isinstance(aoi, GeoBox):\n        aoi = aoi.extent\n\n    with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        aligned_aoi = aoi.to_crs(self.extent.crs)\n        with self.stopuhr(f\"{_geometry_repr(aoi)}: Procedural download in blocking mode\"):\n            self.procedural_download(aligned_aoi, toi)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get temporal slice if time is provided\n        if toi is not None:\n            xrcube = xrcube.sel(time=toi)\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(aligned_aoi, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.load(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry | GeoBox</code>)           \u2013            <p>The reference geometry to load the data for. If a Geobox is provided, it will use the extent of the geobox.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.load(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>, default:                   <code>None</code> )           \u2013            <p>The temporal slice to load. Defaults to None.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    toi = None\n    if \"time\" in ref.coords and self.temporal_extent is not None:\n        toi = ref.get_index(\"time\")\n    return self.load(ref.geobox, toi=toi, **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.loaded_patches","title":"loaded_patches","text":"<pre><code>loaded_patches() -&gt; list[str]\n</code></pre> <p>Get the ids of already (down-)loaded patches.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>list[str]: A list of already loaded patch ids.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def loaded_patches(self) -&gt; list[str]:\n    \"\"\"Get the ids of already (down-)loaded patches.\n\n    Returns:\n        list[str]: A list of already loaded patch ids.\n\n    \"\"\"\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube.attrs.get(\"loaded_patches\", []).copy()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    return self.backend.open_xarray()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    return self.backend.open_zarr()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def post_create(self):\n    \"\"\"Download the ArcticDEM mosaic extent info and store it in the datacube.\"\"\"\n    _download_arcticdem_extent(self._aux_dir)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.post_init","title":"post_init","text":"<pre><code>post_init()\n</code></pre> <p>Check if the ArcticDEM mosaic extent info is already downloaded and downlaod if not.</p> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def post_init(self):\n    \"\"\"Check if the ArcticDEM mosaic extent info is already downloaded and downlaod if not.\"\"\"\n    required_files = [self._aux_dir / f\"ArcticDEM_Mosaic_Index_v4_1_{res}.parquet\" for res in [\"2m\", \"10m\", \"32m\"]]\n    if not all(file.exists() for file in required_files):\n        _download_arcticdem_extent(self._aux_dir)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(aoi: Geometry, toi: TOI)\n</code></pre> <p>Download tiles procedurally.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If not all downloads were successful.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def procedural_download(self, aoi: Geometry, toi: TOI):\n    \"\"\"Download tiles procedurally.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        aoi (Geometry): The geometry of the aoi to download.\n        toi (TOI): The time of interest to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If not all downloads were successful.\n\n    \"\"\"\n    adjacent_patches = self.adjacent_patches(aoi, toi)\n    # interest-string\n    soi = f\"{_geometry_repr(aoi)}\" + (f\" @ {_repr_toi(toi)}\" if toi is not None else \"\")\n    if not adjacent_patches:\n        logger.error(f\"{soi}: No adjacent patches found: {adjacent_patches=}\")\n        raise ValueError(\"No adjacent patches found - is the provided aoi and toi correct?\")\n\n    loaded_patches = self.loaded_patches()\n\n    new_patches = [patch for patch in adjacent_patches if patch.id not in loaded_patches]\n\n    logger.debug(f\"{soi}:  {len(adjacent_patches)=} &amp; {len(loaded_patches)=} -&gt; {len(new_patches)=} to download\")\n    if not new_patches:\n        return\n\n    # This raises Errors if anything goes wrong -&gt; we want to propagate\n    self.backend.submit(new_patches)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.procedural_download(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry</code>)           \u2013            <p>The geometry of the aoi to download.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.procedural_download(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    import cartopy.crs as ccrs\n    import cartopy.feature as cfeature\n    import matplotlib.path as mpath\n    import matplotlib.pyplot as plt\n\n    tile_info = self.current_state()\n\n    if tile_info is None:\n        raise ValueError(\"Datacube is not created or loaded yet. Can't visualize!\")\n\n    # Define the projection\n    projection = ccrs.Stereographic(central_latitude=90, central_longitude=-45, true_scale_latitude=70)\n\n    # Create a figure\n    fig = None\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": projection})\n\n    # Set the extent to focus on the North Pole\n    ax.set_extent([-180, 180, 50, 90], crs=ccrs.PlateCarree())\n\n    # Add features\n    ax.add_feature(cfeature.LAND, zorder=0, edgecolor=\"black\", facecolor=\"white\")\n    ax.add_feature(cfeature.OCEAN, zorder=0, facecolor=\"lightgrey\")\n    ax.add_feature(cfeature.COASTLINE)\n    ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n    ax.add_feature(cfeature.LAKES, alpha=0.5)\n    ax.add_feature(cfeature.RIVERS)\n\n    # Add gridlines\n    gl = ax.gridlines(draw_labels=True)\n    gl.top_labels = False\n    gl.right_labels = False\n\n    # Compute a circle in axes coordinates, which we can use as a boundary\n    # for the map. We can pan/zoom as much as we like - the boundary will be\n    # permanently circular.\n    theta = np.linspace(0, 2 * np.pi, 100)\n    center, radius = [0.5, 0.5], 0.5\n    verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n    circle = mpath.Path(verts * radius + center)\n\n    ax.set_boundary(circle, transform=ax.transAxes)\n\n    tile_info.plot(\n        \"title\",\n        ax=ax,\n        transform=ccrs.PlateCarree(),\n        edgecolor=\"black\",\n        categorical=True,\n        aspect=\"equal\",\n        alpha=0.5,\n    )\n\n    if fig is not None:\n        return fig\n    else:\n        return ax\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.LazyStacPatchIndex","title":"LazyStacPatchIndex","text":"<pre><code>LazyStacPatchIndex(patch_id: str, stac_file: str)\n</code></pre> <p>Lazy wrapper for a PatchIndex containing a STAC Item.</p> <p>This is necessary since the download function of the STAC accessor expects a TileWrapper object containing a pystac.Item.</p> <p>However, creating such a pystac Item always fetches the metadata from the STAC API. For just loading the ArcticDEM data, we don't need this pystac Item. Hence, we create it lazily when it is actually needed.</p> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def __init__(self, patch_id: str, stac_file: str):  # noqa: D107\n    self.id = patch_id\n    self.stac_file = stac_file\n\n    # time is not used\n    self.time = None\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/","title":"tctrend","text":""},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend","title":"smart_geocubes.datasets.tctrend","text":"<p>Predefined accessor for TCTrend data.</p> <p>Classes:</p> <ul> <li> <code>TCTrend2019</code>           \u2013            <p>Accessor for TCTrend data derived from 2000-2019.</p> </li> <li> <code>TCTrend2020</code>           \u2013            <p>Accessor for TCTrend data derived from 2001-2020.</p> </li> <li> <code>TCTrend2022</code>           \u2013            <p>Accessor for TCTrend data derived from 2003-2022.</p> </li> <li> <code>TCTrendABC</code>           \u2013            <p>ABC for TCTrend data.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019","title":"TCTrend2019","text":"<pre><code>TCTrend2019(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n)\n</code></pre> <p>               Bases: <code>TCTrendABC</code></p> <p>Accessor for TCTrend data derived from 2000-2019.</p> <p>Attributes:</p> <ul> <li> <code>collection</code>               (<code>str</code>)           \u2013            <p>The collection ID of the datacube.</p> </li> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the zarr array. Should be equal to the extent geobox.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_patches</code>             \u2013              <p>Get the adjacent patches for the given geobox.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>assert_temporal_cube</code>             \u2013              <p>Assert that the datacube has a temporal dimension.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_patch</code>             \u2013              <p>Download the data for the given patch.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>loaded_patches</code>             \u2013              <p>Get the ids of already (down-)loaded patches.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Post create actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>post_init</code>             \u2013              <p>Post init actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download tiles procedurally.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n        backend (Literal[\"threaded\", \"simple\"], optional): The backend to use for downloading data.\n            Currently, only \"threaded\" is supported. Defaults to \"threaded\".\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = Chronometer(logger.debug)\n\n    if backend == \"threaded\":\n        if not _check_python_version(3, 13):\n            raise NotImplementedError(\n                \"The 'threaded' backend is only fully supported in Python 3.13 and above.\"\n                \" Please consider using the 'simple' backend in a multiprocessing environment\"\n                \" or upgrade your Python version.\"\n            )\n        self.backend = ThreadedBackend(self.repo, self.download_patch)\n    elif backend == \"simple\":\n        self.backend = SimpleBackend(self.repo, self.download_patch)\n    else:\n        raise ValueError(f\"Unknown backend {backend}\")\n\n    self.post_init()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019(backend)","title":"<code>backend</code>","text":"(<code>Literal['threaded', 'simple']</code>, default:                   <code>'threaded'</code> )           \u2013            <p>The backend to use for downloading data. Currently, only \"threaded\" is supported. Defaults to \"threaded\".</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre> <p>Check if the datacube already exists in the storage.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.is_temporal","title":"is_temporal  <code>property</code>","text":"<pre><code>is_temporal: bool\n</code></pre> <p>Check if the datacube has a temporal dimension.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube has a temporal dimension.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.adjacent_patches","title":"adjacent_patches","text":"<pre><code>adjacent_patches(\n    roi: Geometry | GeoBox | GeoDataFrame, toi: TOI\n) -&gt; list[Item]\n</code></pre> <p>Get the adjacent patches for the given geobox.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[Item]</code>           \u2013            <p>list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the ROI type is invalid.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If the datacube is not temporal, but a time of interest is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def adjacent_patches(self, roi: Geometry | GeoBox | gpd.GeoDataFrame, toi: TOI) -&gt; list[Item]:\n    \"\"\"Get the adjacent patches for the given geobox.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        roi (Geometry | GeoBox | gpd.GeoDataFrame): The reference geometry, geobox or reference geodataframe\n        toi (TOI): The time of interest to download.\n\n    Returns:\n        list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.\n\n    Raises:\n        ValueError: If the ROI type is invalid.\n        ValueError: If the datacube is not temporal, but a time of interest is provided.\n\n    \"\"\"\n    if toi is not None and not self.is_temporal:\n        raise ValueError(\"Datacube is not temporal, but time of interest is provided.\")\n\n    if isinstance(roi, gpd.GeoDataFrame):\n        adjacent_geometries = (\n            gpd.sjoin(self._tile_geometries, roi.to_crs(self.extent.crs.wkt), how=\"inner\", predicate=\"intersects\")\n            .reset_index()\n            .drop_duplicates(subset=\"index\", keep=\"first\")\n            .set_index(\"index\")\n        )\n        spatial_idxs: list[tuple[int, int]] = list(adjacent_geometries[\"idx\"])\n    elif isinstance(roi, GeoBox):\n        spatial_idxs: list[tuple[int, int]] = list(self._extent_tiles.tiles(roi.extent))\n    elif isinstance(roi, Geometry):\n        spatial_idxs: list[tuple[int, int]] = list(self._extent_tiles.tiles(roi))\n    else:\n        raise ValueError(\"Invalid ROI type.\")\n\n    if not self.is_temporal:\n        return [\n            PatchIndex(\n                self._stringify_index(spatial_idx),\n                self._extent_tiles[spatial_idx].geographic_extent,\n                None,\n                Item(self._extent_tiles[spatial_idx], None),\n            )\n            for spatial_idx in spatial_idxs\n        ]\n\n    # Now datacube is temporal\n    toi = normalize_toi(self.temporal_extent, toi)\n    patch_idxs = []\n    for time in toi:\n        time_idx = self.temporal_extent.get_loc(time)\n        assert isinstance(time_idx, int), \"Non-Unique temporal extents are not supported!\"\n        for spatial_idx in spatial_idxs:\n            patch_idxs.append(\n                PatchIndex(\n                    self._stringify_index(spatial_idx, time_idx),\n                    self._extent_tiles[spatial_idx].geographic_extent,\n                    time,\n                    Item(self._extent_tiles[spatial_idx], time),\n                )\n            )\n    return patch_idxs\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.adjacent_patches(roi)","title":"<code>roi</code>","text":"(<code>Geometry | GeoBox | GeoDataFrame</code>)           \u2013            <p>The reference geometry, geobox or reference geodataframe</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.adjacent_patches(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\"\"\"\n    self.backend.assert_created()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.assert_temporal_cube","title":"assert_temporal_cube","text":"<pre><code>assert_temporal_cube()\n</code></pre> <p>Assert that the datacube has a temporal dimension.</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube has no temporal dimension.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_temporal_cube(self):\n    \"\"\"Assert that the datacube has a temporal dimension.\n\n    Raises:\n        ValueError: If the datacube has no temporal dimension.\n\n    \"\"\"\n    if self.temporal_extent is None:\n        msg = f\"Datacube {self.title} has no temporal dimension.\"\n        logger.error(msg)\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.create","title":"create","text":"<pre><code>create(overwrite: bool = False, exists_ok: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location and exists_ok is False.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def create(self, overwrite: bool = False, exists_ok: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube.\n            Has no effect if exists_ok is True. Defaults to False.\n        exists_ok (bool, optional): Do not raise an error if the datacube already exists.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location and exists_ok is False.\n\n    \"\"\"\n    if exists_ok and self.created:\n        logger.debug(\"Datacube was already created.\")\n        return\n\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Expand to temporal dimension if defined\n        if self.temporal_extent is not None:\n            ds = ds.expand_dims(time=self.temporal_extent)\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        if self.temporal_extent is not None:\n            coords_encoding[\"time\"] = {\"chunks\": ds.time.shape, **optimize_temporal_encoding(self.temporal_extent)}\n        chunks = (\n            (1, self.chunk_size, self.chunk_size)\n            if self.temporal_extent is not None\n            else (self.chunk_size, self.chunk_size)\n        )\n        var_encoding = {\n            name: {\n                \"chunks\": chunks,\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Has no effect if exists_ok is True. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.create(exists_ok)","title":"<code>exists_ok</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Do not raise an error if the datacube already exists.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.\n\n    \"\"\"\n    import geopandas as gpd\n\n    if not self.created:\n        return None\n\n    loaded_patches = self.loaded_patches()\n\n    if len(loaded_patches) == 0:\n        return None\n\n    patch_infos = []\n    for pid in loaded_patches:\n        spatial_idx, temporal_idx = self._parse_index(pid)\n        geometry = self._extent_tiles[spatial_idx].extent.geom\n        if self.is_temporal:\n            time = self.temporal_extent[temporal_idx]\n            patch_infos.append({\"geometry\": geometry, \"id\": pid, \"time\": time})\n        else:\n            patch_infos.append({\"geometry\": geometry, \"id\": pid})\n\n    gdf = gpd.GeoDataFrame(patch_infos, crs=self.extent.crs.to_wkt())\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.download_patch","title":"download_patch","text":"<pre><code>download_patch(idx: PatchIndex) -&gt; xr.Dataset\n</code></pre> <p>Download the data for the given patch.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded patch data.</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/tctrend.py</code> <pre><code>def download_patch(self, idx: PatchIndex) -&gt; xr.Dataset:\n    \"\"\"Download the data for the given patch.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        idx (PatchIndex): The reference patch to download the data for.\n\n    Returns:\n        xr.Dataset: The downloaded patch data.\n\n    \"\"\"\n    patch = super().download_patch(idx)\n\n    # ?: The following code handles the occurance of nan values when using mosaics\n    # Save original min-max values for each band for clipping later\n    clip_values = {\n        band: (patch[band].min().values.item(), patch[band].max().values.item()) for band in patch.data_vars\n    }\n\n    # Interpolate missing values (there are very few, so we actually can interpolate them)\n    patch.rio.set_spatial_dims(x_dim=\"x\", y_dim=\"y\", inplace=True)\n    for band in patch.data_vars:\n        patch[band] = patch[band].rio.write_nodata(np.nan).rio.interpolate_na()\n\n    # Convert to uint8\n    for band in patch.data_vars:\n        band_min, band_max = clip_values[band]\n        patch[band] = patch[band].clip(band_min, band_max, keep_attrs=True).astype(\"uint8\").rio.write_nodata(None)\n\n    return patch\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.download_patch(idx)","title":"<code>idx</code>","text":"(<code>PatchIndex</code>)           \u2013            <p>The reference patch to download the data for.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.load","title":"load","text":"<pre><code>load(\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load(\n    self,\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        aoi (Geometry | GeoBox): The reference geometry to load the data for. If a Geobox is provided,\n            it will use the extent of the geobox.\n        toi (TOI): The temporal slice to load. Defaults to None.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    if toi is not None:\n        self.assert_temporal_cube()\n\n    if isinstance(aoi, GeoBox):\n        aoi = aoi.extent\n\n    with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        aligned_aoi = aoi.to_crs(self.extent.crs)\n        with self.stopuhr(f\"{_geometry_repr(aoi)}: Procedural download in blocking mode\"):\n            self.procedural_download(aligned_aoi, toi)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get temporal slice if time is provided\n        if toi is not None:\n            xrcube = xrcube.sel(time=toi)\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(aligned_aoi, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.load(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry | GeoBox</code>)           \u2013            <p>The reference geometry to load the data for. If a Geobox is provided, it will use the extent of the geobox.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.load(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>, default:                   <code>None</code> )           \u2013            <p>The temporal slice to load. Defaults to None.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    toi = None\n    if \"time\" in ref.coords and self.temporal_extent is not None:\n        toi = ref.get_index(\"time\")\n    return self.load(ref.geobox, toi=toi, **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.loaded_patches","title":"loaded_patches","text":"<pre><code>loaded_patches() -&gt; list[str]\n</code></pre> <p>Get the ids of already (down-)loaded patches.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>list[str]: A list of already loaded patch ids.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def loaded_patches(self) -&gt; list[str]:\n    \"\"\"Get the ids of already (down-)loaded patches.\n\n    Returns:\n        list[str]: A list of already loaded patch ids.\n\n    \"\"\"\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube.attrs.get(\"loaded_patches\", []).copy()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    return self.backend.open_xarray()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    return self.backend.open_zarr()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Post create actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_create(self):\n    \"\"\"Post create actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.post_init","title":"post_init","text":"<pre><code>post_init()\n</code></pre> <p>Post init actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_init(self):\n    \"\"\"Post init actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(aoi: Geometry, toi: TOI)\n</code></pre> <p>Download tiles procedurally.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If not all downloads were successful.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def procedural_download(self, aoi: Geometry, toi: TOI):\n    \"\"\"Download tiles procedurally.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        aoi (Geometry): The geometry of the aoi to download.\n        toi (TOI): The time of interest to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If not all downloads were successful.\n\n    \"\"\"\n    adjacent_patches = self.adjacent_patches(aoi, toi)\n    # interest-string\n    soi = f\"{_geometry_repr(aoi)}\" + (f\" @ {_repr_toi(toi)}\" if toi is not None else \"\")\n    if not adjacent_patches:\n        logger.error(f\"{soi}: No adjacent patches found: {adjacent_patches=}\")\n        raise ValueError(\"No adjacent patches found - is the provided aoi and toi correct?\")\n\n    loaded_patches = self.loaded_patches()\n\n    new_patches = [patch for patch in adjacent_patches if patch.id not in loaded_patches]\n\n    logger.debug(f\"{soi}:  {len(adjacent_patches)=} &amp; {len(loaded_patches)=} -&gt; {len(new_patches)=} to download\")\n    if not new_patches:\n        return\n\n    # This raises Errors if anything goes wrong -&gt; we want to propagate\n    self.backend.submit(new_patches)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.procedural_download(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry</code>)           \u2013            <p>The geometry of the aoi to download.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.procedural_download(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/tctrend.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    import cartopy.crs as ccrs\n    import cartopy.feature as cfeature\n    import matplotlib.pyplot as plt\n\n    tile_info = self.current_state()\n\n    if tile_info is None:\n        raise ValueError(\"Datacube is not created or loaded yet. Can't visualize!\")\n\n    # Define the projection\n    projection = ccrs.PlateCarree()\n\n    # Create a figure\n    fig = None\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": projection})\n\n    # Set the extent to show the whole world\n    ax.set_extent([-180, 180, -90, 90], crs=ccrs.PlateCarree())\n\n    # Add features\n    ax.add_feature(cfeature.LAND, zorder=0, edgecolor=\"black\", facecolor=\"white\")\n    ax.add_feature(cfeature.OCEAN, zorder=0, facecolor=\"lightgrey\")\n    ax.add_feature(cfeature.COASTLINE)\n    ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n    ax.add_feature(cfeature.LAKES, alpha=0.5)\n    ax.add_feature(cfeature.RIVERS)\n\n    # Add gridlines\n    gl = ax.gridlines(draw_labels=True)\n    gl.top_labels = False\n    gl.right_labels = False\n\n    tile_info.plot(\n        \"id\",\n        ax=ax,\n        transform=ccrs.PlateCarree(),\n        edgecolor=\"black\",\n        categorical=True,\n        aspect=\"equal\",\n        alpha=0.5,\n    )\n\n    if fig is not None:\n        return fig\n    else:\n        return ax\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2019.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020","title":"TCTrend2020","text":"<pre><code>TCTrend2020(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n)\n</code></pre> <p>               Bases: <code>TCTrendABC</code></p> <p>Accessor for TCTrend data derived from 2001-2020.</p> <p>Attributes:</p> <ul> <li> <code>collection</code>               (<code>str</code>)           \u2013            <p>The collection ID of the datacube.</p> </li> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the zarr array. Should be equal to the extent geobox.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_patches</code>             \u2013              <p>Get the adjacent patches for the given geobox.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>assert_temporal_cube</code>             \u2013              <p>Assert that the datacube has a temporal dimension.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_patch</code>             \u2013              <p>Download the data for the given patch.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>loaded_patches</code>             \u2013              <p>Get the ids of already (down-)loaded patches.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Post create actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>post_init</code>             \u2013              <p>Post init actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download tiles procedurally.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n        backend (Literal[\"threaded\", \"simple\"], optional): The backend to use for downloading data.\n            Currently, only \"threaded\" is supported. Defaults to \"threaded\".\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = Chronometer(logger.debug)\n\n    if backend == \"threaded\":\n        if not _check_python_version(3, 13):\n            raise NotImplementedError(\n                \"The 'threaded' backend is only fully supported in Python 3.13 and above.\"\n                \" Please consider using the 'simple' backend in a multiprocessing environment\"\n                \" or upgrade your Python version.\"\n            )\n        self.backend = ThreadedBackend(self.repo, self.download_patch)\n    elif backend == \"simple\":\n        self.backend = SimpleBackend(self.repo, self.download_patch)\n    else:\n        raise ValueError(f\"Unknown backend {backend}\")\n\n    self.post_init()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020(backend)","title":"<code>backend</code>","text":"(<code>Literal['threaded', 'simple']</code>, default:                   <code>'threaded'</code> )           \u2013            <p>The backend to use for downloading data. Currently, only \"threaded\" is supported. Defaults to \"threaded\".</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre> <p>Check if the datacube already exists in the storage.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.is_temporal","title":"is_temporal  <code>property</code>","text":"<pre><code>is_temporal: bool\n</code></pre> <p>Check if the datacube has a temporal dimension.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube has a temporal dimension.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.adjacent_patches","title":"adjacent_patches","text":"<pre><code>adjacent_patches(\n    roi: Geometry | GeoBox | GeoDataFrame, toi: TOI\n) -&gt; list[Item]\n</code></pre> <p>Get the adjacent patches for the given geobox.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[Item]</code>           \u2013            <p>list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the ROI type is invalid.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If the datacube is not temporal, but a time of interest is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def adjacent_patches(self, roi: Geometry | GeoBox | gpd.GeoDataFrame, toi: TOI) -&gt; list[Item]:\n    \"\"\"Get the adjacent patches for the given geobox.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        roi (Geometry | GeoBox | gpd.GeoDataFrame): The reference geometry, geobox or reference geodataframe\n        toi (TOI): The time of interest to download.\n\n    Returns:\n        list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.\n\n    Raises:\n        ValueError: If the ROI type is invalid.\n        ValueError: If the datacube is not temporal, but a time of interest is provided.\n\n    \"\"\"\n    if toi is not None and not self.is_temporal:\n        raise ValueError(\"Datacube is not temporal, but time of interest is provided.\")\n\n    if isinstance(roi, gpd.GeoDataFrame):\n        adjacent_geometries = (\n            gpd.sjoin(self._tile_geometries, roi.to_crs(self.extent.crs.wkt), how=\"inner\", predicate=\"intersects\")\n            .reset_index()\n            .drop_duplicates(subset=\"index\", keep=\"first\")\n            .set_index(\"index\")\n        )\n        spatial_idxs: list[tuple[int, int]] = list(adjacent_geometries[\"idx\"])\n    elif isinstance(roi, GeoBox):\n        spatial_idxs: list[tuple[int, int]] = list(self._extent_tiles.tiles(roi.extent))\n    elif isinstance(roi, Geometry):\n        spatial_idxs: list[tuple[int, int]] = list(self._extent_tiles.tiles(roi))\n    else:\n        raise ValueError(\"Invalid ROI type.\")\n\n    if not self.is_temporal:\n        return [\n            PatchIndex(\n                self._stringify_index(spatial_idx),\n                self._extent_tiles[spatial_idx].geographic_extent,\n                None,\n                Item(self._extent_tiles[spatial_idx], None),\n            )\n            for spatial_idx in spatial_idxs\n        ]\n\n    # Now datacube is temporal\n    toi = normalize_toi(self.temporal_extent, toi)\n    patch_idxs = []\n    for time in toi:\n        time_idx = self.temporal_extent.get_loc(time)\n        assert isinstance(time_idx, int), \"Non-Unique temporal extents are not supported!\"\n        for spatial_idx in spatial_idxs:\n            patch_idxs.append(\n                PatchIndex(\n                    self._stringify_index(spatial_idx, time_idx),\n                    self._extent_tiles[spatial_idx].geographic_extent,\n                    time,\n                    Item(self._extent_tiles[spatial_idx], time),\n                )\n            )\n    return patch_idxs\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.adjacent_patches(roi)","title":"<code>roi</code>","text":"(<code>Geometry | GeoBox | GeoDataFrame</code>)           \u2013            <p>The reference geometry, geobox or reference geodataframe</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.adjacent_patches(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\"\"\"\n    self.backend.assert_created()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.assert_temporal_cube","title":"assert_temporal_cube","text":"<pre><code>assert_temporal_cube()\n</code></pre> <p>Assert that the datacube has a temporal dimension.</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube has no temporal dimension.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_temporal_cube(self):\n    \"\"\"Assert that the datacube has a temporal dimension.\n\n    Raises:\n        ValueError: If the datacube has no temporal dimension.\n\n    \"\"\"\n    if self.temporal_extent is None:\n        msg = f\"Datacube {self.title} has no temporal dimension.\"\n        logger.error(msg)\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.create","title":"create","text":"<pre><code>create(overwrite: bool = False, exists_ok: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location and exists_ok is False.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def create(self, overwrite: bool = False, exists_ok: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube.\n            Has no effect if exists_ok is True. Defaults to False.\n        exists_ok (bool, optional): Do not raise an error if the datacube already exists.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location and exists_ok is False.\n\n    \"\"\"\n    if exists_ok and self.created:\n        logger.debug(\"Datacube was already created.\")\n        return\n\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Expand to temporal dimension if defined\n        if self.temporal_extent is not None:\n            ds = ds.expand_dims(time=self.temporal_extent)\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        if self.temporal_extent is not None:\n            coords_encoding[\"time\"] = {\"chunks\": ds.time.shape, **optimize_temporal_encoding(self.temporal_extent)}\n        chunks = (\n            (1, self.chunk_size, self.chunk_size)\n            if self.temporal_extent is not None\n            else (self.chunk_size, self.chunk_size)\n        )\n        var_encoding = {\n            name: {\n                \"chunks\": chunks,\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Has no effect if exists_ok is True. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.create(exists_ok)","title":"<code>exists_ok</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Do not raise an error if the datacube already exists.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.\n\n    \"\"\"\n    import geopandas as gpd\n\n    if not self.created:\n        return None\n\n    loaded_patches = self.loaded_patches()\n\n    if len(loaded_patches) == 0:\n        return None\n\n    patch_infos = []\n    for pid in loaded_patches:\n        spatial_idx, temporal_idx = self._parse_index(pid)\n        geometry = self._extent_tiles[spatial_idx].extent.geom\n        if self.is_temporal:\n            time = self.temporal_extent[temporal_idx]\n            patch_infos.append({\"geometry\": geometry, \"id\": pid, \"time\": time})\n        else:\n            patch_infos.append({\"geometry\": geometry, \"id\": pid})\n\n    gdf = gpd.GeoDataFrame(patch_infos, crs=self.extent.crs.to_wkt())\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.download_patch","title":"download_patch","text":"<pre><code>download_patch(idx: PatchIndex) -&gt; xr.Dataset\n</code></pre> <p>Download the data for the given patch.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded patch data.</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/tctrend.py</code> <pre><code>def download_patch(self, idx: PatchIndex) -&gt; xr.Dataset:\n    \"\"\"Download the data for the given patch.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        idx (PatchIndex): The reference patch to download the data for.\n\n    Returns:\n        xr.Dataset: The downloaded patch data.\n\n    \"\"\"\n    patch = super().download_patch(idx)\n\n    # ?: The following code handles the occurance of nan values when using mosaics\n    # Save original min-max values for each band for clipping later\n    clip_values = {\n        band: (patch[band].min().values.item(), patch[band].max().values.item()) for band in patch.data_vars\n    }\n\n    # Interpolate missing values (there are very few, so we actually can interpolate them)\n    patch.rio.set_spatial_dims(x_dim=\"x\", y_dim=\"y\", inplace=True)\n    for band in patch.data_vars:\n        patch[band] = patch[band].rio.write_nodata(np.nan).rio.interpolate_na()\n\n    # Convert to uint8\n    for band in patch.data_vars:\n        band_min, band_max = clip_values[band]\n        patch[band] = patch[band].clip(band_min, band_max, keep_attrs=True).astype(\"uint8\").rio.write_nodata(None)\n\n    return patch\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.download_patch(idx)","title":"<code>idx</code>","text":"(<code>PatchIndex</code>)           \u2013            <p>The reference patch to download the data for.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.load","title":"load","text":"<pre><code>load(\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load(\n    self,\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        aoi (Geometry | GeoBox): The reference geometry to load the data for. If a Geobox is provided,\n            it will use the extent of the geobox.\n        toi (TOI): The temporal slice to load. Defaults to None.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    if toi is not None:\n        self.assert_temporal_cube()\n\n    if isinstance(aoi, GeoBox):\n        aoi = aoi.extent\n\n    with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        aligned_aoi = aoi.to_crs(self.extent.crs)\n        with self.stopuhr(f\"{_geometry_repr(aoi)}: Procedural download in blocking mode\"):\n            self.procedural_download(aligned_aoi, toi)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get temporal slice if time is provided\n        if toi is not None:\n            xrcube = xrcube.sel(time=toi)\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(aligned_aoi, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.load(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry | GeoBox</code>)           \u2013            <p>The reference geometry to load the data for. If a Geobox is provided, it will use the extent of the geobox.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.load(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>, default:                   <code>None</code> )           \u2013            <p>The temporal slice to load. Defaults to None.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    toi = None\n    if \"time\" in ref.coords and self.temporal_extent is not None:\n        toi = ref.get_index(\"time\")\n    return self.load(ref.geobox, toi=toi, **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.loaded_patches","title":"loaded_patches","text":"<pre><code>loaded_patches() -&gt; list[str]\n</code></pre> <p>Get the ids of already (down-)loaded patches.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>list[str]: A list of already loaded patch ids.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def loaded_patches(self) -&gt; list[str]:\n    \"\"\"Get the ids of already (down-)loaded patches.\n\n    Returns:\n        list[str]: A list of already loaded patch ids.\n\n    \"\"\"\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube.attrs.get(\"loaded_patches\", []).copy()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    return self.backend.open_xarray()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    return self.backend.open_zarr()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Post create actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_create(self):\n    \"\"\"Post create actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.post_init","title":"post_init","text":"<pre><code>post_init()\n</code></pre> <p>Post init actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_init(self):\n    \"\"\"Post init actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(aoi: Geometry, toi: TOI)\n</code></pre> <p>Download tiles procedurally.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If not all downloads were successful.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def procedural_download(self, aoi: Geometry, toi: TOI):\n    \"\"\"Download tiles procedurally.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        aoi (Geometry): The geometry of the aoi to download.\n        toi (TOI): The time of interest to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If not all downloads were successful.\n\n    \"\"\"\n    adjacent_patches = self.adjacent_patches(aoi, toi)\n    # interest-string\n    soi = f\"{_geometry_repr(aoi)}\" + (f\" @ {_repr_toi(toi)}\" if toi is not None else \"\")\n    if not adjacent_patches:\n        logger.error(f\"{soi}: No adjacent patches found: {adjacent_patches=}\")\n        raise ValueError(\"No adjacent patches found - is the provided aoi and toi correct?\")\n\n    loaded_patches = self.loaded_patches()\n\n    new_patches = [patch for patch in adjacent_patches if patch.id not in loaded_patches]\n\n    logger.debug(f\"{soi}:  {len(adjacent_patches)=} &amp; {len(loaded_patches)=} -&gt; {len(new_patches)=} to download\")\n    if not new_patches:\n        return\n\n    # This raises Errors if anything goes wrong -&gt; we want to propagate\n    self.backend.submit(new_patches)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.procedural_download(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry</code>)           \u2013            <p>The geometry of the aoi to download.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.procedural_download(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/tctrend.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    import cartopy.crs as ccrs\n    import cartopy.feature as cfeature\n    import matplotlib.pyplot as plt\n\n    tile_info = self.current_state()\n\n    if tile_info is None:\n        raise ValueError(\"Datacube is not created or loaded yet. Can't visualize!\")\n\n    # Define the projection\n    projection = ccrs.PlateCarree()\n\n    # Create a figure\n    fig = None\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": projection})\n\n    # Set the extent to show the whole world\n    ax.set_extent([-180, 180, -90, 90], crs=ccrs.PlateCarree())\n\n    # Add features\n    ax.add_feature(cfeature.LAND, zorder=0, edgecolor=\"black\", facecolor=\"white\")\n    ax.add_feature(cfeature.OCEAN, zorder=0, facecolor=\"lightgrey\")\n    ax.add_feature(cfeature.COASTLINE)\n    ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n    ax.add_feature(cfeature.LAKES, alpha=0.5)\n    ax.add_feature(cfeature.RIVERS)\n\n    # Add gridlines\n    gl = ax.gridlines(draw_labels=True)\n    gl.top_labels = False\n    gl.right_labels = False\n\n    tile_info.plot(\n        \"id\",\n        ax=ax,\n        transform=ccrs.PlateCarree(),\n        edgecolor=\"black\",\n        categorical=True,\n        aspect=\"equal\",\n        alpha=0.5,\n    )\n\n    if fig is not None:\n        return fig\n    else:\n        return ax\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2020.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022","title":"TCTrend2022","text":"<pre><code>TCTrend2022(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n)\n</code></pre> <p>               Bases: <code>TCTrendABC</code></p> <p>Accessor for TCTrend data derived from 2003-2022.</p> <p>Attributes:</p> <ul> <li> <code>collection</code>               (<code>str</code>)           \u2013            <p>The collection ID of the datacube.</p> </li> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the zarr array. Should be equal to the extent geobox.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_patches</code>             \u2013              <p>Get the adjacent patches for the given geobox.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>assert_temporal_cube</code>             \u2013              <p>Assert that the datacube has a temporal dimension.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_patch</code>             \u2013              <p>Download the data for the given patch.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>loaded_patches</code>             \u2013              <p>Get the ids of already (down-)loaded patches.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Post create actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>post_init</code>             \u2013              <p>Post init actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download tiles procedurally.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n        backend (Literal[\"threaded\", \"simple\"], optional): The backend to use for downloading data.\n            Currently, only \"threaded\" is supported. Defaults to \"threaded\".\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = Chronometer(logger.debug)\n\n    if backend == \"threaded\":\n        if not _check_python_version(3, 13):\n            raise NotImplementedError(\n                \"The 'threaded' backend is only fully supported in Python 3.13 and above.\"\n                \" Please consider using the 'simple' backend in a multiprocessing environment\"\n                \" or upgrade your Python version.\"\n            )\n        self.backend = ThreadedBackend(self.repo, self.download_patch)\n    elif backend == \"simple\":\n        self.backend = SimpleBackend(self.repo, self.download_patch)\n    else:\n        raise ValueError(f\"Unknown backend {backend}\")\n\n    self.post_init()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022(backend)","title":"<code>backend</code>","text":"(<code>Literal['threaded', 'simple']</code>, default:                   <code>'threaded'</code> )           \u2013            <p>The backend to use for downloading data. Currently, only \"threaded\" is supported. Defaults to \"threaded\".</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre> <p>Check if the datacube already exists in the storage.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.is_temporal","title":"is_temporal  <code>property</code>","text":"<pre><code>is_temporal: bool\n</code></pre> <p>Check if the datacube has a temporal dimension.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube has a temporal dimension.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.adjacent_patches","title":"adjacent_patches","text":"<pre><code>adjacent_patches(\n    roi: Geometry | GeoBox | GeoDataFrame, toi: TOI\n) -&gt; list[Item]\n</code></pre> <p>Get the adjacent patches for the given geobox.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[Item]</code>           \u2013            <p>list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the ROI type is invalid.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If the datacube is not temporal, but a time of interest is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def adjacent_patches(self, roi: Geometry | GeoBox | gpd.GeoDataFrame, toi: TOI) -&gt; list[Item]:\n    \"\"\"Get the adjacent patches for the given geobox.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        roi (Geometry | GeoBox | gpd.GeoDataFrame): The reference geometry, geobox or reference geodataframe\n        toi (TOI): The time of interest to download.\n\n    Returns:\n        list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.\n\n    Raises:\n        ValueError: If the ROI type is invalid.\n        ValueError: If the datacube is not temporal, but a time of interest is provided.\n\n    \"\"\"\n    if toi is not None and not self.is_temporal:\n        raise ValueError(\"Datacube is not temporal, but time of interest is provided.\")\n\n    if isinstance(roi, gpd.GeoDataFrame):\n        adjacent_geometries = (\n            gpd.sjoin(self._tile_geometries, roi.to_crs(self.extent.crs.wkt), how=\"inner\", predicate=\"intersects\")\n            .reset_index()\n            .drop_duplicates(subset=\"index\", keep=\"first\")\n            .set_index(\"index\")\n        )\n        spatial_idxs: list[tuple[int, int]] = list(adjacent_geometries[\"idx\"])\n    elif isinstance(roi, GeoBox):\n        spatial_idxs: list[tuple[int, int]] = list(self._extent_tiles.tiles(roi.extent))\n    elif isinstance(roi, Geometry):\n        spatial_idxs: list[tuple[int, int]] = list(self._extent_tiles.tiles(roi))\n    else:\n        raise ValueError(\"Invalid ROI type.\")\n\n    if not self.is_temporal:\n        return [\n            PatchIndex(\n                self._stringify_index(spatial_idx),\n                self._extent_tiles[spatial_idx].geographic_extent,\n                None,\n                Item(self._extent_tiles[spatial_idx], None),\n            )\n            for spatial_idx in spatial_idxs\n        ]\n\n    # Now datacube is temporal\n    toi = normalize_toi(self.temporal_extent, toi)\n    patch_idxs = []\n    for time in toi:\n        time_idx = self.temporal_extent.get_loc(time)\n        assert isinstance(time_idx, int), \"Non-Unique temporal extents are not supported!\"\n        for spatial_idx in spatial_idxs:\n            patch_idxs.append(\n                PatchIndex(\n                    self._stringify_index(spatial_idx, time_idx),\n                    self._extent_tiles[spatial_idx].geographic_extent,\n                    time,\n                    Item(self._extent_tiles[spatial_idx], time),\n                )\n            )\n    return patch_idxs\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.adjacent_patches(roi)","title":"<code>roi</code>","text":"(<code>Geometry | GeoBox | GeoDataFrame</code>)           \u2013            <p>The reference geometry, geobox or reference geodataframe</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.adjacent_patches(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\"\"\"\n    self.backend.assert_created()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.assert_temporal_cube","title":"assert_temporal_cube","text":"<pre><code>assert_temporal_cube()\n</code></pre> <p>Assert that the datacube has a temporal dimension.</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube has no temporal dimension.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_temporal_cube(self):\n    \"\"\"Assert that the datacube has a temporal dimension.\n\n    Raises:\n        ValueError: If the datacube has no temporal dimension.\n\n    \"\"\"\n    if self.temporal_extent is None:\n        msg = f\"Datacube {self.title} has no temporal dimension.\"\n        logger.error(msg)\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.create","title":"create","text":"<pre><code>create(overwrite: bool = False, exists_ok: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location and exists_ok is False.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def create(self, overwrite: bool = False, exists_ok: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube.\n            Has no effect if exists_ok is True. Defaults to False.\n        exists_ok (bool, optional): Do not raise an error if the datacube already exists.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location and exists_ok is False.\n\n    \"\"\"\n    if exists_ok and self.created:\n        logger.debug(\"Datacube was already created.\")\n        return\n\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Expand to temporal dimension if defined\n        if self.temporal_extent is not None:\n            ds = ds.expand_dims(time=self.temporal_extent)\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        if self.temporal_extent is not None:\n            coords_encoding[\"time\"] = {\"chunks\": ds.time.shape, **optimize_temporal_encoding(self.temporal_extent)}\n        chunks = (\n            (1, self.chunk_size, self.chunk_size)\n            if self.temporal_extent is not None\n            else (self.chunk_size, self.chunk_size)\n        )\n        var_encoding = {\n            name: {\n                \"chunks\": chunks,\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Has no effect if exists_ok is True. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.create(exists_ok)","title":"<code>exists_ok</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Do not raise an error if the datacube already exists.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.\n\n    \"\"\"\n    import geopandas as gpd\n\n    if not self.created:\n        return None\n\n    loaded_patches = self.loaded_patches()\n\n    if len(loaded_patches) == 0:\n        return None\n\n    patch_infos = []\n    for pid in loaded_patches:\n        spatial_idx, temporal_idx = self._parse_index(pid)\n        geometry = self._extent_tiles[spatial_idx].extent.geom\n        if self.is_temporal:\n            time = self.temporal_extent[temporal_idx]\n            patch_infos.append({\"geometry\": geometry, \"id\": pid, \"time\": time})\n        else:\n            patch_infos.append({\"geometry\": geometry, \"id\": pid})\n\n    gdf = gpd.GeoDataFrame(patch_infos, crs=self.extent.crs.to_wkt())\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.download_patch","title":"download_patch","text":"<pre><code>download_patch(idx: PatchIndex) -&gt; xr.Dataset\n</code></pre> <p>Download the data for the given patch.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded patch data.</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/tctrend.py</code> <pre><code>def download_patch(self, idx: PatchIndex) -&gt; xr.Dataset:\n    \"\"\"Download the data for the given patch.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        idx (PatchIndex): The reference patch to download the data for.\n\n    Returns:\n        xr.Dataset: The downloaded patch data.\n\n    \"\"\"\n    patch = super().download_patch(idx)\n\n    # ?: The following code handles the occurance of nan values when using mosaics\n    # Save original min-max values for each band for clipping later\n    clip_values = {\n        band: (patch[band].min().values.item(), patch[band].max().values.item()) for band in patch.data_vars\n    }\n\n    # Interpolate missing values (there are very few, so we actually can interpolate them)\n    patch.rio.set_spatial_dims(x_dim=\"x\", y_dim=\"y\", inplace=True)\n    for band in patch.data_vars:\n        patch[band] = patch[band].rio.write_nodata(np.nan).rio.interpolate_na()\n\n    # Convert to uint8\n    for band in patch.data_vars:\n        band_min, band_max = clip_values[band]\n        patch[band] = patch[band].clip(band_min, band_max, keep_attrs=True).astype(\"uint8\").rio.write_nodata(None)\n\n    return patch\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.download_patch(idx)","title":"<code>idx</code>","text":"(<code>PatchIndex</code>)           \u2013            <p>The reference patch to download the data for.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.load","title":"load","text":"<pre><code>load(\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load(\n    self,\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        aoi (Geometry | GeoBox): The reference geometry to load the data for. If a Geobox is provided,\n            it will use the extent of the geobox.\n        toi (TOI): The temporal slice to load. Defaults to None.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    if toi is not None:\n        self.assert_temporal_cube()\n\n    if isinstance(aoi, GeoBox):\n        aoi = aoi.extent\n\n    with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        aligned_aoi = aoi.to_crs(self.extent.crs)\n        with self.stopuhr(f\"{_geometry_repr(aoi)}: Procedural download in blocking mode\"):\n            self.procedural_download(aligned_aoi, toi)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get temporal slice if time is provided\n        if toi is not None:\n            xrcube = xrcube.sel(time=toi)\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(aligned_aoi, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.load(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry | GeoBox</code>)           \u2013            <p>The reference geometry to load the data for. If a Geobox is provided, it will use the extent of the geobox.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.load(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>, default:                   <code>None</code> )           \u2013            <p>The temporal slice to load. Defaults to None.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    toi = None\n    if \"time\" in ref.coords and self.temporal_extent is not None:\n        toi = ref.get_index(\"time\")\n    return self.load(ref.geobox, toi=toi, **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.loaded_patches","title":"loaded_patches","text":"<pre><code>loaded_patches() -&gt; list[str]\n</code></pre> <p>Get the ids of already (down-)loaded patches.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>list[str]: A list of already loaded patch ids.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def loaded_patches(self) -&gt; list[str]:\n    \"\"\"Get the ids of already (down-)loaded patches.\n\n    Returns:\n        list[str]: A list of already loaded patch ids.\n\n    \"\"\"\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube.attrs.get(\"loaded_patches\", []).copy()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    return self.backend.open_xarray()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    return self.backend.open_zarr()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Post create actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_create(self):\n    \"\"\"Post create actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.post_init","title":"post_init","text":"<pre><code>post_init()\n</code></pre> <p>Post init actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_init(self):\n    \"\"\"Post init actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(aoi: Geometry, toi: TOI)\n</code></pre> <p>Download tiles procedurally.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If not all downloads were successful.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def procedural_download(self, aoi: Geometry, toi: TOI):\n    \"\"\"Download tiles procedurally.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        aoi (Geometry): The geometry of the aoi to download.\n        toi (TOI): The time of interest to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If not all downloads were successful.\n\n    \"\"\"\n    adjacent_patches = self.adjacent_patches(aoi, toi)\n    # interest-string\n    soi = f\"{_geometry_repr(aoi)}\" + (f\" @ {_repr_toi(toi)}\" if toi is not None else \"\")\n    if not adjacent_patches:\n        logger.error(f\"{soi}: No adjacent patches found: {adjacent_patches=}\")\n        raise ValueError(\"No adjacent patches found - is the provided aoi and toi correct?\")\n\n    loaded_patches = self.loaded_patches()\n\n    new_patches = [patch for patch in adjacent_patches if patch.id not in loaded_patches]\n\n    logger.debug(f\"{soi}:  {len(adjacent_patches)=} &amp; {len(loaded_patches)=} -&gt; {len(new_patches)=} to download\")\n    if not new_patches:\n        return\n\n    # This raises Errors if anything goes wrong -&gt; we want to propagate\n    self.backend.submit(new_patches)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.procedural_download(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry</code>)           \u2013            <p>The geometry of the aoi to download.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.procedural_download(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/tctrend.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    import cartopy.crs as ccrs\n    import cartopy.feature as cfeature\n    import matplotlib.pyplot as plt\n\n    tile_info = self.current_state()\n\n    if tile_info is None:\n        raise ValueError(\"Datacube is not created or loaded yet. Can't visualize!\")\n\n    # Define the projection\n    projection = ccrs.PlateCarree()\n\n    # Create a figure\n    fig = None\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": projection})\n\n    # Set the extent to show the whole world\n    ax.set_extent([-180, 180, -90, 90], crs=ccrs.PlateCarree())\n\n    # Add features\n    ax.add_feature(cfeature.LAND, zorder=0, edgecolor=\"black\", facecolor=\"white\")\n    ax.add_feature(cfeature.OCEAN, zorder=0, facecolor=\"lightgrey\")\n    ax.add_feature(cfeature.COASTLINE)\n    ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n    ax.add_feature(cfeature.LAKES, alpha=0.5)\n    ax.add_feature(cfeature.RIVERS)\n\n    # Add gridlines\n    gl = ax.gridlines(draw_labels=True)\n    gl.top_labels = False\n    gl.right_labels = False\n\n    tile_info.plot(\n        \"id\",\n        ax=ax,\n        transform=ccrs.PlateCarree(),\n        edgecolor=\"black\",\n        categorical=True,\n        aspect=\"equal\",\n        alpha=0.5,\n    )\n\n    if fig is not None:\n        return fig\n    else:\n        return ax\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend2022.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC","title":"TCTrendABC","text":"<pre><code>TCTrendABC(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n)\n</code></pre> <p>               Bases: <code>GEEMosaicAccessor</code></p> <p>ABC for TCTrend data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the zarr array. Should be equal to the extent geobox.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_patches</code>             \u2013              <p>Get the adjacent patches for the given geobox.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>assert_temporal_cube</code>             \u2013              <p>Assert that the datacube has a temporal dimension.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_patch</code>             \u2013              <p>Download the data for the given patch.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>loaded_patches</code>             \u2013              <p>Get the ids of already (down-)loaded patches.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Post create actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>post_init</code>             \u2013              <p>Post init actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download tiles procedurally.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n    backend: Literal[\"threaded\", \"simple\"] = \"threaded\",\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n        backend (Literal[\"threaded\", \"simple\"], optional): The backend to use for downloading data.\n            Currently, only \"threaded\" is supported. Defaults to \"threaded\".\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = Chronometer(logger.debug)\n\n    if backend == \"threaded\":\n        if not _check_python_version(3, 13):\n            raise NotImplementedError(\n                \"The 'threaded' backend is only fully supported in Python 3.13 and above.\"\n                \" Please consider using the 'simple' backend in a multiprocessing environment\"\n                \" or upgrade your Python version.\"\n            )\n        self.backend = ThreadedBackend(self.repo, self.download_patch)\n    elif backend == \"simple\":\n        self.backend = SimpleBackend(self.repo, self.download_patch)\n    else:\n        raise ValueError(f\"Unknown backend {backend}\")\n\n    self.post_init()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC(backend)","title":"<code>backend</code>","text":"(<code>Literal['threaded', 'simple']</code>, default:                   <code>'threaded'</code> )           \u2013            <p>The backend to use for downloading data. Currently, only \"threaded\" is supported. Defaults to \"threaded\".</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre> <p>Check if the datacube already exists in the storage.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.is_temporal","title":"is_temporal  <code>property</code>","text":"<pre><code>is_temporal: bool\n</code></pre> <p>Check if the datacube has a temporal dimension.</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the datacube has a temporal dimension.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.adjacent_patches","title":"adjacent_patches","text":"<pre><code>adjacent_patches(\n    roi: Geometry | GeoBox | GeoDataFrame, toi: TOI\n) -&gt; list[Item]\n</code></pre> <p>Get the adjacent patches for the given geobox.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[Item]</code>           \u2013            <p>list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the ROI type is invalid.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If the datacube is not temporal, but a time of interest is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def adjacent_patches(self, roi: Geometry | GeoBox | gpd.GeoDataFrame, toi: TOI) -&gt; list[Item]:\n    \"\"\"Get the adjacent patches for the given geobox.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        roi (Geometry | GeoBox | gpd.GeoDataFrame): The reference geometry, geobox or reference geodataframe\n        toi (TOI): The time of interest to download.\n\n    Returns:\n        list[PatchIndex[Item]]: The adjacent patch(-id)s for the given geobox.\n\n    Raises:\n        ValueError: If the ROI type is invalid.\n        ValueError: If the datacube is not temporal, but a time of interest is provided.\n\n    \"\"\"\n    if toi is not None and not self.is_temporal:\n        raise ValueError(\"Datacube is not temporal, but time of interest is provided.\")\n\n    if isinstance(roi, gpd.GeoDataFrame):\n        adjacent_geometries = (\n            gpd.sjoin(self._tile_geometries, roi.to_crs(self.extent.crs.wkt), how=\"inner\", predicate=\"intersects\")\n            .reset_index()\n            .drop_duplicates(subset=\"index\", keep=\"first\")\n            .set_index(\"index\")\n        )\n        spatial_idxs: list[tuple[int, int]] = list(adjacent_geometries[\"idx\"])\n    elif isinstance(roi, GeoBox):\n        spatial_idxs: list[tuple[int, int]] = list(self._extent_tiles.tiles(roi.extent))\n    elif isinstance(roi, Geometry):\n        spatial_idxs: list[tuple[int, int]] = list(self._extent_tiles.tiles(roi))\n    else:\n        raise ValueError(\"Invalid ROI type.\")\n\n    if not self.is_temporal:\n        return [\n            PatchIndex(\n                self._stringify_index(spatial_idx),\n                self._extent_tiles[spatial_idx].geographic_extent,\n                None,\n                Item(self._extent_tiles[spatial_idx], None),\n            )\n            for spatial_idx in spatial_idxs\n        ]\n\n    # Now datacube is temporal\n    toi = normalize_toi(self.temporal_extent, toi)\n    patch_idxs = []\n    for time in toi:\n        time_idx = self.temporal_extent.get_loc(time)\n        assert isinstance(time_idx, int), \"Non-Unique temporal extents are not supported!\"\n        for spatial_idx in spatial_idxs:\n            patch_idxs.append(\n                PatchIndex(\n                    self._stringify_index(spatial_idx, time_idx),\n                    self._extent_tiles[spatial_idx].geographic_extent,\n                    time,\n                    Item(self._extent_tiles[spatial_idx], time),\n                )\n            )\n    return patch_idxs\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.adjacent_patches(roi)","title":"<code>roi</code>","text":"(<code>Geometry | GeoBox | GeoDataFrame</code>)           \u2013            <p>The reference geometry, geobox or reference geodataframe</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.adjacent_patches(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\"\"\"\n    self.backend.assert_created()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.assert_temporal_cube","title":"assert_temporal_cube","text":"<pre><code>assert_temporal_cube()\n</code></pre> <p>Assert that the datacube has a temporal dimension.</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube has no temporal dimension.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def assert_temporal_cube(self):\n    \"\"\"Assert that the datacube has a temporal dimension.\n\n    Raises:\n        ValueError: If the datacube has no temporal dimension.\n\n    \"\"\"\n    if self.temporal_extent is None:\n        msg = f\"Datacube {self.title} has no temporal dimension.\"\n        logger.error(msg)\n        raise ValueError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.create","title":"create","text":"<pre><code>create(overwrite: bool = False, exists_ok: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location and exists_ok is False.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def create(self, overwrite: bool = False, exists_ok: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube.\n            Has no effect if exists_ok is True. Defaults to False.\n        exists_ok (bool, optional): Do not raise an error if the datacube already exists.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location and exists_ok is False.\n\n    \"\"\"\n    if exists_ok and self.created:\n        logger.debug(\"Datacube was already created.\")\n        return\n\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Expand to temporal dimension if defined\n        if self.temporal_extent is not None:\n            ds = ds.expand_dims(time=self.temporal_extent)\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        if self.temporal_extent is not None:\n            coords_encoding[\"time\"] = {\"chunks\": ds.time.shape, **optimize_temporal_encoding(self.temporal_extent)}\n        chunks = (\n            (1, self.chunk_size, self.chunk_size)\n            if self.temporal_extent is not None\n            else (self.chunk_size, self.chunk_size)\n        )\n        var_encoding = {\n            name: {\n                \"chunks\": chunks,\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Has no effect if exists_ok is True. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.create(exists_ok)","title":"<code>exists_ok</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Do not raise an error if the datacube already exists.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.\n\n    \"\"\"\n    import geopandas as gpd\n\n    if not self.created:\n        return None\n\n    loaded_patches = self.loaded_patches()\n\n    if len(loaded_patches) == 0:\n        return None\n\n    patch_infos = []\n    for pid in loaded_patches:\n        spatial_idx, temporal_idx = self._parse_index(pid)\n        geometry = self._extent_tiles[spatial_idx].extent.geom\n        if self.is_temporal:\n            time = self.temporal_extent[temporal_idx]\n            patch_infos.append({\"geometry\": geometry, \"id\": pid, \"time\": time})\n        else:\n            patch_infos.append({\"geometry\": geometry, \"id\": pid})\n\n    gdf = gpd.GeoDataFrame(patch_infos, crs=self.extent.crs.to_wkt())\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.download_patch","title":"download_patch","text":"<pre><code>download_patch(idx: PatchIndex) -&gt; xr.Dataset\n</code></pre> <p>Download the data for the given patch.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded patch data.</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/tctrend.py</code> <pre><code>def download_patch(self, idx: PatchIndex) -&gt; xr.Dataset:\n    \"\"\"Download the data for the given patch.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        idx (PatchIndex): The reference patch to download the data for.\n\n    Returns:\n        xr.Dataset: The downloaded patch data.\n\n    \"\"\"\n    patch = super().download_patch(idx)\n\n    # ?: The following code handles the occurance of nan values when using mosaics\n    # Save original min-max values for each band for clipping later\n    clip_values = {\n        band: (patch[band].min().values.item(), patch[band].max().values.item()) for band in patch.data_vars\n    }\n\n    # Interpolate missing values (there are very few, so we actually can interpolate them)\n    patch.rio.set_spatial_dims(x_dim=\"x\", y_dim=\"y\", inplace=True)\n    for band in patch.data_vars:\n        patch[band] = patch[band].rio.write_nodata(np.nan).rio.interpolate_na()\n\n    # Convert to uint8\n    for band in patch.data_vars:\n        band_min, band_max = clip_values[band]\n        patch[band] = patch[band].clip(band_min, band_max, keep_attrs=True).astype(\"uint8\").rio.write_nodata(None)\n\n    return patch\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.download_patch(idx)","title":"<code>idx</code>","text":"(<code>PatchIndex</code>)           \u2013            <p>The reference patch to download the data for.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.load","title":"load","text":"<pre><code>load(\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load(\n    self,\n    aoi: Geometry | GeoBox,\n    toi: TOI = None,\n    persist: bool = True,\n    create: bool = False,\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        aoi (Geometry | GeoBox): The reference geometry to load the data for. If a Geobox is provided,\n            it will use the extent of the geobox.\n        toi (TOI): The temporal slice to load. Defaults to None.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    if toi is not None:\n        self.assert_temporal_cube()\n\n    if isinstance(aoi, GeoBox):\n        aoi = aoi.extent\n\n    with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        aligned_aoi = aoi.to_crs(self.extent.crs)\n        with self.stopuhr(f\"{_geometry_repr(aoi)}: Procedural download in blocking mode\"):\n            self.procedural_download(aligned_aoi, toi)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get temporal slice if time is provided\n        if toi is not None:\n            xrcube = xrcube.sel(time=toi)\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(aligned_aoi, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geometry_repr(aoi)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.load(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry | GeoBox</code>)           \u2013            <p>The reference geometry to load the data for. If a Geobox is provided, it will use the extent of the geobox.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.load(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>, default:                   <code>None</code> )           \u2013            <p>The temporal slice to load. Defaults to None.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    toi = None\n    if \"time\" in ref.coords and self.temporal_extent is not None:\n        toi = ref.get_index(\"time\")\n    return self.load(ref.geobox, toi=toi, **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.loaded_patches","title":"loaded_patches","text":"<pre><code>loaded_patches() -&gt; list[str]\n</code></pre> <p>Get the ids of already (down-)loaded patches.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>           \u2013            <p>list[str]: A list of already loaded patch ids.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def loaded_patches(self) -&gt; list[str]:\n    \"\"\"Get the ids of already (down-)loaded patches.\n\n    Returns:\n        list[str]: A list of already loaded patch ids.\n\n    \"\"\"\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube.attrs.get(\"loaded_patches\", []).copy()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    return self.backend.open_xarray()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    return self.backend.open_zarr()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Post create actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_create(self):\n    \"\"\"Post create actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.post_init","title":"post_init","text":"<pre><code>post_init()\n</code></pre> <p>Post init actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def post_init(self):\n    \"\"\"Post init actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(aoi: Geometry, toi: TOI)\n</code></pre> <p>Download tiles procedurally.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If not all downloads were successful.</p> </li> </ul> Source code in <code>src/smart_geocubes/core/accessor.py</code> <pre><code>def procedural_download(self, aoi: Geometry, toi: TOI):\n    \"\"\"Download tiles procedurally.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        aoi (Geometry): The geometry of the aoi to download.\n        toi (TOI): The time of interest to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If not all downloads were successful.\n\n    \"\"\"\n    adjacent_patches = self.adjacent_patches(aoi, toi)\n    # interest-string\n    soi = f\"{_geometry_repr(aoi)}\" + (f\" @ {_repr_toi(toi)}\" if toi is not None else \"\")\n    if not adjacent_patches:\n        logger.error(f\"{soi}: No adjacent patches found: {adjacent_patches=}\")\n        raise ValueError(\"No adjacent patches found - is the provided aoi and toi correct?\")\n\n    loaded_patches = self.loaded_patches()\n\n    new_patches = [patch for patch in adjacent_patches if patch.id not in loaded_patches]\n\n    logger.debug(f\"{soi}:  {len(adjacent_patches)=} &amp; {len(loaded_patches)=} -&gt; {len(new_patches)=} to download\")\n    if not new_patches:\n        return\n\n    # This raises Errors if anything goes wrong -&gt; we want to propagate\n    self.backend.submit(new_patches)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.procedural_download(aoi)","title":"<code>aoi</code>","text":"(<code>Geometry</code>)           \u2013            <p>The geometry of the aoi to download.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.procedural_download(toi)","title":"<code>toi</code>","text":"(<code>TOI</code>)           \u2013            <p>The time of interest to download.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/tctrend.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    import cartopy.crs as ccrs\n    import cartopy.feature as cfeature\n    import matplotlib.pyplot as plt\n\n    tile_info = self.current_state()\n\n    if tile_info is None:\n        raise ValueError(\"Datacube is not created or loaded yet. Can't visualize!\")\n\n    # Define the projection\n    projection = ccrs.PlateCarree()\n\n    # Create a figure\n    fig = None\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": projection})\n\n    # Set the extent to show the whole world\n    ax.set_extent([-180, 180, -90, 90], crs=ccrs.PlateCarree())\n\n    # Add features\n    ax.add_feature(cfeature.LAND, zorder=0, edgecolor=\"black\", facecolor=\"white\")\n    ax.add_feature(cfeature.OCEAN, zorder=0, facecolor=\"lightgrey\")\n    ax.add_feature(cfeature.COASTLINE)\n    ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n    ax.add_feature(cfeature.LAKES, alpha=0.5)\n    ax.add_feature(cfeature.RIVERS)\n\n    # Add gridlines\n    gl = ax.gridlines(draw_labels=True)\n    gl.top_labels = False\n    gl.right_labels = False\n\n    tile_info.plot(\n        \"id\",\n        ax=ax,\n        transform=ccrs.PlateCarree(),\n        edgecolor=\"black\",\n        categorical=True,\n        aspect=\"equal\",\n        alpha=0.5,\n    )\n\n    if fig is not None:\n        return fig\n    else:\n        return ax\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrendABC.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/exceptions/","title":"exceptions","text":""},{"location":"reference/smart_geocubes/exceptions/#smart_geocubes.exceptions","title":"smart_geocubes.exceptions","text":"<p>Exceptions for the smart_geocubes package.</p> <p>Classes:</p> <ul> <li> <code>AlreadyDownloadedError</code>           \u2013            <p>Exception to raise when a tile is already downloaded.</p> </li> </ul>"},{"location":"reference/smart_geocubes/exceptions/#smart_geocubes.exceptions.AlreadyDownloadedError","title":"AlreadyDownloadedError","text":"<p>               Bases: <code>Exception</code></p> <p>Exception to raise when a tile is already downloaded.</p>"}]}