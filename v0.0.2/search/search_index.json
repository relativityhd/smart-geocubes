{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Smart-Geocubes","text":"<p>A high-performance library for intelligent loading and caching of remote geospatial raster data, built with xarray, zarr and icechunk.</p> <p>Inspiration</p> <p>The concept of this package is heavily inspired by EarthMovers implementation of serverless datacube generation.</p>"},{"location":"#quickstart","title":"Quickstart","text":"<p>Install the package with <code>uv</code> or <code>pip</code>:</p> <pre><code>pip install smart-geocubes\n</code></pre> <pre><code>uv add smart-geocubes\n</code></pre> <p>Open data for your region of interest:</p> <pre><code>import smart_geocubes\nfrom odc.geo.geobox import GeoBox\n\naccessor = smart_geocubes.ArcticDEM32m(\"datacubes/arcticdem_32m.icechunk\")\n\nroi = GeoBox.from_bbox((150, 65, 151, 65.5), shape=(1000, 1000), crs=\"EPSG:4326\")\n\narcticdem_at_roi = accessor.load(roi, create=True)\n</code></pre>"},{"location":"#whats-next","title":"What's next?","text":"<ul> <li> <p> Getting Started</p> <p>Get an overview on how this package works.</p> <p> Get Started</p> </li> <li> <p> Write custom Dataset Accessors</p> <p>Read how <code>smart-geocubes</code> works to learn how to access other datasets with own implemented accessors.</p> <p> How it Works</p> </li> <li> <p> Contribute</p> <p>Learn about what I plan to do with this package and how you can help.</p> <p> Contribute &amp; Roadmap</p> </li> <li> <p> API Reference</p> <p>View the API reference of the components.</p> <p> Reference</p> </li> </ul>"},{"location":"#out-of-the-box-included-datasets","title":"Out of the box included datasets","text":"Dataset Quickuse Source Link ArcticDEM Mosaic 2m <code>smart_geocubes.ArcticDEM2m</code> STAC PGC ArcticDEM Mosaic 10m <code>smart_geocubes.ArcticDEM10m</code> STAC PGC ArcticDEM Mosaic 32m <code>smart_geocubes.ArcticDEM32m</code> STAC PGC Tasseled Cap Tren <code>smart_geocubes.TCTrend</code> Google Earth Engine AWI"},{"location":"#implemented-remote-accessors","title":"Implemented Remote Accessors","text":"Accessor Description <code>smart_geocubes.accessors.STAC</code> Accessor for the STAC API, which allows to download data from a STAC API. <code>smart_geocubes.accessors.GEE</code> Accessor for Google Earth Engine, which allows to download data from Google Earth Engine."},{"location":"#what-is-the-purpose-of-this-package","title":"What is the purpose of this package?","text":"<p>This package solves a specific problem that most people who work with Earth observation data don't need to worry about. When you're creating new data from existing data (for example, doing image segmentation with machine learning on Sentinel-2 images), people usually:</p> <ol> <li>Download all the data</li> <li>Run the algorithms and data science on it</li> <li>Delete the data afterwards</li> </ol> <p>This \"batched-processing\" works great if you have a big computer with lots of storage space, like a cluster.</p> <p>But if you're working on a smaller computer (like a laptop with a few hundred GB of storage and 16GB of RAM), this approach creates problems. It makes it really hard to test and improve your programs because you don't have enough space. Using frameworks like Ray for processing is also tricky with this approach. They work better with \"concurrent-processing\": when each step of your processing pipeline can be done for each elements separately instead expecting to run a single step for all your data at once. Plus, if you only need to look at certain areas but don't know which ones ahead of time, downloading everything is wasteful.</p> <p>So instead, this package downloads the data only when you need it. But downloading the same thing over and over is inefficient. That's why we save (or \"cache\") the data on your computer's hard drive in form of zarr datacubes. We call this way of working \"procedural download\" because you download pieces as you need them.</p> <p>Therefore, this package does handle:</p> <ol> <li>The download \"on-demand\" (or \"procedural download\") of the data</li> <li>The caching of the data on your computer's hard drive</li> <li>The loading of the data into memory for regions specified by the user</li> <li>Making everything thread-safe, so you can run on any scaling framework you like.</li> </ol> <p>Multiprocessing</p> <p>On linux systems it is necessary to the the multiprocessing start method to <code>spawn</code> or <code>forkserver</code>. Read more about this here, here and here.</p> <p>The approach itself is already implemented in one of the pipelines we develop at the AWI, you can read more about their docs.</p> <p>Cloud computing</p> <p>This won't help if your computer doesn't have fast storage space available - like if you're working on a cloud-cluster that can't save files locally.</p>"},{"location":"contribute/","title":"Contribute","text":"<p>You are welcome do add a new pre-defined dataset. For other features, please open an issue on GitHub.</p>"},{"location":"contribute/#roadmap","title":"Roadmap","text":"<p>Features:</p> <ul> <li> STAC: Add dask download as optional</li> <li> STAC: Make the progress-bar optional</li> <li> Overall: Add support for temporal axis</li> <li> Overall: Add support for 3D data</li> <li> Overall: Add support for 4D data</li> <li> GEE Accessor</li> <li> Widen support for lat-lon data</li> <li> Support different x-y resolutions</li> <li> True threaded mode: multiple threads for downloading, one thread for writing, multiple for loading</li> </ul> <p>Datasets:</p> <ul> <li> ArcticDEM: increase readspeed by using extent files</li> <li> TCTrend Dataset</li> <li> S2 Dataset</li> <li> Landsat Dataset</li> </ul> <p>Admin:</p> <ul> <li> Use StopUhr to measure performance</li> <li> Write documentation (sphinx or mkdocs)</li> <li> Add GitHub Action</li> <li> Publish to PyPy</li> <li> Replace all execptions with custom exceptions</li> <li> Further flatten the public facing API</li> <li> Replace TileWrapper NamedTuple with a dataclass</li> <li> Make concurrency and storage module private</li> </ul>"},{"location":"how_it_works/","title":"How does it work?","text":"<p>Uncomplete and out of date</p> <p>As of right now, this documentation page is just copied from the DARTS documentation. It will be updated in the future.</p>"},{"location":"how_it_works/#why-zarr-datacubes","title":"Why Zarr Datacubes?","text":"<p>Zarr is a file format for storing chunked, compressed, N-dimensional arrays. It is designed to store large arrays of data, and to facilitate fast and efficient IO. Zarr works well integrated with Dask and Xarray.</p> <p>By storing the auxiliary data in Zarr Datacubes, it is much easier and faster to access the data of interest. If we would use GeoTiffs, we would have to first create a Cloud-Optimized GeoTiff (COG), which is basically an ensemble (mosaic) of multiple GeoTiffs. Then we would have to read from the COG, which behind the scenes would open multiple GeoTiffs and crops them to fit the region of interest. E.g. Opening a specific region of interest 10km x 10km from a 2m resolution COG would take up to 2 minutes, if the COGs extend is panarctic. Opening the same region from a Zarr Datacube takes less than 1 second.</p>"},{"location":"how_it_works/#procedural-download","title":"Procedural download","text":"<p>Info</p> <p>The currently used auxiliary data is downloaded on demand, only data actually used is downloaded and stored on your local machine. Hence, the stored datacubes can be thought of as a cache, which is filled with data as needed.</p> <p>There are currently two implementations of the procedural download used: a cloud based STAC download and a download via Google Earth-Engine.</p> <p>Because the single tiles of the STAC mosaic can be overlapping and intersect with multiple Zarr chunks, the STAC download is slightly more complicated. Since Google Earth-Engine allows for exact geoboxes, download of the exact chunks is possible. This reduces the complexity of the download.</p> STAC GEE 1. ROI 2. ROI <p>The above graphics shows the difference between loading data from STAC (left) and Google Earth-Engine (right). With the STAC download, the data is downloaded from a mosaic of tiles, which can be overlapping with each other and cover multiple Zarr chunks. It may occur that a chunk is not fully covered by the STAC mosaic, which results in only partial loaded chunks. In such cases, the missing data in these chunks will be updated if the other intersecting tile is downloaded, which may occur to a later time if a connected ROI is requested. The download process is much easier for GEE, since one can request the exact geoboxes of the Zarr chunks and GEE will handle the rest. Hence, chunks will always be fully covered by the downloaded data.</p> <p>Regarding the open ROI process, both implementations follow the same principle:</p> <ol> <li>Check which Tiles / Chunks intersect with the region of interest</li> <li>Dowload all new Tiles / Chunks</li> <li>Store the new Tiles / Chunks in their specific Zarr chunks</li> <li>Return the region of interest of the Zarr Datacube</li> </ol>"},{"location":"how_it_works/#stac-download","title":"STAC download","text":""},{"location":"how_it_works/#google-earth-engine-download","title":"Google Earth-Engine download","text":""},{"location":"examples/quickstart/","title":"Getting started with smart-geocubes","text":"In\u00a0[\u00a0]: Copied! <pre>import folium\nfrom odc.geo.geobox import GeoBox\nfrom stopuhr import stopuhr\n\nimport smart_geocubes\n</pre> import folium from odc.geo.geobox import GeoBox from stopuhr import stopuhr  import smart_geocubes <p>Let's start by creating an accessor to the ArcticDEM dataset. <code>smart-geocubes</code> provides the 32m resolution mosaic of the ArcticDEM dataset, along with some other datasets.</p> In\u00a0[\u00a0]: Copied! <pre>accessor = smart_geocubes.ArcticDEM32m(\"datacubes/arcticdem_32m.icechunk\")\naccessor\n</pre> accessor = smart_geocubes.ArcticDEM32m(\"datacubes/arcticdem_32m.icechunk\") accessor Out[\u00a0]: <pre>ArcticDEM32m(GeoBox(Shape2d(x=231256, y=234381), Anchor[-4000096.0 - 4100096.0], EPSG:3413), ['dem', 'datamask'])</pre> <p>This didn't do much yet. Let's define an region of interest with an ODC-GeoBox in eastern russia.</p> In\u00a0[3]: Copied! <pre>roi = GeoBox.from_bbox((150, 65, 151, 65.5), shape=(1000, 1000))\nroi.explore()\n</pre> roi = GeoBox.from_bbox((150, 65, 151, 65.5), shape=(1000, 1000)) roi.explore() Out[3]: Make this Notebook Trusted to load map: File -&gt; Trust Notebook <p>Now let's load the data. We measure the time with the <code>stopuhr</code> package, which provides a very convinient contextmanager for timing code blocks.</p> <p>Note: This may take a while (up to 10 minutes), since the data is downloaded from the ArcticDEM STAC API.</p> In\u00a0[4]: Copied! <pre>with stopuhr(\"Loading ArcticDEM at ROI\"):\n    arcticdem_at_roi = accessor.load(roi, create=True)\nprint(arcticdem_at_roi)\n</pre> with stopuhr(\"Loading ArcticDEM at ROI\"):     arcticdem_at_roi = accessor.load(roi, create=True) print(arcticdem_at_roi) <pre>Loading ArcticDEM at ROI took 109.95s\n&lt;xarray.Dataset&gt; Size: 20MB\nDimensions:      (y: 2110, x: 1908)\nCoordinates:\n  * y            (y) float64 17kB 2.657e+06 2.657e+06 ... 2.589e+06 2.589e+06\n    spatial_ref  int32 4B 3413\n  * x            (x) float64 15kB -7.581e+05 -7.581e+05 ... -6.971e+05\nData variables:\n    dem          (y, x) float32 16MB 103.4 103.6 103.8 ... 79.65 79.78 79.67\n    datamask     (y, x) bool 4MB True True True True ... True True True True\nAttributes:\n    title:         ArcticDEM32m\n    loaded_tiles:  ['67_33_32m_v4.1', '66_34_32m_v4.1', '66_33_32m_v4.1', '67...\n</pre> <p>It took a while, but now we have the data downloaded and cached. Hence, opening the same region the next time will be much faster.</p> <p>Now let's visualize what we got.</p> In\u00a0[5]: Copied! <pre>m = roi.explore()\narcticdem_at_roi[\"dem\"].odc.explore(map=m)\nm\n</pre> m = roi.explore() arcticdem_at_roi[\"dem\"].odc.explore(map=m) m Out[5]: Make this Notebook Trusted to load map: File -&gt; Trust Notebook <p>Our data covers the region we defined, but it does not fit perfectly to our specified region. This is because we specified our region in another coordinate reference system (CRS) than the data is stored in. <code>smart-geocubes</code> will always return the data in the CRS of the dataset, which is EPSG:3413 for ArcticDEM. If we want to fit the data to our region, we need to reproject it manually, e.g. using <code>odc.geo</code>:</p> In\u00a0[6]: Copied! <pre>arcticdem_at_roi_reprojected = arcticdem_at_roi.odc.reproject(roi)\n\nm = roi.explore()\narcticdem_at_roi_reprojected[\"dem\"].odc.explore(map=m)\nm\n</pre> arcticdem_at_roi_reprojected = arcticdem_at_roi.odc.reproject(roi)  m = roi.explore() arcticdem_at_roi_reprojected[\"dem\"].odc.explore(map=m) m Out[6]: Make this Notebook Trusted to load map: File -&gt; Trust Notebook <p>As mentioned earlier, <code>smart-geocubes</code> cached the downloaded data. To be exact, it stored it in a <code>zarr</code> datacube backed an <code>icechunk</code> store, located in the <code>\"datacubes/arcticdem_32m.icechunk\"</code> folder we specified earlier at the creation of our accessor. This datacube will be filled up the more regions we download. We can visualize how much of the datacube is already filled:</p> In\u00a0[7]: Copied! <pre>accessor.visualize_state();\n</pre> accessor.visualize_state(); <p>We can see that the datacube is already filled with four tiles. That means that our region of interest overlaps with four tiles of the ArcticDEM dataset. Let us check this theory:</p> In\u00a0[8]: Copied! <pre>m = accessor.current_state().explore()\nroi.explore(map=m)\nm\n</pre> m = accessor.current_state().explore() roi.explore(map=m) m Out[8]: Make this Notebook Trusted to load map: File -&gt; Trust Notebook <p>Seems to be correct.</p> In\u00a0[9]: Copied! <pre>second_roi = GeoBox.from_bbox((150.5, 65, 151.5, 65.5), shape=(1000, 1000))\nsecond_roi.explore()\n</pre> second_roi = GeoBox.from_bbox((150.5, 65, 151.5, 65.5), shape=(1000, 1000)) second_roi.explore() Out[9]: Make this Notebook Trusted to load map: File -&gt; Trust Notebook In\u00a0[\u00a0]: Copied! <pre>with stopuhr(\"Loading ArcticDEM at second ROI\"):\n    arcticdem_at_second_roi = accessor.load(second_roi)\nprint(arcticdem_at_second_roi)\n</pre> with stopuhr(\"Loading ArcticDEM at second ROI\"):     arcticdem_at_second_roi = accessor.load(second_roi) print(arcticdem_at_second_roi) <pre>Loading ArcticDEM at second ROI took 0.24s\n&lt;xarray.Dataset&gt; Size: 20MB\nDimensions:      (x: 1919, y: 2119)\nCoordinates:\n    spatial_ref  int32 4B 3413\n  * x            (x) float64 15kB -7.812e+05 -7.811e+05 ... -7.198e+05\n  * y            (y) float64 17kB 2.65e+06 2.65e+06 ... 2.583e+06 2.583e+06\nData variables:\n    datamask     (y, x) bool 4MB False False False False ... True True True True\n    dem          (y, x) float32 16MB 95.91 95.91 95.91 ... 54.34 54.11 54.14\nAttributes:\n    title:         ArcticDEM32m\n    loaded_tiles:  ['67_33_32m_v4.1', '66_34_32m_v4.1', '66_33_32m_v4.1', '67...\n</pre> <p>Wow, this was fast! Because this region also overlaps with the tiles we already downloaded before, <code>smart-geocubes</code> just opened the existing tiles from the cache.</p> <p>Let's visualize all together (try to play with the layer control on the top right):</p> In\u00a0[11]: Copied! <pre>m = roi.explore(name=\"First ROI\", grid_lines=False)\nsecond_roi.explore(map=m, name=\"Second ROI\", grid_lines=False)\narcticdem_at_roi[\"dem\"].odc.explore(map=m, name=\"DEM at first ROI\")\narcticdem_at_second_roi[\"dem\"].odc.explore(map=m, name=\"DEM at second ROI\")\naccessor.current_state().explore(m=m, name=\"Already loaded tiles\")\nfolium.LayerControl().add_to(m)\nm\n</pre> m = roi.explore(name=\"First ROI\", grid_lines=False) second_roi.explore(map=m, name=\"Second ROI\", grid_lines=False) arcticdem_at_roi[\"dem\"].odc.explore(map=m, name=\"DEM at first ROI\") arcticdem_at_second_roi[\"dem\"].odc.explore(map=m, name=\"DEM at second ROI\") accessor.current_state().explore(m=m, name=\"Already loaded tiles\") folium.LayerControl().add_to(m) m Out[11]: Make this Notebook Trusted to load map: File -&gt; Trust Notebook In\u00a0[\u00a0]: Copied! <pre>third_roi = GeoBox.from_bbox((151, 65, 152, 65.5), shape=(1000, 1000))\nwith stopuhr(\"Loading ArcticDEM at third ROI\"):\n    arcticdem_at_third_roi = accessor.load(third_roi)\nprint(arcticdem_at_third_roi)\n</pre> third_roi = GeoBox.from_bbox((151, 65, 152, 65.5), shape=(1000, 1000)) with stopuhr(\"Loading ArcticDEM at third ROI\"):     arcticdem_at_third_roi = accessor.load(third_roi) print(arcticdem_at_third_roi) <pre>Loading ArcticDEM at third ROI took 67.40s\n&lt;xarray.Dataset&gt; Size: 21MB\nDimensions:      (x: 1930, y: 2126)\nCoordinates:\n    spatial_ref  int32 4B 3413\n  * x            (x) float64 15kB -8.041e+05 -8.041e+05 ... -7.424e+05\n  * y            (y) float64 17kB 2.644e+06 2.644e+06 ... 2.576e+06 2.576e+06\nData variables:\n    datamask     (y, x) bool 4MB True True True True ... True True True True\n    dem          (y, x) float32 16MB 89.64 89.88 90.26 ... 46.83 46.66 46.63\nAttributes:\n    title:         ArcticDEM32m\n    loaded_tiles:  ['67_33_32m_v4.1', '66_34_32m_v4.1', '66_33_32m_v4.1', '67...\n</pre> <p>It again took a while, but only half as long as the first time. This is because this region overlaps with four tiles, two of which we already downloaded. Hence, only two new tiles need to be downloaded. Let's visualize the new state of the datacube:</p> In\u00a0[13]: Copied! <pre>accessor.visualize_state();\n</pre> accessor.visualize_state(); <p>We can see that two new tiles were added to the datacube, making it a total of six tiles.</p> <p>Rerunning this notebook would not result in the same behavior: The load times would be significantly faster, since the data is already cached.</p>"},{"location":"examples/quickstart/#getting-started-with-smart-geocubes","title":"Getting started with smart-geocubes\u00b6","text":"<p>This notebook demonstrates how one could use the <code>smart-geocubes</code> package to download and cache specific regions from large scale geospatial datasets at the example of the ArcticDEM.</p>"},{"location":"examples/quickstart/#first-region","title":"First region\u00b6","text":""},{"location":"examples/quickstart/#reprojection","title":"Reprojection\u00b6","text":""},{"location":"examples/quickstart/#datacube-state","title":"Datacube State\u00b6","text":""},{"location":"examples/quickstart/#second-region","title":"Second region\u00b6","text":"<p>Let's load a different region of interest, located just next to the previous one:</p>"},{"location":"examples/quickstart/#third-region","title":"Third region\u00b6","text":"<p>What happens when we want to load a third region of interest, which only partially overlaps with the tiles we already downloaded?</p>"},{"location":"reference/smart_geocubes/","title":"smart_geocubes","text":""},{"location":"reference/smart_geocubes/#smart_geocubes","title":"smart_geocubes","text":"<p>Smart-Geocubes: A high-performance library for intelligent loading and caching of remote geospatial raster data, built with xarray and zarr.</p> <p>Modules:</p> <ul> <li> <code>accessors</code>           \u2013            <p>Smart-Geocubes cccessor implementations.</p> </li> <li> <code>datasets</code>           \u2013            <p>Predefined datasets for the SmartGeocubes package.</p> </li> <li> <code>exceptions</code>           \u2013            <p>Exceptions for the smart_geocubes package.</p> </li> </ul> <p>Classes:</p> <ul> <li> <code>ArcticDEM10m</code>           \u2013            <p>Accessor for ArcticDEM 10m data.</p> </li> <li> <code>ArcticDEM2m</code>           \u2013            <p>Accessor for ArcticDEM 2m data.</p> </li> <li> <code>ArcticDEM32m</code>           \u2013            <p>Accessor for ArcticDEM 32m data.</p> </li> <li> <code>TCTrend</code>           \u2013            <p>Accessor for TCTrend data.</p> </li> </ul>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m","title":"ArcticDEM10m","text":"<pre><code>ArcticDEM10m(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n)\n</code></pre> <p>               Bases: <code>ArcticDEMABC</code></p> <p>Accessor for ArcticDEM 10m data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the underlaying zarr array. Should be equal to the extent geobox. However, this property is used to find the target index of the downloaded data, so better save than sorry.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_tiles</code>             \u2013              <p>Get adjacent tiles from a STAC API.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_tile</code>             \u2013              <p>Download a tile from a STAC API and write it to a zarr datacube.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download the data for the given geobox.</p> </li> <li> <code>procedural_download_blocking</code>             \u2013              <p>Download tiles procedurally in blocking mode.</p> </li> <li> <code>procedural_download_threading</code>             \u2013              <p>Download tiles procedurally in threading mode.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = StopUhr(logger.debug)\n\n    # The TypeVar used by the ThreadingHandler was added in 3.12\n    # The Shutdown method of the queue was added in 3.13\n    # Hence, we don't want to import the module unless Python 3.13 is installed\n    if _check_python_version(3, 13):\n        from smart_geocubes._concurrency.threading import ThreadingHandler\n\n        self._threading_handler = ThreadingHandler(self._threading_download)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.adjacent_tiles","title":"adjacent_tiles","text":"<pre><code>adjacent_tiles(geobox: GeoBox) -&gt; list[TileWrapper]\n</code></pre> <p>Get adjacent tiles from a STAC API.</p> <p>Overwrite the default implementation from the STAC accessor to use pre-downloaded extent files instead of querying the STAC API. This results in a faster loading time, but requires the extent files to be downloaded beforehand. This is done in the post_create step.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[TileWrapper]</code>           \u2013            <p>list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def adjacent_tiles(self, geobox: GeoBox) -&gt; list[TileWrapper]:\n    \"\"\"Get adjacent tiles from a STAC API.\n\n    Overwrite the default implementation from the STAC accessor\n    to use pre-downloaded extent files instead of querying the STAC API.\n    This results in a faster loading time, but requires the extent files to be downloaded beforehand.\n    This is done in the post_create step.\n\n    Args:\n        geobox (GeoBox): The geobox for which to get adjacent tiles.\n\n    Returns:\n        list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.\n\n    \"\"\"\n    # Assumes that the extent files are already present and the datacube is already created\n    self.assert_created()\n\n    resolution = int(self.extent.resolution.x)\n    extent_info = gpd.read_parquet(self._aux_dir / f\"ArcticDEM_Mosaic_Index_v4_1_{resolution}m.parquet\")\n    adjacent_tiles = extent_info.loc[extent_info.intersects(geobox.extent.geom)].copy()\n    if adjacent_tiles.empty:\n        return []\n    return [LazyStacTileWrapper(tile.dem_id, _get_stac_url(tile.dem_id)) for tile in adjacent_tiles.itertuples()]\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.adjacent_tiles(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox for which to get adjacent tiles.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> <p>Raises:</p> <ul> <li> <code>FileNotFoundError</code>             \u2013            <p>If the datacube does not exist.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\n\n    Raises:\n        FileNotFoundError: If the datacube does not exist.\n\n    \"\"\"\n    if not self.created:\n        msg = f\"Datacube {self.title} does not exist.\"\n        \" Please use the `create` method or pass `create=True` to `load`.\"\n        logger.error(msg)\n        raise FileNotFoundError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.create","title":"create","text":"<pre><code>create(overwrite: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def create(self, overwrite: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube. Defaults to False.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location\n\n    \"\"\"\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        var_encoding = {\n            name: {\n                \"chunks\": (self.chunk_size, self.chunk_size),\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Defaults to False.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.\n\n\n    \"\"\"\n    import geopandas as gpd\n    import pystac_client\n\n    if not self.created:\n        return None\n\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(session.store, mode=\"r\")\n    loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n\n    if len(loaded_tiles) == 0:\n        return None\n\n    catalog = pystac_client.Client.open(self.stac_api_url)\n    search = catalog.search(collections=[self.collection], ids=loaded_tiles)\n    stac_json = search.item_collection_as_dict()\n\n    gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.download_tile","title":"download_tile","text":"<pre><code>download_tile(tile: TileWrapper) -&gt; xr.Dataset\n</code></pre> <p>Download a tile from a STAC API and write it to a zarr datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded tile data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def download_tile(self, tile: TileWrapper) -&gt; xr.Dataset:\n    \"\"\"Download a tile from a STAC API and write it to a zarr datacube.\n\n    Args:\n        tile (TileWrapper): The tile to download and write.\n\n    Returns:\n        xr.Dataset: The downloaded tile data.\n\n    \"\"\"\n    from odc.stac import stac_load\n\n    tiledata = stac_load([tile.item], bands=self.channels, chunks=None, progress=None)\n\n    # TODO: Allow for multi-temporal datacubes\n    tiledata = tiledata.max(\"time\")\n\n    return tiledata\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.download_tile(tile)","title":"<code>tile</code>","text":"(<code>TileWrapper</code>)           \u2013            <p>The tile to download and write.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.load","title":"load","text":"<pre><code>load(\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load(\n    self,\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        geobox (GeoBox): The reference geobox to load the data for.\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        logger.debug(f\"{_geobox_repr(geobox)}: {geobox.resolution} original resolution\")\n\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        reference_geobox = geobox.to_crs(self.extent.crs, resolution=self.extent.resolution.x).pad(buffer)\n        self.procedural_download(reference_geobox, concurrency_mode=concurrency_mode)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(reference_geobox.extent, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.load(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to load the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.load(buffer)","title":"<code>buffer</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.load(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> <li> <code>concurrency_mode</code>               (<code>ConcurrencyModes</code>)           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    return self.load(_geobox_repr(ref.geobox), **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    xcube = xr.open_zarr(session.store, mask_and_scale=False, consolidated=False).set_coords(\"spatial_ref\")\n    return xcube\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def post_create(self):\n    \"\"\"Download the ArcticDEM mosaic extent info and store it in the datacube.\"\"\"\n    _download_arcticdem_extent(self._aux_dir)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(\n    geobox: GeoBox,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n)\n</code></pre> <p>Download the data for the given geobox.</p> Note <p>The \"threading\" concurrency mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If an unknown concurrency mode is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download(self, geobox: GeoBox, concurrency_mode: ConcurrencyModes = \"blocking\"):\n    \"\"\"Download the data for the given geobox.\n\n    Note:\n        The \"threading\" concurrency mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The reference geobox to download the data for.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Raises:\n        ValueError: If an unknown concurrency mode is provided.\n\n    \"\"\"\n    self.assert_created()\n    if concurrency_mode == \"blocking\":\n        self.procedural_download_blocking(geobox)\n    elif concurrency_mode == \"threading\":\n        self.procedural_download_threading(geobox)\n    else:\n        raise ValueError(f\"Unknown concurrency mode {concurrency_mode}\")\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.procedural_download(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to download the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.procedural_download(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.procedural_download_blocking","title":"procedural_download_blocking","text":"<pre><code>procedural_download_blocking(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in blocking mode.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If no tries are left.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_blocking(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in blocking mode.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If no tries are left.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: Procedural download in blocking mode\"):\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        session = self.repo.readonly_session(\"main\")\n        zcube = zarr.open(store=session.store, mode=\"r\")\n        loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n        new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n        logger.debug(\n            f\"{_geobox_repr(geobox)}:  {len(adjacent_tiles)=} &amp; {len(loaded_tiles)=}\"\n            f\" -&gt; {len(new_tiles)=} to download\"\n        )\n        if not new_tiles:\n            return\n\n        for tile in new_tiles:\n            with self.stopuhr(f\"{tile.id=}: Downloading one new tile in blocking mode\"):\n                logger.debug(f\"{tile.id=}: Start downloading\")\n                tiledata = self.download_tile(tile)\n\n            # Try to write the data to file until a limit is reached\n            limit = 100\n            for i in range(limit):\n                try:\n                    self._write_tile_to_zarr(tiledata, tile)\n                    break\n                except icechunk.ConflictError as conflict_error:\n                    logger.debug(f\"{tile.id=}: {conflict_error=} at retry {i}/{limit}\")\n            else:\n                logger.error(\n                    f\"{tile.id=}: {limit} tries to write the tile failed. \"\n                    \"Please check if the datacube is already created and not empty.\"\n                )\n                raise ValueError(f\"{tile.id=}: {limit} tries to write the tile failed.\")\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.procedural_download_blocking(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.procedural_download_threading","title":"procedural_download_threading","text":"<pre><code>procedural_download_threading(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in threading mode.</p> Note <p>This method ensures that only a single download is running at a time. It uses a SetQueue to prevent duplicate downloads. The threading mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>RuntimeError</code>             \u2013            <p>If the Python version is lower than 3.13.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_threading(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in threading mode.\n\n    Note:\n        This method ensures that only a single download is running at a time.\n        It uses a SetQueue to prevent duplicate downloads.\n        The threading mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        RuntimeError: If the Python version is lower than 3.13.\n\n    \"\"\"\n    if not _check_python_version(3, 13):\n        raise RuntimeError(\"Threading mode requires Python 3.13 or higher\")\n    with self._threading_handler:\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        # Wait until all new_items are loaded\n        prev_len = None\n        while True:\n            session = self.repo.readonly_session(\"main\")\n            zcube = zarr.open(store=session.store, mode=\"r\")\n            loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n            new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n            done_tiles = [tile for tile in adjacent_tiles if tile.id in loaded_tiles]\n            if not new_tiles:\n                break\n            if prev_len != len(new_tiles):\n                logger.debug(\n                    f\"{_geobox_repr(geobox)}: {len(done_tiles)} of {len(adjacent_tiles)} downloaded.\"\n                    f\" Missing: {[t.id for t in new_tiles]} Done: {[t.id for t in done_tiles]}\"\n                )\n            for tile in new_tiles:\n                self._threading_handler._queue.put(tile)\n            prev_len = len(new_tiles)\n            time.sleep(5)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.procedural_download_threading(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    import cartopy.crs as ccrs\n    import cartopy.feature as cfeature\n    import matplotlib.path as mpath\n    import matplotlib.pyplot as plt\n\n    tile_info = self.current_state()\n\n    if tile_info is None:\n        raise ValueError(\"Datacube is not created or loaded yet. Can't visualize!\")\n\n    # Define the projection\n    projection = ccrs.Stereographic(central_latitude=90, central_longitude=-45, true_scale_latitude=70)\n\n    # Create a figure\n    fig = None\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": projection})\n\n    # Set the extent to focus on the North Pole\n    ax.set_extent([-180, 180, 50, 90], crs=ccrs.PlateCarree())\n\n    # Add features\n    ax.add_feature(cfeature.LAND, zorder=0, edgecolor=\"black\", facecolor=\"white\")\n    ax.add_feature(cfeature.OCEAN, zorder=0, facecolor=\"lightgrey\")\n    ax.add_feature(cfeature.COASTLINE)\n    ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n    ax.add_feature(cfeature.LAKES, alpha=0.5)\n    ax.add_feature(cfeature.RIVERS)\n\n    # Add gridlines\n    gl = ax.gridlines(draw_labels=True)\n    gl.top_labels = False\n    gl.right_labels = False\n\n    # Compute a circle in axes coordinates, which we can use as a boundary\n    # for the map. We can pan/zoom as much as we like - the boundary will be\n    # permanently circular.\n    theta = np.linspace(0, 2 * np.pi, 100)\n    center, radius = [0.5, 0.5], 0.5\n    verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n    circle = mpath.Path(verts * radius + center)\n\n    ax.set_boundary(circle, transform=ax.transAxes)\n\n    tile_info.plot(\n        \"title\",\n        ax=ax,\n        transform=ccrs.PlateCarree(),\n        edgecolor=\"black\",\n        categorical=True,\n        aspect=\"equal\",\n        alpha=0.5,\n    )\n\n    if fig is not None:\n        return fig\n    else:\n        return ax\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM10m.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m","title":"ArcticDEM2m","text":"<pre><code>ArcticDEM2m(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n)\n</code></pre> <p>               Bases: <code>ArcticDEMABC</code></p> <p>Accessor for ArcticDEM 2m data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the underlaying zarr array. Should be equal to the extent geobox. However, this property is used to find the target index of the downloaded data, so better save than sorry.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_tiles</code>             \u2013              <p>Get adjacent tiles from a STAC API.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_tile</code>             \u2013              <p>Download a tile from a STAC API and write it to a zarr datacube.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download the data for the given geobox.</p> </li> <li> <code>procedural_download_blocking</code>             \u2013              <p>Download tiles procedurally in blocking mode.</p> </li> <li> <code>procedural_download_threading</code>             \u2013              <p>Download tiles procedurally in threading mode.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = StopUhr(logger.debug)\n\n    # The TypeVar used by the ThreadingHandler was added in 3.12\n    # The Shutdown method of the queue was added in 3.13\n    # Hence, we don't want to import the module unless Python 3.13 is installed\n    if _check_python_version(3, 13):\n        from smart_geocubes._concurrency.threading import ThreadingHandler\n\n        self._threading_handler = ThreadingHandler(self._threading_download)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.adjacent_tiles","title":"adjacent_tiles","text":"<pre><code>adjacent_tiles(geobox: GeoBox) -&gt; list[TileWrapper]\n</code></pre> <p>Get adjacent tiles from a STAC API.</p> <p>Overwrite the default implementation from the STAC accessor to use pre-downloaded extent files instead of querying the STAC API. This results in a faster loading time, but requires the extent files to be downloaded beforehand. This is done in the post_create step.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[TileWrapper]</code>           \u2013            <p>list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def adjacent_tiles(self, geobox: GeoBox) -&gt; list[TileWrapper]:\n    \"\"\"Get adjacent tiles from a STAC API.\n\n    Overwrite the default implementation from the STAC accessor\n    to use pre-downloaded extent files instead of querying the STAC API.\n    This results in a faster loading time, but requires the extent files to be downloaded beforehand.\n    This is done in the post_create step.\n\n    Args:\n        geobox (GeoBox): The geobox for which to get adjacent tiles.\n\n    Returns:\n        list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.\n\n    \"\"\"\n    # Assumes that the extent files are already present and the datacube is already created\n    self.assert_created()\n\n    resolution = int(self.extent.resolution.x)\n    extent_info = gpd.read_parquet(self._aux_dir / f\"ArcticDEM_Mosaic_Index_v4_1_{resolution}m.parquet\")\n    adjacent_tiles = extent_info.loc[extent_info.intersects(geobox.extent.geom)].copy()\n    if adjacent_tiles.empty:\n        return []\n    return [LazyStacTileWrapper(tile.dem_id, _get_stac_url(tile.dem_id)) for tile in adjacent_tiles.itertuples()]\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.adjacent_tiles(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox for which to get adjacent tiles.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> <p>Raises:</p> <ul> <li> <code>FileNotFoundError</code>             \u2013            <p>If the datacube does not exist.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\n\n    Raises:\n        FileNotFoundError: If the datacube does not exist.\n\n    \"\"\"\n    if not self.created:\n        msg = f\"Datacube {self.title} does not exist.\"\n        \" Please use the `create` method or pass `create=True` to `load`.\"\n        logger.error(msg)\n        raise FileNotFoundError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.create","title":"create","text":"<pre><code>create(overwrite: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def create(self, overwrite: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube. Defaults to False.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location\n\n    \"\"\"\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        var_encoding = {\n            name: {\n                \"chunks\": (self.chunk_size, self.chunk_size),\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Defaults to False.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.\n\n\n    \"\"\"\n    import geopandas as gpd\n    import pystac_client\n\n    if not self.created:\n        return None\n\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(session.store, mode=\"r\")\n    loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n\n    if len(loaded_tiles) == 0:\n        return None\n\n    catalog = pystac_client.Client.open(self.stac_api_url)\n    search = catalog.search(collections=[self.collection], ids=loaded_tiles)\n    stac_json = search.item_collection_as_dict()\n\n    gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.download_tile","title":"download_tile","text":"<pre><code>download_tile(tile: TileWrapper) -&gt; xr.Dataset\n</code></pre> <p>Download a tile from a STAC API and write it to a zarr datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded tile data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def download_tile(self, tile: TileWrapper) -&gt; xr.Dataset:\n    \"\"\"Download a tile from a STAC API and write it to a zarr datacube.\n\n    Args:\n        tile (TileWrapper): The tile to download and write.\n\n    Returns:\n        xr.Dataset: The downloaded tile data.\n\n    \"\"\"\n    from odc.stac import stac_load\n\n    tiledata = stac_load([tile.item], bands=self.channels, chunks=None, progress=None)\n\n    # TODO: Allow for multi-temporal datacubes\n    tiledata = tiledata.max(\"time\")\n\n    return tiledata\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.download_tile(tile)","title":"<code>tile</code>","text":"(<code>TileWrapper</code>)           \u2013            <p>The tile to download and write.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.load","title":"load","text":"<pre><code>load(\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load(\n    self,\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        geobox (GeoBox): The reference geobox to load the data for.\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        logger.debug(f\"{_geobox_repr(geobox)}: {geobox.resolution} original resolution\")\n\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        reference_geobox = geobox.to_crs(self.extent.crs, resolution=self.extent.resolution.x).pad(buffer)\n        self.procedural_download(reference_geobox, concurrency_mode=concurrency_mode)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(reference_geobox.extent, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.load(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to load the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.load(buffer)","title":"<code>buffer</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.load(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> <li> <code>concurrency_mode</code>               (<code>ConcurrencyModes</code>)           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    return self.load(_geobox_repr(ref.geobox), **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    xcube = xr.open_zarr(session.store, mask_and_scale=False, consolidated=False).set_coords(\"spatial_ref\")\n    return xcube\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def post_create(self):\n    \"\"\"Download the ArcticDEM mosaic extent info and store it in the datacube.\"\"\"\n    _download_arcticdem_extent(self._aux_dir)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(\n    geobox: GeoBox,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n)\n</code></pre> <p>Download the data for the given geobox.</p> Note <p>The \"threading\" concurrency mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If an unknown concurrency mode is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download(self, geobox: GeoBox, concurrency_mode: ConcurrencyModes = \"blocking\"):\n    \"\"\"Download the data for the given geobox.\n\n    Note:\n        The \"threading\" concurrency mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The reference geobox to download the data for.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Raises:\n        ValueError: If an unknown concurrency mode is provided.\n\n    \"\"\"\n    self.assert_created()\n    if concurrency_mode == \"blocking\":\n        self.procedural_download_blocking(geobox)\n    elif concurrency_mode == \"threading\":\n        self.procedural_download_threading(geobox)\n    else:\n        raise ValueError(f\"Unknown concurrency mode {concurrency_mode}\")\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.procedural_download(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to download the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.procedural_download(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.procedural_download_blocking","title":"procedural_download_blocking","text":"<pre><code>procedural_download_blocking(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in blocking mode.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If no tries are left.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_blocking(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in blocking mode.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If no tries are left.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: Procedural download in blocking mode\"):\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        session = self.repo.readonly_session(\"main\")\n        zcube = zarr.open(store=session.store, mode=\"r\")\n        loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n        new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n        logger.debug(\n            f\"{_geobox_repr(geobox)}:  {len(adjacent_tiles)=} &amp; {len(loaded_tiles)=}\"\n            f\" -&gt; {len(new_tiles)=} to download\"\n        )\n        if not new_tiles:\n            return\n\n        for tile in new_tiles:\n            with self.stopuhr(f\"{tile.id=}: Downloading one new tile in blocking mode\"):\n                logger.debug(f\"{tile.id=}: Start downloading\")\n                tiledata = self.download_tile(tile)\n\n            # Try to write the data to file until a limit is reached\n            limit = 100\n            for i in range(limit):\n                try:\n                    self._write_tile_to_zarr(tiledata, tile)\n                    break\n                except icechunk.ConflictError as conflict_error:\n                    logger.debug(f\"{tile.id=}: {conflict_error=} at retry {i}/{limit}\")\n            else:\n                logger.error(\n                    f\"{tile.id=}: {limit} tries to write the tile failed. \"\n                    \"Please check if the datacube is already created and not empty.\"\n                )\n                raise ValueError(f\"{tile.id=}: {limit} tries to write the tile failed.\")\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.procedural_download_blocking(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.procedural_download_threading","title":"procedural_download_threading","text":"<pre><code>procedural_download_threading(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in threading mode.</p> Note <p>This method ensures that only a single download is running at a time. It uses a SetQueue to prevent duplicate downloads. The threading mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>RuntimeError</code>             \u2013            <p>If the Python version is lower than 3.13.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_threading(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in threading mode.\n\n    Note:\n        This method ensures that only a single download is running at a time.\n        It uses a SetQueue to prevent duplicate downloads.\n        The threading mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        RuntimeError: If the Python version is lower than 3.13.\n\n    \"\"\"\n    if not _check_python_version(3, 13):\n        raise RuntimeError(\"Threading mode requires Python 3.13 or higher\")\n    with self._threading_handler:\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        # Wait until all new_items are loaded\n        prev_len = None\n        while True:\n            session = self.repo.readonly_session(\"main\")\n            zcube = zarr.open(store=session.store, mode=\"r\")\n            loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n            new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n            done_tiles = [tile for tile in adjacent_tiles if tile.id in loaded_tiles]\n            if not new_tiles:\n                break\n            if prev_len != len(new_tiles):\n                logger.debug(\n                    f\"{_geobox_repr(geobox)}: {len(done_tiles)} of {len(adjacent_tiles)} downloaded.\"\n                    f\" Missing: {[t.id for t in new_tiles]} Done: {[t.id for t in done_tiles]}\"\n                )\n            for tile in new_tiles:\n                self._threading_handler._queue.put(tile)\n            prev_len = len(new_tiles)\n            time.sleep(5)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.procedural_download_threading(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    import cartopy.crs as ccrs\n    import cartopy.feature as cfeature\n    import matplotlib.path as mpath\n    import matplotlib.pyplot as plt\n\n    tile_info = self.current_state()\n\n    if tile_info is None:\n        raise ValueError(\"Datacube is not created or loaded yet. Can't visualize!\")\n\n    # Define the projection\n    projection = ccrs.Stereographic(central_latitude=90, central_longitude=-45, true_scale_latitude=70)\n\n    # Create a figure\n    fig = None\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": projection})\n\n    # Set the extent to focus on the North Pole\n    ax.set_extent([-180, 180, 50, 90], crs=ccrs.PlateCarree())\n\n    # Add features\n    ax.add_feature(cfeature.LAND, zorder=0, edgecolor=\"black\", facecolor=\"white\")\n    ax.add_feature(cfeature.OCEAN, zorder=0, facecolor=\"lightgrey\")\n    ax.add_feature(cfeature.COASTLINE)\n    ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n    ax.add_feature(cfeature.LAKES, alpha=0.5)\n    ax.add_feature(cfeature.RIVERS)\n\n    # Add gridlines\n    gl = ax.gridlines(draw_labels=True)\n    gl.top_labels = False\n    gl.right_labels = False\n\n    # Compute a circle in axes coordinates, which we can use as a boundary\n    # for the map. We can pan/zoom as much as we like - the boundary will be\n    # permanently circular.\n    theta = np.linspace(0, 2 * np.pi, 100)\n    center, radius = [0.5, 0.5], 0.5\n    verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n    circle = mpath.Path(verts * radius + center)\n\n    ax.set_boundary(circle, transform=ax.transAxes)\n\n    tile_info.plot(\n        \"title\",\n        ax=ax,\n        transform=ccrs.PlateCarree(),\n        edgecolor=\"black\",\n        categorical=True,\n        aspect=\"equal\",\n        alpha=0.5,\n    )\n\n    if fig is not None:\n        return fig\n    else:\n        return ax\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM2m.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m","title":"ArcticDEM32m","text":"<pre><code>ArcticDEM32m(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n)\n</code></pre> <p>               Bases: <code>ArcticDEMABC</code></p> <p>Accessor for ArcticDEM 32m data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the underlaying zarr array. Should be equal to the extent geobox. However, this property is used to find the target index of the downloaded data, so better save than sorry.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_tiles</code>             \u2013              <p>Get adjacent tiles from a STAC API.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_tile</code>             \u2013              <p>Download a tile from a STAC API and write it to a zarr datacube.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download the data for the given geobox.</p> </li> <li> <code>procedural_download_blocking</code>             \u2013              <p>Download tiles procedurally in blocking mode.</p> </li> <li> <code>procedural_download_threading</code>             \u2013              <p>Download tiles procedurally in threading mode.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = StopUhr(logger.debug)\n\n    # The TypeVar used by the ThreadingHandler was added in 3.12\n    # The Shutdown method of the queue was added in 3.13\n    # Hence, we don't want to import the module unless Python 3.13 is installed\n    if _check_python_version(3, 13):\n        from smart_geocubes._concurrency.threading import ThreadingHandler\n\n        self._threading_handler = ThreadingHandler(self._threading_download)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.adjacent_tiles","title":"adjacent_tiles","text":"<pre><code>adjacent_tiles(geobox: GeoBox) -&gt; list[TileWrapper]\n</code></pre> <p>Get adjacent tiles from a STAC API.</p> <p>Overwrite the default implementation from the STAC accessor to use pre-downloaded extent files instead of querying the STAC API. This results in a faster loading time, but requires the extent files to be downloaded beforehand. This is done in the post_create step.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[TileWrapper]</code>           \u2013            <p>list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def adjacent_tiles(self, geobox: GeoBox) -&gt; list[TileWrapper]:\n    \"\"\"Get adjacent tiles from a STAC API.\n\n    Overwrite the default implementation from the STAC accessor\n    to use pre-downloaded extent files instead of querying the STAC API.\n    This results in a faster loading time, but requires the extent files to be downloaded beforehand.\n    This is done in the post_create step.\n\n    Args:\n        geobox (GeoBox): The geobox for which to get adjacent tiles.\n\n    Returns:\n        list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.\n\n    \"\"\"\n    # Assumes that the extent files are already present and the datacube is already created\n    self.assert_created()\n\n    resolution = int(self.extent.resolution.x)\n    extent_info = gpd.read_parquet(self._aux_dir / f\"ArcticDEM_Mosaic_Index_v4_1_{resolution}m.parquet\")\n    adjacent_tiles = extent_info.loc[extent_info.intersects(geobox.extent.geom)].copy()\n    if adjacent_tiles.empty:\n        return []\n    return [LazyStacTileWrapper(tile.dem_id, _get_stac_url(tile.dem_id)) for tile in adjacent_tiles.itertuples()]\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.adjacent_tiles(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox for which to get adjacent tiles.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> <p>Raises:</p> <ul> <li> <code>FileNotFoundError</code>             \u2013            <p>If the datacube does not exist.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\n\n    Raises:\n        FileNotFoundError: If the datacube does not exist.\n\n    \"\"\"\n    if not self.created:\n        msg = f\"Datacube {self.title} does not exist.\"\n        \" Please use the `create` method or pass `create=True` to `load`.\"\n        logger.error(msg)\n        raise FileNotFoundError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.create","title":"create","text":"<pre><code>create(overwrite: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def create(self, overwrite: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube. Defaults to False.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location\n\n    \"\"\"\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        var_encoding = {\n            name: {\n                \"chunks\": (self.chunk_size, self.chunk_size),\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Defaults to False.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.\n\n\n    \"\"\"\n    import geopandas as gpd\n    import pystac_client\n\n    if not self.created:\n        return None\n\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(session.store, mode=\"r\")\n    loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n\n    if len(loaded_tiles) == 0:\n        return None\n\n    catalog = pystac_client.Client.open(self.stac_api_url)\n    search = catalog.search(collections=[self.collection], ids=loaded_tiles)\n    stac_json = search.item_collection_as_dict()\n\n    gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.download_tile","title":"download_tile","text":"<pre><code>download_tile(tile: TileWrapper) -&gt; xr.Dataset\n</code></pre> <p>Download a tile from a STAC API and write it to a zarr datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded tile data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def download_tile(self, tile: TileWrapper) -&gt; xr.Dataset:\n    \"\"\"Download a tile from a STAC API and write it to a zarr datacube.\n\n    Args:\n        tile (TileWrapper): The tile to download and write.\n\n    Returns:\n        xr.Dataset: The downloaded tile data.\n\n    \"\"\"\n    from odc.stac import stac_load\n\n    tiledata = stac_load([tile.item], bands=self.channels, chunks=None, progress=None)\n\n    # TODO: Allow for multi-temporal datacubes\n    tiledata = tiledata.max(\"time\")\n\n    return tiledata\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.download_tile(tile)","title":"<code>tile</code>","text":"(<code>TileWrapper</code>)           \u2013            <p>The tile to download and write.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.load","title":"load","text":"<pre><code>load(\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load(\n    self,\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        geobox (GeoBox): The reference geobox to load the data for.\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        logger.debug(f\"{_geobox_repr(geobox)}: {geobox.resolution} original resolution\")\n\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        reference_geobox = geobox.to_crs(self.extent.crs, resolution=self.extent.resolution.x).pad(buffer)\n        self.procedural_download(reference_geobox, concurrency_mode=concurrency_mode)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(reference_geobox.extent, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.load(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to load the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.load(buffer)","title":"<code>buffer</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.load(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> <li> <code>concurrency_mode</code>               (<code>ConcurrencyModes</code>)           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    return self.load(_geobox_repr(ref.geobox), **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    xcube = xr.open_zarr(session.store, mask_and_scale=False, consolidated=False).set_coords(\"spatial_ref\")\n    return xcube\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def post_create(self):\n    \"\"\"Download the ArcticDEM mosaic extent info and store it in the datacube.\"\"\"\n    _download_arcticdem_extent(self._aux_dir)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(\n    geobox: GeoBox,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n)\n</code></pre> <p>Download the data for the given geobox.</p> Note <p>The \"threading\" concurrency mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If an unknown concurrency mode is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download(self, geobox: GeoBox, concurrency_mode: ConcurrencyModes = \"blocking\"):\n    \"\"\"Download the data for the given geobox.\n\n    Note:\n        The \"threading\" concurrency mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The reference geobox to download the data for.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Raises:\n        ValueError: If an unknown concurrency mode is provided.\n\n    \"\"\"\n    self.assert_created()\n    if concurrency_mode == \"blocking\":\n        self.procedural_download_blocking(geobox)\n    elif concurrency_mode == \"threading\":\n        self.procedural_download_threading(geobox)\n    else:\n        raise ValueError(f\"Unknown concurrency mode {concurrency_mode}\")\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.procedural_download(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to download the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.procedural_download(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.procedural_download_blocking","title":"procedural_download_blocking","text":"<pre><code>procedural_download_blocking(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in blocking mode.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If no tries are left.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_blocking(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in blocking mode.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If no tries are left.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: Procedural download in blocking mode\"):\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        session = self.repo.readonly_session(\"main\")\n        zcube = zarr.open(store=session.store, mode=\"r\")\n        loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n        new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n        logger.debug(\n            f\"{_geobox_repr(geobox)}:  {len(adjacent_tiles)=} &amp; {len(loaded_tiles)=}\"\n            f\" -&gt; {len(new_tiles)=} to download\"\n        )\n        if not new_tiles:\n            return\n\n        for tile in new_tiles:\n            with self.stopuhr(f\"{tile.id=}: Downloading one new tile in blocking mode\"):\n                logger.debug(f\"{tile.id=}: Start downloading\")\n                tiledata = self.download_tile(tile)\n\n            # Try to write the data to file until a limit is reached\n            limit = 100\n            for i in range(limit):\n                try:\n                    self._write_tile_to_zarr(tiledata, tile)\n                    break\n                except icechunk.ConflictError as conflict_error:\n                    logger.debug(f\"{tile.id=}: {conflict_error=} at retry {i}/{limit}\")\n            else:\n                logger.error(\n                    f\"{tile.id=}: {limit} tries to write the tile failed. \"\n                    \"Please check if the datacube is already created and not empty.\"\n                )\n                raise ValueError(f\"{tile.id=}: {limit} tries to write the tile failed.\")\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.procedural_download_blocking(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.procedural_download_threading","title":"procedural_download_threading","text":"<pre><code>procedural_download_threading(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in threading mode.</p> Note <p>This method ensures that only a single download is running at a time. It uses a SetQueue to prevent duplicate downloads. The threading mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>RuntimeError</code>             \u2013            <p>If the Python version is lower than 3.13.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_threading(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in threading mode.\n\n    Note:\n        This method ensures that only a single download is running at a time.\n        It uses a SetQueue to prevent duplicate downloads.\n        The threading mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        RuntimeError: If the Python version is lower than 3.13.\n\n    \"\"\"\n    if not _check_python_version(3, 13):\n        raise RuntimeError(\"Threading mode requires Python 3.13 or higher\")\n    with self._threading_handler:\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        # Wait until all new_items are loaded\n        prev_len = None\n        while True:\n            session = self.repo.readonly_session(\"main\")\n            zcube = zarr.open(store=session.store, mode=\"r\")\n            loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n            new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n            done_tiles = [tile for tile in adjacent_tiles if tile.id in loaded_tiles]\n            if not new_tiles:\n                break\n            if prev_len != len(new_tiles):\n                logger.debug(\n                    f\"{_geobox_repr(geobox)}: {len(done_tiles)} of {len(adjacent_tiles)} downloaded.\"\n                    f\" Missing: {[t.id for t in new_tiles]} Done: {[t.id for t in done_tiles]}\"\n                )\n            for tile in new_tiles:\n                self._threading_handler._queue.put(tile)\n            prev_len = len(new_tiles)\n            time.sleep(5)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.procedural_download_threading(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    import cartopy.crs as ccrs\n    import cartopy.feature as cfeature\n    import matplotlib.path as mpath\n    import matplotlib.pyplot as plt\n\n    tile_info = self.current_state()\n\n    if tile_info is None:\n        raise ValueError(\"Datacube is not created or loaded yet. Can't visualize!\")\n\n    # Define the projection\n    projection = ccrs.Stereographic(central_latitude=90, central_longitude=-45, true_scale_latitude=70)\n\n    # Create a figure\n    fig = None\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": projection})\n\n    # Set the extent to focus on the North Pole\n    ax.set_extent([-180, 180, 50, 90], crs=ccrs.PlateCarree())\n\n    # Add features\n    ax.add_feature(cfeature.LAND, zorder=0, edgecolor=\"black\", facecolor=\"white\")\n    ax.add_feature(cfeature.OCEAN, zorder=0, facecolor=\"lightgrey\")\n    ax.add_feature(cfeature.COASTLINE)\n    ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n    ax.add_feature(cfeature.LAKES, alpha=0.5)\n    ax.add_feature(cfeature.RIVERS)\n\n    # Add gridlines\n    gl = ax.gridlines(draw_labels=True)\n    gl.top_labels = False\n    gl.right_labels = False\n\n    # Compute a circle in axes coordinates, which we can use as a boundary\n    # for the map. We can pan/zoom as much as we like - the boundary will be\n    # permanently circular.\n    theta = np.linspace(0, 2 * np.pi, 100)\n    center, radius = [0.5, 0.5], 0.5\n    verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n    circle = mpath.Path(verts * radius + center)\n\n    ax.set_boundary(circle, transform=ax.transAxes)\n\n    tile_info.plot(\n        \"title\",\n        ax=ax,\n        transform=ccrs.PlateCarree(),\n        edgecolor=\"black\",\n        categorical=True,\n        aspect=\"equal\",\n        alpha=0.5,\n    )\n\n    if fig is not None:\n        return fig\n    else:\n        return ax\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.ArcticDEM32m.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend","title":"TCTrend","text":"<pre><code>TCTrend(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n)\n</code></pre> <p>               Bases: <code>GEEAccessor</code></p> <p>Accessor for TCTrend data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the zarr array. Should be equal to the extent geobox.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_tiles</code>             \u2013              <p>Get adjacent tiles from Google Earth Engine.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_tile</code>             \u2013              <p>Download a tile from Google Earth Engine.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Post create actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download the data for the given geobox.</p> </li> <li> <code>procedural_download_blocking</code>             \u2013              <p>Download tiles procedurally in blocking mode.</p> </li> <li> <code>procedural_download_threading</code>             \u2013              <p>Download tiles procedurally in threading mode.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = StopUhr(logger.debug)\n\n    # The TypeVar used by the ThreadingHandler was added in 3.12\n    # The Shutdown method of the queue was added in 3.13\n    # Hence, we don't want to import the module unless Python 3.13 is installed\n    if _check_python_version(3, 13):\n        from smart_geocubes._concurrency.threading import ThreadingHandler\n\n        self._threading_handler = ThreadingHandler(self._threading_download)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.adjacent_tiles","title":"adjacent_tiles","text":"<pre><code>adjacent_tiles(geobox: GeoBox) -&gt; list[TileWrapper]\n</code></pre> <p>Get adjacent tiles from Google Earth Engine.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[TileWrapper]</code>           \u2013            <p>list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def adjacent_tiles(self, geobox: GeoBox) -&gt; list[TileWrapper]:\n    \"\"\"Get adjacent tiles from Google Earth Engine.\n\n    Args:\n        geobox (GeoBox): The geobox for which to get adjacent tiles.\n\n    Returns:\n        list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.\n\n    \"\"\"\n    extent_tiles = GeoboxTiles(self.extent, (self.chunk_size, self.chunk_size))\n    return [TileWrapper(_tileidx_to_id(idx), extent_tiles[idx]) for idx in extent_tiles.tiles(geobox.extent)]\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.adjacent_tiles(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox for which to get adjacent tiles.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> <p>Raises:</p> <ul> <li> <code>FileNotFoundError</code>             \u2013            <p>If the datacube does not exist.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\n\n    Raises:\n        FileNotFoundError: If the datacube does not exist.\n\n    \"\"\"\n    if not self.created:\n        msg = f\"Datacube {self.title} does not exist.\"\n        \" Please use the `create` method or pass `create=True` to `load`.\"\n        logger.error(msg)\n        raise FileNotFoundError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.create","title":"create","text":"<pre><code>create(overwrite: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def create(self, overwrite: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube. Defaults to False.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location\n\n    \"\"\"\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        var_encoding = {\n            name: {\n                \"chunks\": (self.chunk_size, self.chunk_size),\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Defaults to False.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.\n\n    \"\"\"\n    import geopandas as gpd\n\n    if not self.created:\n        return None\n\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(session.store, mode=\"r\")\n    loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n\n    if len(loaded_tiles) == 0:\n        return None\n\n    tiles = GeoboxTiles(self.extent, (self.chunk_size, self.chunk_size))\n    loaded_tiles = [{\"geometry\": tiles[_id_to_tileidx(tid)].extent.geom, \"id\": tid} for tid in loaded_tiles]\n    gdf = gpd.GeoDataFrame(loaded_tiles, crs=self.extent.crs.to_wkt())\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.download_tile","title":"download_tile","text":"<pre><code>download_tile(\n    zcube: Group, tile: TileWrapper\n) -&gt; xr.Dataset\n</code></pre> <p>Download a tile from Google Earth Engine.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded tile data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def download_tile(self, zcube: zarr.Group, tile: TileWrapper) -&gt; xr.Dataset:\n    \"\"\"Download a tile from Google Earth Engine.\n\n    Args:\n        zcube (zarr.Group): The zarr datacube to download the tile to.\n        tile (TileWrapper): The tile to download.\n\n    Returns:\n        xr.Dataset: The downloaded tile data.\n\n    \"\"\"\n    import ee\n    import rioxarray  # noqa: F401\n    import xee  # noqa: F401\n\n    # Note: This is a little bit weird: First we create an own grid which overlaps to the chunks\n    # of the zarr array. Then we create a mosaic of the data and clip it to a single chunk.\n    # We could load the images from the collection directly instead of creating a mosaic.\n    # However, this would require more testing and probably results a lot of manual computation\n    # of slices etc. like in the stac variant. So for now, we just use the mosaic.\n    logging.getLogger(\"urllib3.connectionpool\").disabled = True\n    geom = ee.Geometry.Rectangle(tile.item.geographic_extent.boundingbox)\n    ee_img = ee.ImageCollection(self.collection).mosaic().clip(geom)\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=UserWarning, message=EE_WARN_MSG)\n        tiledata = xr.open_dataset(\n            ee_img,\n            engine=\"ee\",\n            geometry=geom,\n            crs=f\"epsg:{self.extent.crs.to_epsg()}\",\n            scale=self.extent.resolution.x,\n        )\n\n    # TODO: Allow for multi-temporal datacubes and lat/lon coordinates\n    tiledata = tiledata.max(\"time\").rename({\"lon\": \"x\", \"lat\": \"y\"}).transpose(\"y\", \"x\")\n\n    # Download the data\n    tiledata.load()\n    logging.getLogger(\"urllib3.connectionpool\").disabled = False\n\n    # Flip y-axis, because convention is x in positive direction and y in negative, but gee use positive for both\n    tiledata = tiledata.isel(y=slice(None, None, -1))\n\n    # For some reason xee does not always set the crs\n    tiledata = tiledata.odc.assign_crs(self.extent.crs)\n\n    # Recrop the data to the tile, since gee does not always return the exact extent\n    tiledata = tiledata.odc.crop(tile.item.extent)\n\n    # Save original min-max values for each band for clipping later\n    clip_values = {\n        band: (tiledata[band].min().values.item(), tiledata[band].max().values.item())\n        for band in tiledata.data_vars\n    }\n\n    # Interpolate missing values (there are very few, so we actually can interpolate them)\n    tiledata.rio.set_spatial_dims(x_dim=\"x\", y_dim=\"y\", inplace=True)\n    for band in tiledata.data_vars:\n        tiledata[band] = tiledata[band].rio.write_nodata(np.nan).rio.interpolate_na()\n\n    # Convert to uint8\n    for band in tiledata.data_vars:\n        band_min, band_max = clip_values[band]\n        tiledata[band] = (\n            tiledata[band].clip(band_min, band_max, keep_attrs=True).astype(\"uint8\").rio.write_nodata(None)\n        )\n\n    return tiledata\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.download_tile(zcube)","title":"<code>zcube</code>","text":"(<code>Group</code>)           \u2013            <p>The zarr datacube to download the tile to.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.download_tile(tile)","title":"<code>tile</code>","text":"(<code>TileWrapper</code>)           \u2013            <p>The tile to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.load","title":"load","text":"<pre><code>load(\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load(\n    self,\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        geobox (GeoBox): The reference geobox to load the data for.\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        logger.debug(f\"{_geobox_repr(geobox)}: {geobox.resolution} original resolution\")\n\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        reference_geobox = geobox.to_crs(self.extent.crs, resolution=self.extent.resolution.x).pad(buffer)\n        self.procedural_download(reference_geobox, concurrency_mode=concurrency_mode)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(reference_geobox.extent, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.load(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to load the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.load(buffer)","title":"<code>buffer</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.load(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> <li> <code>concurrency_mode</code>               (<code>ConcurrencyModes</code>)           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    return self.load(_geobox_repr(ref.geobox), **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    xcube = xr.open_zarr(session.store, mask_and_scale=False, consolidated=False).set_coords(\"spatial_ref\")\n    return xcube\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Post create actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def post_create(self):\n    \"\"\"Post create actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(\n    geobox: GeoBox,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n)\n</code></pre> <p>Download the data for the given geobox.</p> Note <p>The \"threading\" concurrency mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If an unknown concurrency mode is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download(self, geobox: GeoBox, concurrency_mode: ConcurrencyModes = \"blocking\"):\n    \"\"\"Download the data for the given geobox.\n\n    Note:\n        The \"threading\" concurrency mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The reference geobox to download the data for.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Raises:\n        ValueError: If an unknown concurrency mode is provided.\n\n    \"\"\"\n    self.assert_created()\n    if concurrency_mode == \"blocking\":\n        self.procedural_download_blocking(geobox)\n    elif concurrency_mode == \"threading\":\n        self.procedural_download_threading(geobox)\n    else:\n        raise ValueError(f\"Unknown concurrency mode {concurrency_mode}\")\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.procedural_download(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to download the data for.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.procedural_download(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.procedural_download_blocking","title":"procedural_download_blocking","text":"<pre><code>procedural_download_blocking(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in blocking mode.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If no tries are left.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_blocking(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in blocking mode.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If no tries are left.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: Procedural download in blocking mode\"):\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        session = self.repo.readonly_session(\"main\")\n        zcube = zarr.open(store=session.store, mode=\"r\")\n        loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n        new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n        logger.debug(\n            f\"{_geobox_repr(geobox)}:  {len(adjacent_tiles)=} &amp; {len(loaded_tiles)=}\"\n            f\" -&gt; {len(new_tiles)=} to download\"\n        )\n        if not new_tiles:\n            return\n\n        for tile in new_tiles:\n            with self.stopuhr(f\"{tile.id=}: Downloading one new tile in blocking mode\"):\n                logger.debug(f\"{tile.id=}: Start downloading\")\n                tiledata = self.download_tile(tile)\n\n            # Try to write the data to file until a limit is reached\n            limit = 100\n            for i in range(limit):\n                try:\n                    self._write_tile_to_zarr(tiledata, tile)\n                    break\n                except icechunk.ConflictError as conflict_error:\n                    logger.debug(f\"{tile.id=}: {conflict_error=} at retry {i}/{limit}\")\n            else:\n                logger.error(\n                    f\"{tile.id=}: {limit} tries to write the tile failed. \"\n                    \"Please check if the datacube is already created and not empty.\"\n                )\n                raise ValueError(f\"{tile.id=}: {limit} tries to write the tile failed.\")\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.procedural_download_blocking(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.procedural_download_threading","title":"procedural_download_threading","text":"<pre><code>procedural_download_threading(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in threading mode.</p> Note <p>This method ensures that only a single download is running at a time. It uses a SetQueue to prevent duplicate downloads. The threading mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>RuntimeError</code>             \u2013            <p>If the Python version is lower than 3.13.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_threading(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in threading mode.\n\n    Note:\n        This method ensures that only a single download is running at a time.\n        It uses a SetQueue to prevent duplicate downloads.\n        The threading mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        RuntimeError: If the Python version is lower than 3.13.\n\n    \"\"\"\n    if not _check_python_version(3, 13):\n        raise RuntimeError(\"Threading mode requires Python 3.13 or higher\")\n    with self._threading_handler:\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        # Wait until all new_items are loaded\n        prev_len = None\n        while True:\n            session = self.repo.readonly_session(\"main\")\n            zcube = zarr.open(store=session.store, mode=\"r\")\n            loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n            new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n            done_tiles = [tile for tile in adjacent_tiles if tile.id in loaded_tiles]\n            if not new_tiles:\n                break\n            if prev_len != len(new_tiles):\n                logger.debug(\n                    f\"{_geobox_repr(geobox)}: {len(done_tiles)} of {len(adjacent_tiles)} downloaded.\"\n                    f\" Missing: {[t.id for t in new_tiles]} Done: {[t.id for t in done_tiles]}\"\n                )\n            for tile in new_tiles:\n                self._threading_handler._queue.put(tile)\n            prev_len = len(new_tiles)\n            time.sleep(5)\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.procedural_download_threading(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/tctrend.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    import cartopy.crs as ccrs\n    import cartopy.feature as cfeature\n    import matplotlib.pyplot as plt\n\n    tile_info = self.current_state()\n\n    if tile_info is None:\n        raise ValueError(\"Datacube is not created or loaded yet. Can't visualize!\")\n\n    # Define the projection\n    projection = ccrs.PlateCarree()\n\n    # Create a figure\n    fig = None\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": projection})\n\n    # Set the extent to show the whole world\n    ax.set_extent([-180, 180, -90, 90], crs=ccrs.PlateCarree())\n\n    # Add features\n    ax.add_feature(cfeature.LAND, zorder=0, edgecolor=\"black\", facecolor=\"white\")\n    ax.add_feature(cfeature.OCEAN, zorder=0, facecolor=\"lightgrey\")\n    ax.add_feature(cfeature.COASTLINE)\n    ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n    ax.add_feature(cfeature.LAKES, alpha=0.5)\n    ax.add_feature(cfeature.RIVERS)\n\n    # Add gridlines\n    gl = ax.gridlines(draw_labels=True)\n    gl.top_labels = False\n    gl.right_labels = False\n\n    tile_info.plot(\n        \"id\",\n        ax=ax,\n        transform=ccrs.PlateCarree(),\n        edgecolor=\"black\",\n        categorical=True,\n        aspect=\"equal\",\n        alpha=0.5,\n    )\n\n    if fig is not None:\n        return fig\n    else:\n        return ax\n</code></pre>"},{"location":"reference/smart_geocubes/#smart_geocubes.TCTrend.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/accessors/","title":"smart_geocubes.accessors","text":""},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors","title":"smart_geocubes.accessors","text":"<p>Smart-Geocubes cccessor implementations.</p> <p>Modules:</p> <ul> <li> <code>base</code>           \u2013            <p>Base class for remote accessors.</p> </li> <li> <code>gee</code>           \u2013            <p>Google Earth Engine Accessor for Smart Geocubes.</p> </li> <li> <code>stac</code>           \u2013            <p>STAC Accessor for Smart Geocubes.</p> </li> </ul> <p>Classes:</p> <ul> <li> <code>GEEAccessor</code>           \u2013            <p>Accessor for Google Earth Engine data.</p> </li> <li> <code>RemoteAccessor</code>           \u2013            <p>Base class for remote accessors.</p> </li> <li> <code>STACAccessor</code>           \u2013            <p>Accessor for STAC data.</p> </li> </ul>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor","title":"GEEAccessor","text":"<pre><code>GEEAccessor(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n)\n</code></pre> <p>               Bases: <code>RemoteAccessor</code></p> <p>Accessor for Google Earth Engine data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the underlaying zarr array. Should be equal to the extent geobox. However, this property is used to find the target index of the downloaded data, so better save than sorry.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_tiles</code>             \u2013              <p>Get adjacent tiles from Google Earth Engine.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_tile</code>             \u2013              <p>Download a tile from Google Earth Engine.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Post create actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download the data for the given geobox.</p> </li> <li> <code>procedural_download_blocking</code>             \u2013              <p>Download tiles procedurally in blocking mode.</p> </li> <li> <code>procedural_download_threading</code>             \u2013              <p>Download tiles procedurally in threading mode.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize currently stored tiles / chunk.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = StopUhr(logger.debug)\n\n    # The TypeVar used by the ThreadingHandler was added in 3.12\n    # The Shutdown method of the queue was added in 3.13\n    # Hence, we don't want to import the module unless Python 3.13 is installed\n    if _check_python_version(3, 13):\n        from smart_geocubes._concurrency.threading import ThreadingHandler\n\n        self._threading_handler = ThreadingHandler(self._threading_download)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.adjacent_tiles","title":"adjacent_tiles","text":"<pre><code>adjacent_tiles(geobox: GeoBox) -&gt; list[TileWrapper]\n</code></pre> <p>Get adjacent tiles from Google Earth Engine.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[TileWrapper]</code>           \u2013            <p>list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def adjacent_tiles(self, geobox: GeoBox) -&gt; list[TileWrapper]:\n    \"\"\"Get adjacent tiles from Google Earth Engine.\n\n    Args:\n        geobox (GeoBox): The geobox for which to get adjacent tiles.\n\n    Returns:\n        list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.\n\n    \"\"\"\n    extent_tiles = GeoboxTiles(self.extent, (self.chunk_size, self.chunk_size))\n    return [TileWrapper(_tileidx_to_id(idx), extent_tiles[idx]) for idx in extent_tiles.tiles(geobox.extent)]\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.adjacent_tiles(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox for which to get adjacent tiles.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> <p>Raises:</p> <ul> <li> <code>FileNotFoundError</code>             \u2013            <p>If the datacube does not exist.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\n\n    Raises:\n        FileNotFoundError: If the datacube does not exist.\n\n    \"\"\"\n    if not self.created:\n        msg = f\"Datacube {self.title} does not exist.\"\n        \" Please use the `create` method or pass `create=True` to `load`.\"\n        logger.error(msg)\n        raise FileNotFoundError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.create","title":"create","text":"<pre><code>create(overwrite: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def create(self, overwrite: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube. Defaults to False.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location\n\n    \"\"\"\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        var_encoding = {\n            name: {\n                \"chunks\": (self.chunk_size, self.chunk_size),\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Defaults to False.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.\n\n    \"\"\"\n    import geopandas as gpd\n\n    if not self.created:\n        return None\n\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(session.store, mode=\"r\")\n    loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n\n    if len(loaded_tiles) == 0:\n        return None\n\n    tiles = GeoboxTiles(self.extent, (self.chunk_size, self.chunk_size))\n    loaded_tiles = [{\"geometry\": tiles[_id_to_tileidx(tid)].extent.geom, \"id\": tid} for tid in loaded_tiles]\n    gdf = gpd.GeoDataFrame(loaded_tiles, crs=self.extent.crs.to_wkt())\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.download_tile","title":"download_tile","text":"<pre><code>download_tile(\n    zcube: Group, tile: TileWrapper\n) -&gt; xr.Dataset\n</code></pre> <p>Download a tile from Google Earth Engine.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded tile data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def download_tile(self, zcube: zarr.Group, tile: TileWrapper) -&gt; xr.Dataset:\n    \"\"\"Download a tile from Google Earth Engine.\n\n    Args:\n        zcube (zarr.Group): The zarr datacube to download the tile to.\n        tile (TileWrapper): The tile to download.\n\n    Returns:\n        xr.Dataset: The downloaded tile data.\n\n    \"\"\"\n    import ee\n    import rioxarray  # noqa: F401\n    import xee  # noqa: F401\n\n    # Note: This is a little bit weird: First we create an own grid which overlaps to the chunks\n    # of the zarr array. Then we create a mosaic of the data and clip it to a single chunk.\n    # We could load the images from the collection directly instead of creating a mosaic.\n    # However, this would require more testing and probably results a lot of manual computation\n    # of slices etc. like in the stac variant. So for now, we just use the mosaic.\n    logging.getLogger(\"urllib3.connectionpool\").disabled = True\n    geom = ee.Geometry.Rectangle(tile.item.geographic_extent.boundingbox)\n    ee_img = ee.ImageCollection(self.collection).mosaic().clip(geom)\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=UserWarning, message=EE_WARN_MSG)\n        tiledata = xr.open_dataset(\n            ee_img,\n            engine=\"ee\",\n            geometry=geom,\n            crs=f\"epsg:{self.extent.crs.to_epsg()}\",\n            scale=self.extent.resolution.x,\n        )\n\n    # TODO: Allow for multi-temporal datacubes and lat/lon coordinates\n    tiledata = tiledata.max(\"time\").rename({\"lon\": \"x\", \"lat\": \"y\"}).transpose(\"y\", \"x\")\n\n    # Download the data\n    tiledata.load()\n    logging.getLogger(\"urllib3.connectionpool\").disabled = False\n\n    # Flip y-axis, because convention is x in positive direction and y in negative, but gee use positive for both\n    tiledata = tiledata.isel(y=slice(None, None, -1))\n\n    # For some reason xee does not always set the crs\n    tiledata = tiledata.odc.assign_crs(self.extent.crs)\n\n    # Recrop the data to the tile, since gee does not always return the exact extent\n    tiledata = tiledata.odc.crop(tile.item.extent)\n\n    # Save original min-max values for each band for clipping later\n    clip_values = {\n        band: (tiledata[band].min().values.item(), tiledata[band].max().values.item())\n        for band in tiledata.data_vars\n    }\n\n    # Interpolate missing values (there are very few, so we actually can interpolate them)\n    tiledata.rio.set_spatial_dims(x_dim=\"x\", y_dim=\"y\", inplace=True)\n    for band in tiledata.data_vars:\n        tiledata[band] = tiledata[band].rio.write_nodata(np.nan).rio.interpolate_na()\n\n    # Convert to uint8\n    for band in tiledata.data_vars:\n        band_min, band_max = clip_values[band]\n        tiledata[band] = (\n            tiledata[band].clip(band_min, band_max, keep_attrs=True).astype(\"uint8\").rio.write_nodata(None)\n        )\n\n    return tiledata\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.download_tile(zcube)","title":"<code>zcube</code>","text":"(<code>Group</code>)           \u2013            <p>The zarr datacube to download the tile to.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.download_tile(tile)","title":"<code>tile</code>","text":"(<code>TileWrapper</code>)           \u2013            <p>The tile to download.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.load","title":"load","text":"<pre><code>load(\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load(\n    self,\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        geobox (GeoBox): The reference geobox to load the data for.\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        logger.debug(f\"{_geobox_repr(geobox)}: {geobox.resolution} original resolution\")\n\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        reference_geobox = geobox.to_crs(self.extent.crs, resolution=self.extent.resolution.x).pad(buffer)\n        self.procedural_download(reference_geobox, concurrency_mode=concurrency_mode)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(reference_geobox.extent, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.load(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to load the data for.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.load(buffer)","title":"<code>buffer</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.load(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> <li> <code>concurrency_mode</code>               (<code>ConcurrencyModes</code>)           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    return self.load(_geobox_repr(ref.geobox), **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    xcube = xr.open_zarr(session.store, mask_and_scale=False, consolidated=False).set_coords(\"spatial_ref\")\n    return xcube\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Post create actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def post_create(self):\n    \"\"\"Post create actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(\n    geobox: GeoBox,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n)\n</code></pre> <p>Download the data for the given geobox.</p> Note <p>The \"threading\" concurrency mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If an unknown concurrency mode is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download(self, geobox: GeoBox, concurrency_mode: ConcurrencyModes = \"blocking\"):\n    \"\"\"Download the data for the given geobox.\n\n    Note:\n        The \"threading\" concurrency mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The reference geobox to download the data for.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Raises:\n        ValueError: If an unknown concurrency mode is provided.\n\n    \"\"\"\n    self.assert_created()\n    if concurrency_mode == \"blocking\":\n        self.procedural_download_blocking(geobox)\n    elif concurrency_mode == \"threading\":\n        self.procedural_download_threading(geobox)\n    else:\n        raise ValueError(f\"Unknown concurrency mode {concurrency_mode}\")\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.procedural_download(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to download the data for.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.procedural_download(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.procedural_download_blocking","title":"procedural_download_blocking","text":"<pre><code>procedural_download_blocking(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in blocking mode.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If no tries are left.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_blocking(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in blocking mode.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If no tries are left.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: Procedural download in blocking mode\"):\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        session = self.repo.readonly_session(\"main\")\n        zcube = zarr.open(store=session.store, mode=\"r\")\n        loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n        new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n        logger.debug(\n            f\"{_geobox_repr(geobox)}:  {len(adjacent_tiles)=} &amp; {len(loaded_tiles)=}\"\n            f\" -&gt; {len(new_tiles)=} to download\"\n        )\n        if not new_tiles:\n            return\n\n        for tile in new_tiles:\n            with self.stopuhr(f\"{tile.id=}: Downloading one new tile in blocking mode\"):\n                logger.debug(f\"{tile.id=}: Start downloading\")\n                tiledata = self.download_tile(tile)\n\n            # Try to write the data to file until a limit is reached\n            limit = 100\n            for i in range(limit):\n                try:\n                    self._write_tile_to_zarr(tiledata, tile)\n                    break\n                except icechunk.ConflictError as conflict_error:\n                    logger.debug(f\"{tile.id=}: {conflict_error=} at retry {i}/{limit}\")\n            else:\n                logger.error(\n                    f\"{tile.id=}: {limit} tries to write the tile failed. \"\n                    \"Please check if the datacube is already created and not empty.\"\n                )\n                raise ValueError(f\"{tile.id=}: {limit} tries to write the tile failed.\")\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.procedural_download_blocking(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.procedural_download_threading","title":"procedural_download_threading","text":"<pre><code>procedural_download_threading(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in threading mode.</p> Note <p>This method ensures that only a single download is running at a time. It uses a SetQueue to prevent duplicate downloads. The threading mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>RuntimeError</code>             \u2013            <p>If the Python version is lower than 3.13.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_threading(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in threading mode.\n\n    Note:\n        This method ensures that only a single download is running at a time.\n        It uses a SetQueue to prevent duplicate downloads.\n        The threading mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        RuntimeError: If the Python version is lower than 3.13.\n\n    \"\"\"\n    if not _check_python_version(3, 13):\n        raise RuntimeError(\"Threading mode requires Python 3.13 or higher\")\n    with self._threading_handler:\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        # Wait until all new_items are loaded\n        prev_len = None\n        while True:\n            session = self.repo.readonly_session(\"main\")\n            zcube = zarr.open(store=session.store, mode=\"r\")\n            loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n            new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n            done_tiles = [tile for tile in adjacent_tiles if tile.id in loaded_tiles]\n            if not new_tiles:\n                break\n            if prev_len != len(new_tiles):\n                logger.debug(\n                    f\"{_geobox_repr(geobox)}: {len(done_tiles)} of {len(adjacent_tiles)} downloaded.\"\n                    f\" Missing: {[t.id for t in new_tiles]} Done: {[t.id for t in done_tiles]}\"\n                )\n            for tile in new_tiles:\n                self._threading_handler._queue.put(tile)\n            prev_len = len(new_tiles)\n            time.sleep(5)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.procedural_download_threading(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.visualize_state","title":"visualize_state  <code>abstractmethod</code>","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize currently stored tiles / chunk.</p> <p>Must be implemented by the DatasetAccessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>@abstractmethod\ndef visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize currently stored tiles / chunk.\n\n    Must be implemented by the DatasetAccessor.\n\n    Args:\n        ax (plt.Axes | None, optional): The axes drawn to. If None, will create a new figure and axes.\n            Defaults to None.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization\n\n    \"\"\"\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.GEEAccessor.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes. Defaults to None.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor","title":"RemoteAccessor","text":"<pre><code>RemoteAccessor(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Base class for remote accessors.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the underlaying zarr array. Should be equal to the extent geobox. However, this property is used to find the target index of the downloaded data, so better save than sorry.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_tiles</code>             \u2013              <p>Get the adjacent tiles for the given geobox.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles / chunk.</p> </li> <li> <code>download_tile</code>             \u2013              <p>Download the data for the given tile.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Post create actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download the data for the given geobox.</p> </li> <li> <code>procedural_download_blocking</code>             \u2013              <p>Download tiles procedurally in blocking mode.</p> </li> <li> <code>procedural_download_threading</code>             \u2013              <p>Download tiles procedurally in threading mode.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize currently stored tiles / chunk.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = StopUhr(logger.debug)\n\n    # The TypeVar used by the ThreadingHandler was added in 3.12\n    # The Shutdown method of the queue was added in 3.13\n    # Hence, we don't want to import the module unless Python 3.13 is installed\n    if _check_python_version(3, 13):\n        from smart_geocubes._concurrency.threading import ThreadingHandler\n\n        self._threading_handler = ThreadingHandler(self._threading_download)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.adjacent_tiles","title":"adjacent_tiles  <code>abstractmethod</code>","text":"<pre><code>adjacent_tiles(geobox: GeoBox) -&gt; list[TileWrapper]\n</code></pre> <p>Get the adjacent tiles for the given geobox.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[TileWrapper]</code>           \u2013            <p>list[TileWrapper]: The adjacent tile(-id)s for the given geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>@abstractmethod\ndef adjacent_tiles(self, geobox: GeoBox) -&gt; list[TileWrapper]:\n    \"\"\"Get the adjacent tiles for the given geobox.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        geobox (GeoBox): The reference geobox to get the adjacent tiles for.\n\n    Returns:\n        list[TileWrapper]: The adjacent tile(-id)s for the given geobox.\n\n    \"\"\"\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.adjacent_tiles(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to get the adjacent tiles for.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> <p>Raises:</p> <ul> <li> <code>FileNotFoundError</code>             \u2013            <p>If the datacube does not exist.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\n\n    Raises:\n        FileNotFoundError: If the datacube does not exist.\n\n    \"\"\"\n    if not self.created:\n        msg = f\"Datacube {self.title} does not exist.\"\n        \" Please use the `create` method or pass `create=True` to `load`.\"\n        logger.error(msg)\n        raise FileNotFoundError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.create","title":"create","text":"<pre><code>create(overwrite: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def create(self, overwrite: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube. Defaults to False.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location\n\n    \"\"\"\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        var_encoding = {\n            name: {\n                \"chunks\": (self.chunk_size, self.chunk_size),\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Defaults to False.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.current_state","title":"current_state  <code>abstractmethod</code>","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles / chunk.</p> <p>Must be implemented by the Accessor.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame | None: Tile or Chunk info.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>@abstractmethod\ndef current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles / chunk.\n\n    Must be implemented by the Accessor.\n\n    Returns:\n        gpd.GeoDataFrame | None: Tile or Chunk info.\n\n    \"\"\"\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.download_tile","title":"download_tile  <code>abstractmethod</code>","text":"<pre><code>download_tile(tile: TileWrapper) -&gt; xr.Dataset\n</code></pre> <p>Download the data for the given tile.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded tile data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>@abstractmethod\ndef download_tile(self, tile: TileWrapper) -&gt; xr.Dataset:\n    \"\"\"Download the data for the given tile.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        tile (TileWrapper): The reference tile to download the data for.\n\n    Returns:\n        xr.Dataset: The downloaded tile data.\n\n    \"\"\"\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.download_tile(tile)","title":"<code>tile</code>","text":"(<code>TileWrapper</code>)           \u2013            <p>The reference tile to download the data for.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.load","title":"load","text":"<pre><code>load(\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load(\n    self,\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        geobox (GeoBox): The reference geobox to load the data for.\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        logger.debug(f\"{_geobox_repr(geobox)}: {geobox.resolution} original resolution\")\n\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        reference_geobox = geobox.to_crs(self.extent.crs, resolution=self.extent.resolution.x).pad(buffer)\n        self.procedural_download(reference_geobox, concurrency_mode=concurrency_mode)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(reference_geobox.extent, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.load(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to load the data for.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.load(buffer)","title":"<code>buffer</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.load(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> <li> <code>concurrency_mode</code>               (<code>ConcurrencyModes</code>)           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    return self.load(_geobox_repr(ref.geobox), **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    xcube = xr.open_zarr(session.store, mask_and_scale=False, consolidated=False).set_coords(\"spatial_ref\")\n    return xcube\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Post create actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def post_create(self):\n    \"\"\"Post create actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(\n    geobox: GeoBox,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n)\n</code></pre> <p>Download the data for the given geobox.</p> Note <p>The \"threading\" concurrency mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If an unknown concurrency mode is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download(self, geobox: GeoBox, concurrency_mode: ConcurrencyModes = \"blocking\"):\n    \"\"\"Download the data for the given geobox.\n\n    Note:\n        The \"threading\" concurrency mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The reference geobox to download the data for.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Raises:\n        ValueError: If an unknown concurrency mode is provided.\n\n    \"\"\"\n    self.assert_created()\n    if concurrency_mode == \"blocking\":\n        self.procedural_download_blocking(geobox)\n    elif concurrency_mode == \"threading\":\n        self.procedural_download_threading(geobox)\n    else:\n        raise ValueError(f\"Unknown concurrency mode {concurrency_mode}\")\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.procedural_download(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to download the data for.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.procedural_download(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.procedural_download_blocking","title":"procedural_download_blocking","text":"<pre><code>procedural_download_blocking(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in blocking mode.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If no tries are left.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_blocking(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in blocking mode.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If no tries are left.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: Procedural download in blocking mode\"):\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        session = self.repo.readonly_session(\"main\")\n        zcube = zarr.open(store=session.store, mode=\"r\")\n        loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n        new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n        logger.debug(\n            f\"{_geobox_repr(geobox)}:  {len(adjacent_tiles)=} &amp; {len(loaded_tiles)=}\"\n            f\" -&gt; {len(new_tiles)=} to download\"\n        )\n        if not new_tiles:\n            return\n\n        for tile in new_tiles:\n            with self.stopuhr(f\"{tile.id=}: Downloading one new tile in blocking mode\"):\n                logger.debug(f\"{tile.id=}: Start downloading\")\n                tiledata = self.download_tile(tile)\n\n            # Try to write the data to file until a limit is reached\n            limit = 100\n            for i in range(limit):\n                try:\n                    self._write_tile_to_zarr(tiledata, tile)\n                    break\n                except icechunk.ConflictError as conflict_error:\n                    logger.debug(f\"{tile.id=}: {conflict_error=} at retry {i}/{limit}\")\n            else:\n                logger.error(\n                    f\"{tile.id=}: {limit} tries to write the tile failed. \"\n                    \"Please check if the datacube is already created and not empty.\"\n                )\n                raise ValueError(f\"{tile.id=}: {limit} tries to write the tile failed.\")\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.procedural_download_blocking(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.procedural_download_threading","title":"procedural_download_threading","text":"<pre><code>procedural_download_threading(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in threading mode.</p> Note <p>This method ensures that only a single download is running at a time. It uses a SetQueue to prevent duplicate downloads. The threading mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>RuntimeError</code>             \u2013            <p>If the Python version is lower than 3.13.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_threading(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in threading mode.\n\n    Note:\n        This method ensures that only a single download is running at a time.\n        It uses a SetQueue to prevent duplicate downloads.\n        The threading mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        RuntimeError: If the Python version is lower than 3.13.\n\n    \"\"\"\n    if not _check_python_version(3, 13):\n        raise RuntimeError(\"Threading mode requires Python 3.13 or higher\")\n    with self._threading_handler:\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        # Wait until all new_items are loaded\n        prev_len = None\n        while True:\n            session = self.repo.readonly_session(\"main\")\n            zcube = zarr.open(store=session.store, mode=\"r\")\n            loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n            new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n            done_tiles = [tile for tile in adjacent_tiles if tile.id in loaded_tiles]\n            if not new_tiles:\n                break\n            if prev_len != len(new_tiles):\n                logger.debug(\n                    f\"{_geobox_repr(geobox)}: {len(done_tiles)} of {len(adjacent_tiles)} downloaded.\"\n                    f\" Missing: {[t.id for t in new_tiles]} Done: {[t.id for t in done_tiles]}\"\n                )\n            for tile in new_tiles:\n                self._threading_handler._queue.put(tile)\n            prev_len = len(new_tiles)\n            time.sleep(5)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.procedural_download_threading(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.visualize_state","title":"visualize_state  <code>abstractmethod</code>","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize currently stored tiles / chunk.</p> <p>Must be implemented by the DatasetAccessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>@abstractmethod\ndef visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize currently stored tiles / chunk.\n\n    Must be implemented by the DatasetAccessor.\n\n    Args:\n        ax (plt.Axes | None, optional): The axes drawn to. If None, will create a new figure and axes.\n            Defaults to None.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization\n\n    \"\"\"\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.RemoteAccessor.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes. Defaults to None.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor","title":"STACAccessor","text":"<pre><code>STACAccessor(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n)\n</code></pre> <p>               Bases: <code>RemoteAccessor</code></p> <p>Accessor for STAC data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the underlaying zarr array. Should be equal to the extent geobox. However, this property is used to find the target index of the downloaded data, so better save than sorry.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_tiles</code>             \u2013              <p>Get adjacent tiles from a STAC API.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_tile</code>             \u2013              <p>Download a tile from a STAC API and write it to a zarr datacube.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Post create actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download the data for the given geobox.</p> </li> <li> <code>procedural_download_blocking</code>             \u2013              <p>Download tiles procedurally in blocking mode.</p> </li> <li> <code>procedural_download_threading</code>             \u2013              <p>Download tiles procedurally in threading mode.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize currently stored tiles / chunk.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = StopUhr(logger.debug)\n\n    # The TypeVar used by the ThreadingHandler was added in 3.12\n    # The Shutdown method of the queue was added in 3.13\n    # Hence, we don't want to import the module unless Python 3.13 is installed\n    if _check_python_version(3, 13):\n        from smart_geocubes._concurrency.threading import ThreadingHandler\n\n        self._threading_handler = ThreadingHandler(self._threading_download)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.adjacent_tiles","title":"adjacent_tiles","text":"<pre><code>adjacent_tiles(geobox: GeoBox) -&gt; list[TileWrapper]\n</code></pre> <p>Get adjacent tiles from a STAC API.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[TileWrapper]</code>           \u2013            <p>list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def adjacent_tiles(self, geobox: GeoBox) -&gt; list[TileWrapper]:\n    \"\"\"Get adjacent tiles from a STAC API.\n\n    Args:\n        geobox (GeoBox): The geobox for which to get adjacent tiles.\n\n    Returns:\n        list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.\n\n    \"\"\"\n    import pystac_client\n\n    catalog = pystac_client.Client.open(self.stac_api_url)\n    search = catalog.search(collections=[self.collection], intersects=geobox.to_crs(\"EPSG:4326\").extent.geom)\n    items = list(search.items())\n    return [TileWrapper(item.id, item) for item in items]\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.adjacent_tiles(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox for which to get adjacent tiles.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> <p>Raises:</p> <ul> <li> <code>FileNotFoundError</code>             \u2013            <p>If the datacube does not exist.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\n\n    Raises:\n        FileNotFoundError: If the datacube does not exist.\n\n    \"\"\"\n    if not self.created:\n        msg = f\"Datacube {self.title} does not exist.\"\n        \" Please use the `create` method or pass `create=True` to `load`.\"\n        logger.error(msg)\n        raise FileNotFoundError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.create","title":"create","text":"<pre><code>create(overwrite: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def create(self, overwrite: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube. Defaults to False.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location\n\n    \"\"\"\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        var_encoding = {\n            name: {\n                \"chunks\": (self.chunk_size, self.chunk_size),\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Defaults to False.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.\n\n\n    \"\"\"\n    import geopandas as gpd\n    import pystac_client\n\n    if not self.created:\n        return None\n\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(session.store, mode=\"r\")\n    loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n\n    if len(loaded_tiles) == 0:\n        return None\n\n    catalog = pystac_client.Client.open(self.stac_api_url)\n    search = catalog.search(collections=[self.collection], ids=loaded_tiles)\n    stac_json = search.item_collection_as_dict()\n\n    gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.download_tile","title":"download_tile","text":"<pre><code>download_tile(tile: TileWrapper) -&gt; xr.Dataset\n</code></pre> <p>Download a tile from a STAC API and write it to a zarr datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded tile data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def download_tile(self, tile: TileWrapper) -&gt; xr.Dataset:\n    \"\"\"Download a tile from a STAC API and write it to a zarr datacube.\n\n    Args:\n        tile (TileWrapper): The tile to download and write.\n\n    Returns:\n        xr.Dataset: The downloaded tile data.\n\n    \"\"\"\n    from odc.stac import stac_load\n\n    tiledata = stac_load([tile.item], bands=self.channels, chunks=None, progress=None)\n\n    # TODO: Allow for multi-temporal datacubes\n    tiledata = tiledata.max(\"time\")\n\n    return tiledata\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.download_tile(tile)","title":"<code>tile</code>","text":"(<code>TileWrapper</code>)           \u2013            <p>The tile to download and write.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.load","title":"load","text":"<pre><code>load(\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load(\n    self,\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        geobox (GeoBox): The reference geobox to load the data for.\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        logger.debug(f\"{_geobox_repr(geobox)}: {geobox.resolution} original resolution\")\n\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        reference_geobox = geobox.to_crs(self.extent.crs, resolution=self.extent.resolution.x).pad(buffer)\n        self.procedural_download(reference_geobox, concurrency_mode=concurrency_mode)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(reference_geobox.extent, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.load(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to load the data for.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.load(buffer)","title":"<code>buffer</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.load(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> <li> <code>concurrency_mode</code>               (<code>ConcurrencyModes</code>)           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    return self.load(_geobox_repr(ref.geobox), **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    xcube = xr.open_zarr(session.store, mask_and_scale=False, consolidated=False).set_coords(\"spatial_ref\")\n    return xcube\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Post create actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def post_create(self):\n    \"\"\"Post create actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(\n    geobox: GeoBox,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n)\n</code></pre> <p>Download the data for the given geobox.</p> Note <p>The \"threading\" concurrency mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If an unknown concurrency mode is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download(self, geobox: GeoBox, concurrency_mode: ConcurrencyModes = \"blocking\"):\n    \"\"\"Download the data for the given geobox.\n\n    Note:\n        The \"threading\" concurrency mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The reference geobox to download the data for.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Raises:\n        ValueError: If an unknown concurrency mode is provided.\n\n    \"\"\"\n    self.assert_created()\n    if concurrency_mode == \"blocking\":\n        self.procedural_download_blocking(geobox)\n    elif concurrency_mode == \"threading\":\n        self.procedural_download_threading(geobox)\n    else:\n        raise ValueError(f\"Unknown concurrency mode {concurrency_mode}\")\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.procedural_download(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to download the data for.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.procedural_download(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.procedural_download_blocking","title":"procedural_download_blocking","text":"<pre><code>procedural_download_blocking(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in blocking mode.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If no tries are left.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_blocking(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in blocking mode.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If no tries are left.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: Procedural download in blocking mode\"):\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        session = self.repo.readonly_session(\"main\")\n        zcube = zarr.open(store=session.store, mode=\"r\")\n        loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n        new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n        logger.debug(\n            f\"{_geobox_repr(geobox)}:  {len(adjacent_tiles)=} &amp; {len(loaded_tiles)=}\"\n            f\" -&gt; {len(new_tiles)=} to download\"\n        )\n        if not new_tiles:\n            return\n\n        for tile in new_tiles:\n            with self.stopuhr(f\"{tile.id=}: Downloading one new tile in blocking mode\"):\n                logger.debug(f\"{tile.id=}: Start downloading\")\n                tiledata = self.download_tile(tile)\n\n            # Try to write the data to file until a limit is reached\n            limit = 100\n            for i in range(limit):\n                try:\n                    self._write_tile_to_zarr(tiledata, tile)\n                    break\n                except icechunk.ConflictError as conflict_error:\n                    logger.debug(f\"{tile.id=}: {conflict_error=} at retry {i}/{limit}\")\n            else:\n                logger.error(\n                    f\"{tile.id=}: {limit} tries to write the tile failed. \"\n                    \"Please check if the datacube is already created and not empty.\"\n                )\n                raise ValueError(f\"{tile.id=}: {limit} tries to write the tile failed.\")\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.procedural_download_blocking(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.procedural_download_threading","title":"procedural_download_threading","text":"<pre><code>procedural_download_threading(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in threading mode.</p> Note <p>This method ensures that only a single download is running at a time. It uses a SetQueue to prevent duplicate downloads. The threading mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>RuntimeError</code>             \u2013            <p>If the Python version is lower than 3.13.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_threading(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in threading mode.\n\n    Note:\n        This method ensures that only a single download is running at a time.\n        It uses a SetQueue to prevent duplicate downloads.\n        The threading mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        RuntimeError: If the Python version is lower than 3.13.\n\n    \"\"\"\n    if not _check_python_version(3, 13):\n        raise RuntimeError(\"Threading mode requires Python 3.13 or higher\")\n    with self._threading_handler:\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        # Wait until all new_items are loaded\n        prev_len = None\n        while True:\n            session = self.repo.readonly_session(\"main\")\n            zcube = zarr.open(store=session.store, mode=\"r\")\n            loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n            new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n            done_tiles = [tile for tile in adjacent_tiles if tile.id in loaded_tiles]\n            if not new_tiles:\n                break\n            if prev_len != len(new_tiles):\n                logger.debug(\n                    f\"{_geobox_repr(geobox)}: {len(done_tiles)} of {len(adjacent_tiles)} downloaded.\"\n                    f\" Missing: {[t.id for t in new_tiles]} Done: {[t.id for t in done_tiles]}\"\n                )\n            for tile in new_tiles:\n                self._threading_handler._queue.put(tile)\n            prev_len = len(new_tiles)\n            time.sleep(5)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.procedural_download_threading(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.visualize_state","title":"visualize_state  <code>abstractmethod</code>","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize currently stored tiles / chunk.</p> <p>Must be implemented by the DatasetAccessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>@abstractmethod\ndef visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize currently stored tiles / chunk.\n\n    Must be implemented by the DatasetAccessor.\n\n    Args:\n        ax (plt.Axes | None, optional): The axes drawn to. If None, will create a new figure and axes.\n            Defaults to None.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization\n\n    \"\"\"\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/#smart_geocubes.accessors.STACAccessor.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes. Defaults to None.</p>"},{"location":"reference/smart_geocubes/accessors/base/","title":"smart_geocubes.accessors.base","text":""},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base","title":"smart_geocubes.accessors.base","text":"<p>Base class for remote accessors.</p> <p>Classes:</p> <ul> <li> <code>LoadParams</code>           \u2013            <p>TypedDict for the load function parameters.</p> </li> <li> <code>RemoteAccessor</code>           \u2013            <p>Base class for remote accessors.</p> </li> <li> <code>TileWrapper</code>           \u2013            <p>Wrapper for a tile with an id.</p> </li> </ul>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.LoadParams","title":"LoadParams","text":"<p>               Bases: <code>TypedDict</code></p> <p>TypedDict for the load function parameters.</p>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor","title":"RemoteAccessor","text":"<pre><code>RemoteAccessor(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Base class for remote accessors.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the underlaying zarr array. Should be equal to the extent geobox. However, this property is used to find the target index of the downloaded data, so better save than sorry.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_tiles</code>             \u2013              <p>Get the adjacent tiles for the given geobox.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles / chunk.</p> </li> <li> <code>download_tile</code>             \u2013              <p>Download the data for the given tile.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Post create actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download the data for the given geobox.</p> </li> <li> <code>procedural_download_blocking</code>             \u2013              <p>Download tiles procedurally in blocking mode.</p> </li> <li> <code>procedural_download_threading</code>             \u2013              <p>Download tiles procedurally in threading mode.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize currently stored tiles / chunk.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = StopUhr(logger.debug)\n\n    # The TypeVar used by the ThreadingHandler was added in 3.12\n    # The Shutdown method of the queue was added in 3.13\n    # Hence, we don't want to import the module unless Python 3.13 is installed\n    if _check_python_version(3, 13):\n        from smart_geocubes._concurrency.threading import ThreadingHandler\n\n        self._threading_handler = ThreadingHandler(self._threading_download)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.adjacent_tiles","title":"adjacent_tiles  <code>abstractmethod</code>","text":"<pre><code>adjacent_tiles(geobox: GeoBox) -&gt; list[TileWrapper]\n</code></pre> <p>Get the adjacent tiles for the given geobox.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[TileWrapper]</code>           \u2013            <p>list[TileWrapper]: The adjacent tile(-id)s for the given geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>@abstractmethod\ndef adjacent_tiles(self, geobox: GeoBox) -&gt; list[TileWrapper]:\n    \"\"\"Get the adjacent tiles for the given geobox.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        geobox (GeoBox): The reference geobox to get the adjacent tiles for.\n\n    Returns:\n        list[TileWrapper]: The adjacent tile(-id)s for the given geobox.\n\n    \"\"\"\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.adjacent_tiles(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to get the adjacent tiles for.</p>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> <p>Raises:</p> <ul> <li> <code>FileNotFoundError</code>             \u2013            <p>If the datacube does not exist.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\n\n    Raises:\n        FileNotFoundError: If the datacube does not exist.\n\n    \"\"\"\n    if not self.created:\n        msg = f\"Datacube {self.title} does not exist.\"\n        \" Please use the `create` method or pass `create=True` to `load`.\"\n        logger.error(msg)\n        raise FileNotFoundError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.create","title":"create","text":"<pre><code>create(overwrite: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def create(self, overwrite: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube. Defaults to False.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location\n\n    \"\"\"\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        var_encoding = {\n            name: {\n                \"chunks\": (self.chunk_size, self.chunk_size),\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Defaults to False.</p>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.current_state","title":"current_state  <code>abstractmethod</code>","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles / chunk.</p> <p>Must be implemented by the Accessor.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame | None: Tile or Chunk info.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>@abstractmethod\ndef current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles / chunk.\n\n    Must be implemented by the Accessor.\n\n    Returns:\n        gpd.GeoDataFrame | None: Tile or Chunk info.\n\n    \"\"\"\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.download_tile","title":"download_tile  <code>abstractmethod</code>","text":"<pre><code>download_tile(tile: TileWrapper) -&gt; xr.Dataset\n</code></pre> <p>Download the data for the given tile.</p> <p>Must be implemented by the Accessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded tile data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>@abstractmethod\ndef download_tile(self, tile: TileWrapper) -&gt; xr.Dataset:\n    \"\"\"Download the data for the given tile.\n\n    Must be implemented by the Accessor.\n\n    Args:\n        tile (TileWrapper): The reference tile to download the data for.\n\n    Returns:\n        xr.Dataset: The downloaded tile data.\n\n    \"\"\"\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.download_tile(tile)","title":"<code>tile</code>","text":"(<code>TileWrapper</code>)           \u2013            <p>The reference tile to download the data for.</p>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.load","title":"load","text":"<pre><code>load(\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load(\n    self,\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        geobox (GeoBox): The reference geobox to load the data for.\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        logger.debug(f\"{_geobox_repr(geobox)}: {geobox.resolution} original resolution\")\n\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        reference_geobox = geobox.to_crs(self.extent.crs, resolution=self.extent.resolution.x).pad(buffer)\n        self.procedural_download(reference_geobox, concurrency_mode=concurrency_mode)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(reference_geobox.extent, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.load(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to load the data for.</p>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.load(buffer)","title":"<code>buffer</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.load(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> <li> <code>concurrency_mode</code>               (<code>ConcurrencyModes</code>)           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    return self.load(_geobox_repr(ref.geobox), **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    xcube = xr.open_zarr(session.store, mask_and_scale=False, consolidated=False).set_coords(\"spatial_ref\")\n    return xcube\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Post create actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def post_create(self):\n    \"\"\"Post create actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(\n    geobox: GeoBox,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n)\n</code></pre> <p>Download the data for the given geobox.</p> Note <p>The \"threading\" concurrency mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If an unknown concurrency mode is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download(self, geobox: GeoBox, concurrency_mode: ConcurrencyModes = \"blocking\"):\n    \"\"\"Download the data for the given geobox.\n\n    Note:\n        The \"threading\" concurrency mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The reference geobox to download the data for.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Raises:\n        ValueError: If an unknown concurrency mode is provided.\n\n    \"\"\"\n    self.assert_created()\n    if concurrency_mode == \"blocking\":\n        self.procedural_download_blocking(geobox)\n    elif concurrency_mode == \"threading\":\n        self.procedural_download_threading(geobox)\n    else:\n        raise ValueError(f\"Unknown concurrency mode {concurrency_mode}\")\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.procedural_download(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to download the data for.</p>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.procedural_download(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.procedural_download_blocking","title":"procedural_download_blocking","text":"<pre><code>procedural_download_blocking(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in blocking mode.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If no tries are left.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_blocking(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in blocking mode.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If no tries are left.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: Procedural download in blocking mode\"):\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        session = self.repo.readonly_session(\"main\")\n        zcube = zarr.open(store=session.store, mode=\"r\")\n        loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n        new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n        logger.debug(\n            f\"{_geobox_repr(geobox)}:  {len(adjacent_tiles)=} &amp; {len(loaded_tiles)=}\"\n            f\" -&gt; {len(new_tiles)=} to download\"\n        )\n        if not new_tiles:\n            return\n\n        for tile in new_tiles:\n            with self.stopuhr(f\"{tile.id=}: Downloading one new tile in blocking mode\"):\n                logger.debug(f\"{tile.id=}: Start downloading\")\n                tiledata = self.download_tile(tile)\n\n            # Try to write the data to file until a limit is reached\n            limit = 100\n            for i in range(limit):\n                try:\n                    self._write_tile_to_zarr(tiledata, tile)\n                    break\n                except icechunk.ConflictError as conflict_error:\n                    logger.debug(f\"{tile.id=}: {conflict_error=} at retry {i}/{limit}\")\n            else:\n                logger.error(\n                    f\"{tile.id=}: {limit} tries to write the tile failed. \"\n                    \"Please check if the datacube is already created and not empty.\"\n                )\n                raise ValueError(f\"{tile.id=}: {limit} tries to write the tile failed.\")\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.procedural_download_blocking(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.procedural_download_threading","title":"procedural_download_threading","text":"<pre><code>procedural_download_threading(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in threading mode.</p> Note <p>This method ensures that only a single download is running at a time. It uses a SetQueue to prevent duplicate downloads. The threading mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>RuntimeError</code>             \u2013            <p>If the Python version is lower than 3.13.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_threading(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in threading mode.\n\n    Note:\n        This method ensures that only a single download is running at a time.\n        It uses a SetQueue to prevent duplicate downloads.\n        The threading mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        RuntimeError: If the Python version is lower than 3.13.\n\n    \"\"\"\n    if not _check_python_version(3, 13):\n        raise RuntimeError(\"Threading mode requires Python 3.13 or higher\")\n    with self._threading_handler:\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        # Wait until all new_items are loaded\n        prev_len = None\n        while True:\n            session = self.repo.readonly_session(\"main\")\n            zcube = zarr.open(store=session.store, mode=\"r\")\n            loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n            new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n            done_tiles = [tile for tile in adjacent_tiles if tile.id in loaded_tiles]\n            if not new_tiles:\n                break\n            if prev_len != len(new_tiles):\n                logger.debug(\n                    f\"{_geobox_repr(geobox)}: {len(done_tiles)} of {len(adjacent_tiles)} downloaded.\"\n                    f\" Missing: {[t.id for t in new_tiles]} Done: {[t.id for t in done_tiles]}\"\n                )\n            for tile in new_tiles:\n                self._threading_handler._queue.put(tile)\n            prev_len = len(new_tiles)\n            time.sleep(5)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.procedural_download_threading(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.visualize_state","title":"visualize_state  <code>abstractmethod</code>","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize currently stored tiles / chunk.</p> <p>Must be implemented by the DatasetAccessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>@abstractmethod\ndef visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize currently stored tiles / chunk.\n\n    Must be implemented by the DatasetAccessor.\n\n    Args:\n        ax (plt.Axes | None, optional): The axes drawn to. If None, will create a new figure and axes.\n            Defaults to None.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization\n\n    \"\"\"\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.RemoteAccessor.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes. Defaults to None.</p>"},{"location":"reference/smart_geocubes/accessors/base/#smart_geocubes.accessors.base.TileWrapper","title":"TileWrapper","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Wrapper for a tile with an id.</p>"},{"location":"reference/smart_geocubes/accessors/gee/","title":"smart_geocubes.accessors.gee","text":""},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee","title":"smart_geocubes.accessors.gee","text":"<p>Google Earth Engine Accessor for Smart Geocubes.</p> <p>Classes:</p> <ul> <li> <code>GEEAccessor</code>           \u2013            <p>Accessor for Google Earth Engine data.</p> </li> </ul>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor","title":"GEEAccessor","text":"<pre><code>GEEAccessor(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n)\n</code></pre> <p>               Bases: <code>RemoteAccessor</code></p> <p>Accessor for Google Earth Engine data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the underlaying zarr array. Should be equal to the extent geobox. However, this property is used to find the target index of the downloaded data, so better save than sorry.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_tiles</code>             \u2013              <p>Get adjacent tiles from Google Earth Engine.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_tile</code>             \u2013              <p>Download a tile from Google Earth Engine.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Post create actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download the data for the given geobox.</p> </li> <li> <code>procedural_download_blocking</code>             \u2013              <p>Download tiles procedurally in blocking mode.</p> </li> <li> <code>procedural_download_threading</code>             \u2013              <p>Download tiles procedurally in threading mode.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize currently stored tiles / chunk.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = StopUhr(logger.debug)\n\n    # The TypeVar used by the ThreadingHandler was added in 3.12\n    # The Shutdown method of the queue was added in 3.13\n    # Hence, we don't want to import the module unless Python 3.13 is installed\n    if _check_python_version(3, 13):\n        from smart_geocubes._concurrency.threading import ThreadingHandler\n\n        self._threading_handler = ThreadingHandler(self._threading_download)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.adjacent_tiles","title":"adjacent_tiles","text":"<pre><code>adjacent_tiles(geobox: GeoBox) -&gt; list[TileWrapper]\n</code></pre> <p>Get adjacent tiles from Google Earth Engine.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[TileWrapper]</code>           \u2013            <p>list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def adjacent_tiles(self, geobox: GeoBox) -&gt; list[TileWrapper]:\n    \"\"\"Get adjacent tiles from Google Earth Engine.\n\n    Args:\n        geobox (GeoBox): The geobox for which to get adjacent tiles.\n\n    Returns:\n        list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.\n\n    \"\"\"\n    extent_tiles = GeoboxTiles(self.extent, (self.chunk_size, self.chunk_size))\n    return [TileWrapper(_tileidx_to_id(idx), extent_tiles[idx]) for idx in extent_tiles.tiles(geobox.extent)]\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.adjacent_tiles(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox for which to get adjacent tiles.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> <p>Raises:</p> <ul> <li> <code>FileNotFoundError</code>             \u2013            <p>If the datacube does not exist.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\n\n    Raises:\n        FileNotFoundError: If the datacube does not exist.\n\n    \"\"\"\n    if not self.created:\n        msg = f\"Datacube {self.title} does not exist.\"\n        \" Please use the `create` method or pass `create=True` to `load`.\"\n        logger.error(msg)\n        raise FileNotFoundError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.create","title":"create","text":"<pre><code>create(overwrite: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def create(self, overwrite: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube. Defaults to False.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location\n\n    \"\"\"\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        var_encoding = {\n            name: {\n                \"chunks\": (self.chunk_size, self.chunk_size),\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Defaults to False.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.\n\n    \"\"\"\n    import geopandas as gpd\n\n    if not self.created:\n        return None\n\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(session.store, mode=\"r\")\n    loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n\n    if len(loaded_tiles) == 0:\n        return None\n\n    tiles = GeoboxTiles(self.extent, (self.chunk_size, self.chunk_size))\n    loaded_tiles = [{\"geometry\": tiles[_id_to_tileidx(tid)].extent.geom, \"id\": tid} for tid in loaded_tiles]\n    gdf = gpd.GeoDataFrame(loaded_tiles, crs=self.extent.crs.to_wkt())\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.download_tile","title":"download_tile","text":"<pre><code>download_tile(\n    zcube: Group, tile: TileWrapper\n) -&gt; xr.Dataset\n</code></pre> <p>Download a tile from Google Earth Engine.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded tile data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def download_tile(self, zcube: zarr.Group, tile: TileWrapper) -&gt; xr.Dataset:\n    \"\"\"Download a tile from Google Earth Engine.\n\n    Args:\n        zcube (zarr.Group): The zarr datacube to download the tile to.\n        tile (TileWrapper): The tile to download.\n\n    Returns:\n        xr.Dataset: The downloaded tile data.\n\n    \"\"\"\n    import ee\n    import rioxarray  # noqa: F401\n    import xee  # noqa: F401\n\n    # Note: This is a little bit weird: First we create an own grid which overlaps to the chunks\n    # of the zarr array. Then we create a mosaic of the data and clip it to a single chunk.\n    # We could load the images from the collection directly instead of creating a mosaic.\n    # However, this would require more testing and probably results a lot of manual computation\n    # of slices etc. like in the stac variant. So for now, we just use the mosaic.\n    logging.getLogger(\"urllib3.connectionpool\").disabled = True\n    geom = ee.Geometry.Rectangle(tile.item.geographic_extent.boundingbox)\n    ee_img = ee.ImageCollection(self.collection).mosaic().clip(geom)\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=UserWarning, message=EE_WARN_MSG)\n        tiledata = xr.open_dataset(\n            ee_img,\n            engine=\"ee\",\n            geometry=geom,\n            crs=f\"epsg:{self.extent.crs.to_epsg()}\",\n            scale=self.extent.resolution.x,\n        )\n\n    # TODO: Allow for multi-temporal datacubes and lat/lon coordinates\n    tiledata = tiledata.max(\"time\").rename({\"lon\": \"x\", \"lat\": \"y\"}).transpose(\"y\", \"x\")\n\n    # Download the data\n    tiledata.load()\n    logging.getLogger(\"urllib3.connectionpool\").disabled = False\n\n    # Flip y-axis, because convention is x in positive direction and y in negative, but gee use positive for both\n    tiledata = tiledata.isel(y=slice(None, None, -1))\n\n    # For some reason xee does not always set the crs\n    tiledata = tiledata.odc.assign_crs(self.extent.crs)\n\n    # Recrop the data to the tile, since gee does not always return the exact extent\n    tiledata = tiledata.odc.crop(tile.item.extent)\n\n    # Save original min-max values for each band for clipping later\n    clip_values = {\n        band: (tiledata[band].min().values.item(), tiledata[band].max().values.item())\n        for band in tiledata.data_vars\n    }\n\n    # Interpolate missing values (there are very few, so we actually can interpolate them)\n    tiledata.rio.set_spatial_dims(x_dim=\"x\", y_dim=\"y\", inplace=True)\n    for band in tiledata.data_vars:\n        tiledata[band] = tiledata[band].rio.write_nodata(np.nan).rio.interpolate_na()\n\n    # Convert to uint8\n    for band in tiledata.data_vars:\n        band_min, band_max = clip_values[band]\n        tiledata[band] = (\n            tiledata[band].clip(band_min, band_max, keep_attrs=True).astype(\"uint8\").rio.write_nodata(None)\n        )\n\n    return tiledata\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.download_tile(zcube)","title":"<code>zcube</code>","text":"(<code>Group</code>)           \u2013            <p>The zarr datacube to download the tile to.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.download_tile(tile)","title":"<code>tile</code>","text":"(<code>TileWrapper</code>)           \u2013            <p>The tile to download.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.load","title":"load","text":"<pre><code>load(\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load(\n    self,\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        geobox (GeoBox): The reference geobox to load the data for.\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        logger.debug(f\"{_geobox_repr(geobox)}: {geobox.resolution} original resolution\")\n\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        reference_geobox = geobox.to_crs(self.extent.crs, resolution=self.extent.resolution.x).pad(buffer)\n        self.procedural_download(reference_geobox, concurrency_mode=concurrency_mode)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(reference_geobox.extent, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.load(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to load the data for.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.load(buffer)","title":"<code>buffer</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.load(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> <li> <code>concurrency_mode</code>               (<code>ConcurrencyModes</code>)           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    return self.load(_geobox_repr(ref.geobox), **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    xcube = xr.open_zarr(session.store, mask_and_scale=False, consolidated=False).set_coords(\"spatial_ref\")\n    return xcube\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Post create actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def post_create(self):\n    \"\"\"Post create actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(\n    geobox: GeoBox,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n)\n</code></pre> <p>Download the data for the given geobox.</p> Note <p>The \"threading\" concurrency mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If an unknown concurrency mode is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download(self, geobox: GeoBox, concurrency_mode: ConcurrencyModes = \"blocking\"):\n    \"\"\"Download the data for the given geobox.\n\n    Note:\n        The \"threading\" concurrency mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The reference geobox to download the data for.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Raises:\n        ValueError: If an unknown concurrency mode is provided.\n\n    \"\"\"\n    self.assert_created()\n    if concurrency_mode == \"blocking\":\n        self.procedural_download_blocking(geobox)\n    elif concurrency_mode == \"threading\":\n        self.procedural_download_threading(geobox)\n    else:\n        raise ValueError(f\"Unknown concurrency mode {concurrency_mode}\")\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.procedural_download(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to download the data for.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.procedural_download(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.procedural_download_blocking","title":"procedural_download_blocking","text":"<pre><code>procedural_download_blocking(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in blocking mode.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If no tries are left.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_blocking(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in blocking mode.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If no tries are left.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: Procedural download in blocking mode\"):\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        session = self.repo.readonly_session(\"main\")\n        zcube = zarr.open(store=session.store, mode=\"r\")\n        loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n        new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n        logger.debug(\n            f\"{_geobox_repr(geobox)}:  {len(adjacent_tiles)=} &amp; {len(loaded_tiles)=}\"\n            f\" -&gt; {len(new_tiles)=} to download\"\n        )\n        if not new_tiles:\n            return\n\n        for tile in new_tiles:\n            with self.stopuhr(f\"{tile.id=}: Downloading one new tile in blocking mode\"):\n                logger.debug(f\"{tile.id=}: Start downloading\")\n                tiledata = self.download_tile(tile)\n\n            # Try to write the data to file until a limit is reached\n            limit = 100\n            for i in range(limit):\n                try:\n                    self._write_tile_to_zarr(tiledata, tile)\n                    break\n                except icechunk.ConflictError as conflict_error:\n                    logger.debug(f\"{tile.id=}: {conflict_error=} at retry {i}/{limit}\")\n            else:\n                logger.error(\n                    f\"{tile.id=}: {limit} tries to write the tile failed. \"\n                    \"Please check if the datacube is already created and not empty.\"\n                )\n                raise ValueError(f\"{tile.id=}: {limit} tries to write the tile failed.\")\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.procedural_download_blocking(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.procedural_download_threading","title":"procedural_download_threading","text":"<pre><code>procedural_download_threading(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in threading mode.</p> Note <p>This method ensures that only a single download is running at a time. It uses a SetQueue to prevent duplicate downloads. The threading mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>RuntimeError</code>             \u2013            <p>If the Python version is lower than 3.13.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_threading(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in threading mode.\n\n    Note:\n        This method ensures that only a single download is running at a time.\n        It uses a SetQueue to prevent duplicate downloads.\n        The threading mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        RuntimeError: If the Python version is lower than 3.13.\n\n    \"\"\"\n    if not _check_python_version(3, 13):\n        raise RuntimeError(\"Threading mode requires Python 3.13 or higher\")\n    with self._threading_handler:\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        # Wait until all new_items are loaded\n        prev_len = None\n        while True:\n            session = self.repo.readonly_session(\"main\")\n            zcube = zarr.open(store=session.store, mode=\"r\")\n            loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n            new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n            done_tiles = [tile for tile in adjacent_tiles if tile.id in loaded_tiles]\n            if not new_tiles:\n                break\n            if prev_len != len(new_tiles):\n                logger.debug(\n                    f\"{_geobox_repr(geobox)}: {len(done_tiles)} of {len(adjacent_tiles)} downloaded.\"\n                    f\" Missing: {[t.id for t in new_tiles]} Done: {[t.id for t in done_tiles]}\"\n                )\n            for tile in new_tiles:\n                self._threading_handler._queue.put(tile)\n            prev_len = len(new_tiles)\n            time.sleep(5)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.procedural_download_threading(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.visualize_state","title":"visualize_state  <code>abstractmethod</code>","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize currently stored tiles / chunk.</p> <p>Must be implemented by the DatasetAccessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>@abstractmethod\ndef visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize currently stored tiles / chunk.\n\n    Must be implemented by the DatasetAccessor.\n\n    Args:\n        ax (plt.Axes | None, optional): The axes drawn to. If None, will create a new figure and axes.\n            Defaults to None.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization\n\n    \"\"\"\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/gee/#smart_geocubes.accessors.gee.GEEAccessor.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes. Defaults to None.</p>"},{"location":"reference/smart_geocubes/accessors/stac/","title":"smart_geocubes.accessors.stac","text":""},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac","title":"smart_geocubes.accessors.stac","text":"<p>STAC Accessor for Smart Geocubes.</p> <p>Classes:</p> <ul> <li> <code>STACAccessor</code>           \u2013            <p>Accessor for STAC data.</p> </li> </ul> <p>Functions:</p> <ul> <li> <code>correct_bounds</code>             \u2013              <p>Correct the bounds of a tile to fit within a GeoBox.</p> </li> </ul>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor","title":"STACAccessor","text":"<pre><code>STACAccessor(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n)\n</code></pre> <p>               Bases: <code>RemoteAccessor</code></p> <p>Accessor for STAC data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the underlaying zarr array. Should be equal to the extent geobox. However, this property is used to find the target index of the downloaded data, so better save than sorry.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_tiles</code>             \u2013              <p>Get adjacent tiles from a STAC API.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_tile</code>             \u2013              <p>Download a tile from a STAC API and write it to a zarr datacube.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Post create actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download the data for the given geobox.</p> </li> <li> <code>procedural_download_blocking</code>             \u2013              <p>Download tiles procedurally in blocking mode.</p> </li> <li> <code>procedural_download_threading</code>             \u2013              <p>Download tiles procedurally in threading mode.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize currently stored tiles / chunk.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = StopUhr(logger.debug)\n\n    # The TypeVar used by the ThreadingHandler was added in 3.12\n    # The Shutdown method of the queue was added in 3.13\n    # Hence, we don't want to import the module unless Python 3.13 is installed\n    if _check_python_version(3, 13):\n        from smart_geocubes._concurrency.threading import ThreadingHandler\n\n        self._threading_handler = ThreadingHandler(self._threading_download)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.adjacent_tiles","title":"adjacent_tiles","text":"<pre><code>adjacent_tiles(geobox: GeoBox) -&gt; list[TileWrapper]\n</code></pre> <p>Get adjacent tiles from a STAC API.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[TileWrapper]</code>           \u2013            <p>list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def adjacent_tiles(self, geobox: GeoBox) -&gt; list[TileWrapper]:\n    \"\"\"Get adjacent tiles from a STAC API.\n\n    Args:\n        geobox (GeoBox): The geobox for which to get adjacent tiles.\n\n    Returns:\n        list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.\n\n    \"\"\"\n    import pystac_client\n\n    catalog = pystac_client.Client.open(self.stac_api_url)\n    search = catalog.search(collections=[self.collection], intersects=geobox.to_crs(\"EPSG:4326\").extent.geom)\n    items = list(search.items())\n    return [TileWrapper(item.id, item) for item in items]\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.adjacent_tiles(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox for which to get adjacent tiles.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> <p>Raises:</p> <ul> <li> <code>FileNotFoundError</code>             \u2013            <p>If the datacube does not exist.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\n\n    Raises:\n        FileNotFoundError: If the datacube does not exist.\n\n    \"\"\"\n    if not self.created:\n        msg = f\"Datacube {self.title} does not exist.\"\n        \" Please use the `create` method or pass `create=True` to `load`.\"\n        logger.error(msg)\n        raise FileNotFoundError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.create","title":"create","text":"<pre><code>create(overwrite: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def create(self, overwrite: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube. Defaults to False.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location\n\n    \"\"\"\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        var_encoding = {\n            name: {\n                \"chunks\": (self.chunk_size, self.chunk_size),\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Defaults to False.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.\n\n\n    \"\"\"\n    import geopandas as gpd\n    import pystac_client\n\n    if not self.created:\n        return None\n\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(session.store, mode=\"r\")\n    loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n\n    if len(loaded_tiles) == 0:\n        return None\n\n    catalog = pystac_client.Client.open(self.stac_api_url)\n    search = catalog.search(collections=[self.collection], ids=loaded_tiles)\n    stac_json = search.item_collection_as_dict()\n\n    gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.download_tile","title":"download_tile","text":"<pre><code>download_tile(tile: TileWrapper) -&gt; xr.Dataset\n</code></pre> <p>Download a tile from a STAC API and write it to a zarr datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded tile data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def download_tile(self, tile: TileWrapper) -&gt; xr.Dataset:\n    \"\"\"Download a tile from a STAC API and write it to a zarr datacube.\n\n    Args:\n        tile (TileWrapper): The tile to download and write.\n\n    Returns:\n        xr.Dataset: The downloaded tile data.\n\n    \"\"\"\n    from odc.stac import stac_load\n\n    tiledata = stac_load([tile.item], bands=self.channels, chunks=None, progress=None)\n\n    # TODO: Allow for multi-temporal datacubes\n    tiledata = tiledata.max(\"time\")\n\n    return tiledata\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.download_tile(tile)","title":"<code>tile</code>","text":"(<code>TileWrapper</code>)           \u2013            <p>The tile to download and write.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.load","title":"load","text":"<pre><code>load(\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load(\n    self,\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        geobox (GeoBox): The reference geobox to load the data for.\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        logger.debug(f\"{_geobox_repr(geobox)}: {geobox.resolution} original resolution\")\n\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        reference_geobox = geobox.to_crs(self.extent.crs, resolution=self.extent.resolution.x).pad(buffer)\n        self.procedural_download(reference_geobox, concurrency_mode=concurrency_mode)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(reference_geobox.extent, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.load(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to load the data for.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.load(buffer)","title":"<code>buffer</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.load(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> <li> <code>concurrency_mode</code>               (<code>ConcurrencyModes</code>)           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    return self.load(_geobox_repr(ref.geobox), **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    xcube = xr.open_zarr(session.store, mask_and_scale=False, consolidated=False).set_coords(\"spatial_ref\")\n    return xcube\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Post create actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def post_create(self):\n    \"\"\"Post create actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(\n    geobox: GeoBox,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n)\n</code></pre> <p>Download the data for the given geobox.</p> Note <p>The \"threading\" concurrency mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If an unknown concurrency mode is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download(self, geobox: GeoBox, concurrency_mode: ConcurrencyModes = \"blocking\"):\n    \"\"\"Download the data for the given geobox.\n\n    Note:\n        The \"threading\" concurrency mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The reference geobox to download the data for.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Raises:\n        ValueError: If an unknown concurrency mode is provided.\n\n    \"\"\"\n    self.assert_created()\n    if concurrency_mode == \"blocking\":\n        self.procedural_download_blocking(geobox)\n    elif concurrency_mode == \"threading\":\n        self.procedural_download_threading(geobox)\n    else:\n        raise ValueError(f\"Unknown concurrency mode {concurrency_mode}\")\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.procedural_download(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to download the data for.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.procedural_download(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.procedural_download_blocking","title":"procedural_download_blocking","text":"<pre><code>procedural_download_blocking(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in blocking mode.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If no tries are left.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_blocking(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in blocking mode.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If no tries are left.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: Procedural download in blocking mode\"):\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        session = self.repo.readonly_session(\"main\")\n        zcube = zarr.open(store=session.store, mode=\"r\")\n        loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n        new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n        logger.debug(\n            f\"{_geobox_repr(geobox)}:  {len(adjacent_tiles)=} &amp; {len(loaded_tiles)=}\"\n            f\" -&gt; {len(new_tiles)=} to download\"\n        )\n        if not new_tiles:\n            return\n\n        for tile in new_tiles:\n            with self.stopuhr(f\"{tile.id=}: Downloading one new tile in blocking mode\"):\n                logger.debug(f\"{tile.id=}: Start downloading\")\n                tiledata = self.download_tile(tile)\n\n            # Try to write the data to file until a limit is reached\n            limit = 100\n            for i in range(limit):\n                try:\n                    self._write_tile_to_zarr(tiledata, tile)\n                    break\n                except icechunk.ConflictError as conflict_error:\n                    logger.debug(f\"{tile.id=}: {conflict_error=} at retry {i}/{limit}\")\n            else:\n                logger.error(\n                    f\"{tile.id=}: {limit} tries to write the tile failed. \"\n                    \"Please check if the datacube is already created and not empty.\"\n                )\n                raise ValueError(f\"{tile.id=}: {limit} tries to write the tile failed.\")\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.procedural_download_blocking(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.procedural_download_threading","title":"procedural_download_threading","text":"<pre><code>procedural_download_threading(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in threading mode.</p> Note <p>This method ensures that only a single download is running at a time. It uses a SetQueue to prevent duplicate downloads. The threading mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>RuntimeError</code>             \u2013            <p>If the Python version is lower than 3.13.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_threading(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in threading mode.\n\n    Note:\n        This method ensures that only a single download is running at a time.\n        It uses a SetQueue to prevent duplicate downloads.\n        The threading mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        RuntimeError: If the Python version is lower than 3.13.\n\n    \"\"\"\n    if not _check_python_version(3, 13):\n        raise RuntimeError(\"Threading mode requires Python 3.13 or higher\")\n    with self._threading_handler:\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        # Wait until all new_items are loaded\n        prev_len = None\n        while True:\n            session = self.repo.readonly_session(\"main\")\n            zcube = zarr.open(store=session.store, mode=\"r\")\n            loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n            new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n            done_tiles = [tile for tile in adjacent_tiles if tile.id in loaded_tiles]\n            if not new_tiles:\n                break\n            if prev_len != len(new_tiles):\n                logger.debug(\n                    f\"{_geobox_repr(geobox)}: {len(done_tiles)} of {len(adjacent_tiles)} downloaded.\"\n                    f\" Missing: {[t.id for t in new_tiles]} Done: {[t.id for t in done_tiles]}\"\n                )\n            for tile in new_tiles:\n                self._threading_handler._queue.put(tile)\n            prev_len = len(new_tiles)\n            time.sleep(5)\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.procedural_download_threading(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.visualize_state","title":"visualize_state  <code>abstractmethod</code>","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize currently stored tiles / chunk.</p> <p>Must be implemented by the DatasetAccessor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>@abstractmethod\ndef visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize currently stored tiles / chunk.\n\n    Must be implemented by the DatasetAccessor.\n\n    Args:\n        ax (plt.Axes | None, optional): The axes drawn to. If None, will create a new figure and axes.\n            Defaults to None.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization\n\n    \"\"\"\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.STACAccessor.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes. Defaults to None.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.correct_bounds","title":"correct_bounds","text":"<pre><code>correct_bounds(\n    tile: Dataset, zgeobox: GeoBox\n) -&gt; xr.Dataset\n</code></pre> <p>Correct the bounds of a tile to fit within a GeoBox.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the tile is out of the geobox's bounds.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The corrected tile.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def correct_bounds(tile: xr.Dataset, zgeobox: GeoBox) -&gt; xr.Dataset:\n    \"\"\"Correct the bounds of a tile to fit within a GeoBox.\n\n    Args:\n        tile (xr.Dataset): The tile to correct.\n        zgeobox (GeoBox): The GeoBox to correct the tile to.\n\n    Raises:\n        ValueError: If the tile is out of the geobox's bounds.\n\n    Returns:\n        xr.Dataset: The corrected tile.\n\n    \"\"\"\n    yslice, xslice = tile.odc.geobox.overlap_roi(zgeobox)\n    yslice_is_valid = yslice.start &gt;= 0 and yslice.start &lt; yslice.stop and yslice.stop &lt;= tile.sizes[\"y\"]\n    xslice_is_valid = xslice.start &gt;= 0 and xslice.start &lt; xslice.stop and xslice.stop &lt;= tile.sizes[\"x\"]\n    if not yslice_is_valid or not xslice_is_valid:\n        logger.error(f\"Tile is out of bounds! {yslice=} {xslice=} {tile.sizes=} {zgeobox=}\")\n        raise ValueError(\"Tile is out of bounds!\")\n    if yslice.start != 0 or xslice.start != 0 or yslice.stop != tile.sizes[\"y\"] or xslice.stop != tile.sizes[\"x\"]:\n        logger.warning(\n            f\"Correcting tile bounds. This is an indicator that the datacube extent is to narrow.\"\n            f\" This will crop the tile to fit the datacube. {yslice=} {xslice=} {tile.sizes=} {zgeobox=}\"\n        )\n        tile = tile.isel(x=xslice, y=yslice)\n    return tile\n</code></pre>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.correct_bounds(tile)","title":"<code>tile</code>","text":"(<code>Dataset</code>)           \u2013            <p>The tile to correct.</p>"},{"location":"reference/smart_geocubes/accessors/stac/#smart_geocubes.accessors.stac.correct_bounds(zgeobox)","title":"<code>zgeobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The GeoBox to correct the tile to.</p>"},{"location":"reference/smart_geocubes/datasets/","title":"smart_geocubes.datasets","text":""},{"location":"reference/smart_geocubes/datasets/#smart_geocubes.datasets","title":"smart_geocubes.datasets","text":"<p>Predefined datasets for the SmartGeocubes package.</p> <p>Modules:</p> <ul> <li> <code>arcticdem</code>           \u2013            <p>Predefined accessor for ArcticDEM 32m, 10m and 2m data.</p> </li> <li> <code>tctrend</code>           \u2013            <p>Predefined accessor for TCTrend data.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/arcticdem/","title":"smart_geocubes.datasets.arcticdem","text":""},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem","title":"smart_geocubes.datasets.arcticdem","text":"<p>Predefined accessor for ArcticDEM 32m, 10m and 2m data.</p> <p>Classes:</p> <ul> <li> <code>ArcticDEM10m</code>           \u2013            <p>Accessor for ArcticDEM 10m data.</p> </li> <li> <code>ArcticDEM2m</code>           \u2013            <p>Accessor for ArcticDEM 2m data.</p> </li> <li> <code>ArcticDEM32m</code>           \u2013            <p>Accessor for ArcticDEM 32m data.</p> </li> <li> <code>ArcticDEMABC</code>           \u2013            <p>ABC for Arcticdem data.</p> </li> <li> <code>LazyStacTileWrapper</code>           \u2013            <p>Lazy wrapper for a TileWrapper containing a STAC Item.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m","title":"ArcticDEM10m","text":"<pre><code>ArcticDEM10m(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n)\n</code></pre> <p>               Bases: <code>ArcticDEMABC</code></p> <p>Accessor for ArcticDEM 10m data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the underlaying zarr array. Should be equal to the extent geobox. However, this property is used to find the target index of the downloaded data, so better save than sorry.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_tiles</code>             \u2013              <p>Get adjacent tiles from a STAC API.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_tile</code>             \u2013              <p>Download a tile from a STAC API and write it to a zarr datacube.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download the data for the given geobox.</p> </li> <li> <code>procedural_download_blocking</code>             \u2013              <p>Download tiles procedurally in blocking mode.</p> </li> <li> <code>procedural_download_threading</code>             \u2013              <p>Download tiles procedurally in threading mode.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = StopUhr(logger.debug)\n\n    # The TypeVar used by the ThreadingHandler was added in 3.12\n    # The Shutdown method of the queue was added in 3.13\n    # Hence, we don't want to import the module unless Python 3.13 is installed\n    if _check_python_version(3, 13):\n        from smart_geocubes._concurrency.threading import ThreadingHandler\n\n        self._threading_handler = ThreadingHandler(self._threading_download)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.adjacent_tiles","title":"adjacent_tiles","text":"<pre><code>adjacent_tiles(geobox: GeoBox) -&gt; list[TileWrapper]\n</code></pre> <p>Get adjacent tiles from a STAC API.</p> <p>Overwrite the default implementation from the STAC accessor to use pre-downloaded extent files instead of querying the STAC API. This results in a faster loading time, but requires the extent files to be downloaded beforehand. This is done in the post_create step.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[TileWrapper]</code>           \u2013            <p>list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def adjacent_tiles(self, geobox: GeoBox) -&gt; list[TileWrapper]:\n    \"\"\"Get adjacent tiles from a STAC API.\n\n    Overwrite the default implementation from the STAC accessor\n    to use pre-downloaded extent files instead of querying the STAC API.\n    This results in a faster loading time, but requires the extent files to be downloaded beforehand.\n    This is done in the post_create step.\n\n    Args:\n        geobox (GeoBox): The geobox for which to get adjacent tiles.\n\n    Returns:\n        list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.\n\n    \"\"\"\n    # Assumes that the extent files are already present and the datacube is already created\n    self.assert_created()\n\n    resolution = int(self.extent.resolution.x)\n    extent_info = gpd.read_parquet(self._aux_dir / f\"ArcticDEM_Mosaic_Index_v4_1_{resolution}m.parquet\")\n    adjacent_tiles = extent_info.loc[extent_info.intersects(geobox.extent.geom)].copy()\n    if adjacent_tiles.empty:\n        return []\n    return [LazyStacTileWrapper(tile.dem_id, _get_stac_url(tile.dem_id)) for tile in adjacent_tiles.itertuples()]\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.adjacent_tiles(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox for which to get adjacent tiles.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> <p>Raises:</p> <ul> <li> <code>FileNotFoundError</code>             \u2013            <p>If the datacube does not exist.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\n\n    Raises:\n        FileNotFoundError: If the datacube does not exist.\n\n    \"\"\"\n    if not self.created:\n        msg = f\"Datacube {self.title} does not exist.\"\n        \" Please use the `create` method or pass `create=True` to `load`.\"\n        logger.error(msg)\n        raise FileNotFoundError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.create","title":"create","text":"<pre><code>create(overwrite: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def create(self, overwrite: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube. Defaults to False.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location\n\n    \"\"\"\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        var_encoding = {\n            name: {\n                \"chunks\": (self.chunk_size, self.chunk_size),\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.\n\n\n    \"\"\"\n    import geopandas as gpd\n    import pystac_client\n\n    if not self.created:\n        return None\n\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(session.store, mode=\"r\")\n    loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n\n    if len(loaded_tiles) == 0:\n        return None\n\n    catalog = pystac_client.Client.open(self.stac_api_url)\n    search = catalog.search(collections=[self.collection], ids=loaded_tiles)\n    stac_json = search.item_collection_as_dict()\n\n    gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.download_tile","title":"download_tile","text":"<pre><code>download_tile(tile: TileWrapper) -&gt; xr.Dataset\n</code></pre> <p>Download a tile from a STAC API and write it to a zarr datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded tile data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def download_tile(self, tile: TileWrapper) -&gt; xr.Dataset:\n    \"\"\"Download a tile from a STAC API and write it to a zarr datacube.\n\n    Args:\n        tile (TileWrapper): The tile to download and write.\n\n    Returns:\n        xr.Dataset: The downloaded tile data.\n\n    \"\"\"\n    from odc.stac import stac_load\n\n    tiledata = stac_load([tile.item], bands=self.channels, chunks=None, progress=None)\n\n    # TODO: Allow for multi-temporal datacubes\n    tiledata = tiledata.max(\"time\")\n\n    return tiledata\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.download_tile(tile)","title":"<code>tile</code>","text":"(<code>TileWrapper</code>)           \u2013            <p>The tile to download and write.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.load","title":"load","text":"<pre><code>load(\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load(\n    self,\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        geobox (GeoBox): The reference geobox to load the data for.\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        logger.debug(f\"{_geobox_repr(geobox)}: {geobox.resolution} original resolution\")\n\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        reference_geobox = geobox.to_crs(self.extent.crs, resolution=self.extent.resolution.x).pad(buffer)\n        self.procedural_download(reference_geobox, concurrency_mode=concurrency_mode)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(reference_geobox.extent, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.load(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to load the data for.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.load(buffer)","title":"<code>buffer</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.load(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> <li> <code>concurrency_mode</code>               (<code>ConcurrencyModes</code>)           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    return self.load(_geobox_repr(ref.geobox), **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    xcube = xr.open_zarr(session.store, mask_and_scale=False, consolidated=False).set_coords(\"spatial_ref\")\n    return xcube\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def post_create(self):\n    \"\"\"Download the ArcticDEM mosaic extent info and store it in the datacube.\"\"\"\n    _download_arcticdem_extent(self._aux_dir)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(\n    geobox: GeoBox,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n)\n</code></pre> <p>Download the data for the given geobox.</p> Note <p>The \"threading\" concurrency mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If an unknown concurrency mode is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download(self, geobox: GeoBox, concurrency_mode: ConcurrencyModes = \"blocking\"):\n    \"\"\"Download the data for the given geobox.\n\n    Note:\n        The \"threading\" concurrency mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The reference geobox to download the data for.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Raises:\n        ValueError: If an unknown concurrency mode is provided.\n\n    \"\"\"\n    self.assert_created()\n    if concurrency_mode == \"blocking\":\n        self.procedural_download_blocking(geobox)\n    elif concurrency_mode == \"threading\":\n        self.procedural_download_threading(geobox)\n    else:\n        raise ValueError(f\"Unknown concurrency mode {concurrency_mode}\")\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.procedural_download(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to download the data for.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.procedural_download(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.procedural_download_blocking","title":"procedural_download_blocking","text":"<pre><code>procedural_download_blocking(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in blocking mode.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If no tries are left.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_blocking(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in blocking mode.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If no tries are left.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: Procedural download in blocking mode\"):\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        session = self.repo.readonly_session(\"main\")\n        zcube = zarr.open(store=session.store, mode=\"r\")\n        loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n        new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n        logger.debug(\n            f\"{_geobox_repr(geobox)}:  {len(adjacent_tiles)=} &amp; {len(loaded_tiles)=}\"\n            f\" -&gt; {len(new_tiles)=} to download\"\n        )\n        if not new_tiles:\n            return\n\n        for tile in new_tiles:\n            with self.stopuhr(f\"{tile.id=}: Downloading one new tile in blocking mode\"):\n                logger.debug(f\"{tile.id=}: Start downloading\")\n                tiledata = self.download_tile(tile)\n\n            # Try to write the data to file until a limit is reached\n            limit = 100\n            for i in range(limit):\n                try:\n                    self._write_tile_to_zarr(tiledata, tile)\n                    break\n                except icechunk.ConflictError as conflict_error:\n                    logger.debug(f\"{tile.id=}: {conflict_error=} at retry {i}/{limit}\")\n            else:\n                logger.error(\n                    f\"{tile.id=}: {limit} tries to write the tile failed. \"\n                    \"Please check if the datacube is already created and not empty.\"\n                )\n                raise ValueError(f\"{tile.id=}: {limit} tries to write the tile failed.\")\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.procedural_download_blocking(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.procedural_download_threading","title":"procedural_download_threading","text":"<pre><code>procedural_download_threading(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in threading mode.</p> Note <p>This method ensures that only a single download is running at a time. It uses a SetQueue to prevent duplicate downloads. The threading mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>RuntimeError</code>             \u2013            <p>If the Python version is lower than 3.13.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_threading(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in threading mode.\n\n    Note:\n        This method ensures that only a single download is running at a time.\n        It uses a SetQueue to prevent duplicate downloads.\n        The threading mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        RuntimeError: If the Python version is lower than 3.13.\n\n    \"\"\"\n    if not _check_python_version(3, 13):\n        raise RuntimeError(\"Threading mode requires Python 3.13 or higher\")\n    with self._threading_handler:\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        # Wait until all new_items are loaded\n        prev_len = None\n        while True:\n            session = self.repo.readonly_session(\"main\")\n            zcube = zarr.open(store=session.store, mode=\"r\")\n            loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n            new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n            done_tiles = [tile for tile in adjacent_tiles if tile.id in loaded_tiles]\n            if not new_tiles:\n                break\n            if prev_len != len(new_tiles):\n                logger.debug(\n                    f\"{_geobox_repr(geobox)}: {len(done_tiles)} of {len(adjacent_tiles)} downloaded.\"\n                    f\" Missing: {[t.id for t in new_tiles]} Done: {[t.id for t in done_tiles]}\"\n                )\n            for tile in new_tiles:\n                self._threading_handler._queue.put(tile)\n            prev_len = len(new_tiles)\n            time.sleep(5)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.procedural_download_threading(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    import cartopy.crs as ccrs\n    import cartopy.feature as cfeature\n    import matplotlib.path as mpath\n    import matplotlib.pyplot as plt\n\n    tile_info = self.current_state()\n\n    if tile_info is None:\n        raise ValueError(\"Datacube is not created or loaded yet. Can't visualize!\")\n\n    # Define the projection\n    projection = ccrs.Stereographic(central_latitude=90, central_longitude=-45, true_scale_latitude=70)\n\n    # Create a figure\n    fig = None\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": projection})\n\n    # Set the extent to focus on the North Pole\n    ax.set_extent([-180, 180, 50, 90], crs=ccrs.PlateCarree())\n\n    # Add features\n    ax.add_feature(cfeature.LAND, zorder=0, edgecolor=\"black\", facecolor=\"white\")\n    ax.add_feature(cfeature.OCEAN, zorder=0, facecolor=\"lightgrey\")\n    ax.add_feature(cfeature.COASTLINE)\n    ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n    ax.add_feature(cfeature.LAKES, alpha=0.5)\n    ax.add_feature(cfeature.RIVERS)\n\n    # Add gridlines\n    gl = ax.gridlines(draw_labels=True)\n    gl.top_labels = False\n    gl.right_labels = False\n\n    # Compute a circle in axes coordinates, which we can use as a boundary\n    # for the map. We can pan/zoom as much as we like - the boundary will be\n    # permanently circular.\n    theta = np.linspace(0, 2 * np.pi, 100)\n    center, radius = [0.5, 0.5], 0.5\n    verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n    circle = mpath.Path(verts * radius + center)\n\n    ax.set_boundary(circle, transform=ax.transAxes)\n\n    tile_info.plot(\n        \"title\",\n        ax=ax,\n        transform=ccrs.PlateCarree(),\n        edgecolor=\"black\",\n        categorical=True,\n        aspect=\"equal\",\n        alpha=0.5,\n    )\n\n    if fig is not None:\n        return fig\n    else:\n        return ax\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM10m.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m","title":"ArcticDEM2m","text":"<pre><code>ArcticDEM2m(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n)\n</code></pre> <p>               Bases: <code>ArcticDEMABC</code></p> <p>Accessor for ArcticDEM 2m data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the underlaying zarr array. Should be equal to the extent geobox. However, this property is used to find the target index of the downloaded data, so better save than sorry.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_tiles</code>             \u2013              <p>Get adjacent tiles from a STAC API.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_tile</code>             \u2013              <p>Download a tile from a STAC API and write it to a zarr datacube.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download the data for the given geobox.</p> </li> <li> <code>procedural_download_blocking</code>             \u2013              <p>Download tiles procedurally in blocking mode.</p> </li> <li> <code>procedural_download_threading</code>             \u2013              <p>Download tiles procedurally in threading mode.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = StopUhr(logger.debug)\n\n    # The TypeVar used by the ThreadingHandler was added in 3.12\n    # The Shutdown method of the queue was added in 3.13\n    # Hence, we don't want to import the module unless Python 3.13 is installed\n    if _check_python_version(3, 13):\n        from smart_geocubes._concurrency.threading import ThreadingHandler\n\n        self._threading_handler = ThreadingHandler(self._threading_download)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.adjacent_tiles","title":"adjacent_tiles","text":"<pre><code>adjacent_tiles(geobox: GeoBox) -&gt; list[TileWrapper]\n</code></pre> <p>Get adjacent tiles from a STAC API.</p> <p>Overwrite the default implementation from the STAC accessor to use pre-downloaded extent files instead of querying the STAC API. This results in a faster loading time, but requires the extent files to be downloaded beforehand. This is done in the post_create step.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[TileWrapper]</code>           \u2013            <p>list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def adjacent_tiles(self, geobox: GeoBox) -&gt; list[TileWrapper]:\n    \"\"\"Get adjacent tiles from a STAC API.\n\n    Overwrite the default implementation from the STAC accessor\n    to use pre-downloaded extent files instead of querying the STAC API.\n    This results in a faster loading time, but requires the extent files to be downloaded beforehand.\n    This is done in the post_create step.\n\n    Args:\n        geobox (GeoBox): The geobox for which to get adjacent tiles.\n\n    Returns:\n        list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.\n\n    \"\"\"\n    # Assumes that the extent files are already present and the datacube is already created\n    self.assert_created()\n\n    resolution = int(self.extent.resolution.x)\n    extent_info = gpd.read_parquet(self._aux_dir / f\"ArcticDEM_Mosaic_Index_v4_1_{resolution}m.parquet\")\n    adjacent_tiles = extent_info.loc[extent_info.intersects(geobox.extent.geom)].copy()\n    if adjacent_tiles.empty:\n        return []\n    return [LazyStacTileWrapper(tile.dem_id, _get_stac_url(tile.dem_id)) for tile in adjacent_tiles.itertuples()]\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.adjacent_tiles(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox for which to get adjacent tiles.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> <p>Raises:</p> <ul> <li> <code>FileNotFoundError</code>             \u2013            <p>If the datacube does not exist.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\n\n    Raises:\n        FileNotFoundError: If the datacube does not exist.\n\n    \"\"\"\n    if not self.created:\n        msg = f\"Datacube {self.title} does not exist.\"\n        \" Please use the `create` method or pass `create=True` to `load`.\"\n        logger.error(msg)\n        raise FileNotFoundError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.create","title":"create","text":"<pre><code>create(overwrite: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def create(self, overwrite: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube. Defaults to False.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location\n\n    \"\"\"\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        var_encoding = {\n            name: {\n                \"chunks\": (self.chunk_size, self.chunk_size),\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.\n\n\n    \"\"\"\n    import geopandas as gpd\n    import pystac_client\n\n    if not self.created:\n        return None\n\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(session.store, mode=\"r\")\n    loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n\n    if len(loaded_tiles) == 0:\n        return None\n\n    catalog = pystac_client.Client.open(self.stac_api_url)\n    search = catalog.search(collections=[self.collection], ids=loaded_tiles)\n    stac_json = search.item_collection_as_dict()\n\n    gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.download_tile","title":"download_tile","text":"<pre><code>download_tile(tile: TileWrapper) -&gt; xr.Dataset\n</code></pre> <p>Download a tile from a STAC API and write it to a zarr datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded tile data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def download_tile(self, tile: TileWrapper) -&gt; xr.Dataset:\n    \"\"\"Download a tile from a STAC API and write it to a zarr datacube.\n\n    Args:\n        tile (TileWrapper): The tile to download and write.\n\n    Returns:\n        xr.Dataset: The downloaded tile data.\n\n    \"\"\"\n    from odc.stac import stac_load\n\n    tiledata = stac_load([tile.item], bands=self.channels, chunks=None, progress=None)\n\n    # TODO: Allow for multi-temporal datacubes\n    tiledata = tiledata.max(\"time\")\n\n    return tiledata\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.download_tile(tile)","title":"<code>tile</code>","text":"(<code>TileWrapper</code>)           \u2013            <p>The tile to download and write.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.load","title":"load","text":"<pre><code>load(\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load(\n    self,\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        geobox (GeoBox): The reference geobox to load the data for.\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        logger.debug(f\"{_geobox_repr(geobox)}: {geobox.resolution} original resolution\")\n\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        reference_geobox = geobox.to_crs(self.extent.crs, resolution=self.extent.resolution.x).pad(buffer)\n        self.procedural_download(reference_geobox, concurrency_mode=concurrency_mode)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(reference_geobox.extent, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.load(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to load the data for.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.load(buffer)","title":"<code>buffer</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.load(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> <li> <code>concurrency_mode</code>               (<code>ConcurrencyModes</code>)           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    return self.load(_geobox_repr(ref.geobox), **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    xcube = xr.open_zarr(session.store, mask_and_scale=False, consolidated=False).set_coords(\"spatial_ref\")\n    return xcube\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def post_create(self):\n    \"\"\"Download the ArcticDEM mosaic extent info and store it in the datacube.\"\"\"\n    _download_arcticdem_extent(self._aux_dir)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(\n    geobox: GeoBox,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n)\n</code></pre> <p>Download the data for the given geobox.</p> Note <p>The \"threading\" concurrency mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If an unknown concurrency mode is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download(self, geobox: GeoBox, concurrency_mode: ConcurrencyModes = \"blocking\"):\n    \"\"\"Download the data for the given geobox.\n\n    Note:\n        The \"threading\" concurrency mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The reference geobox to download the data for.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Raises:\n        ValueError: If an unknown concurrency mode is provided.\n\n    \"\"\"\n    self.assert_created()\n    if concurrency_mode == \"blocking\":\n        self.procedural_download_blocking(geobox)\n    elif concurrency_mode == \"threading\":\n        self.procedural_download_threading(geobox)\n    else:\n        raise ValueError(f\"Unknown concurrency mode {concurrency_mode}\")\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.procedural_download(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to download the data for.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.procedural_download(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.procedural_download_blocking","title":"procedural_download_blocking","text":"<pre><code>procedural_download_blocking(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in blocking mode.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If no tries are left.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_blocking(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in blocking mode.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If no tries are left.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: Procedural download in blocking mode\"):\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        session = self.repo.readonly_session(\"main\")\n        zcube = zarr.open(store=session.store, mode=\"r\")\n        loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n        new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n        logger.debug(\n            f\"{_geobox_repr(geobox)}:  {len(adjacent_tiles)=} &amp; {len(loaded_tiles)=}\"\n            f\" -&gt; {len(new_tiles)=} to download\"\n        )\n        if not new_tiles:\n            return\n\n        for tile in new_tiles:\n            with self.stopuhr(f\"{tile.id=}: Downloading one new tile in blocking mode\"):\n                logger.debug(f\"{tile.id=}: Start downloading\")\n                tiledata = self.download_tile(tile)\n\n            # Try to write the data to file until a limit is reached\n            limit = 100\n            for i in range(limit):\n                try:\n                    self._write_tile_to_zarr(tiledata, tile)\n                    break\n                except icechunk.ConflictError as conflict_error:\n                    logger.debug(f\"{tile.id=}: {conflict_error=} at retry {i}/{limit}\")\n            else:\n                logger.error(\n                    f\"{tile.id=}: {limit} tries to write the tile failed. \"\n                    \"Please check if the datacube is already created and not empty.\"\n                )\n                raise ValueError(f\"{tile.id=}: {limit} tries to write the tile failed.\")\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.procedural_download_blocking(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.procedural_download_threading","title":"procedural_download_threading","text":"<pre><code>procedural_download_threading(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in threading mode.</p> Note <p>This method ensures that only a single download is running at a time. It uses a SetQueue to prevent duplicate downloads. The threading mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>RuntimeError</code>             \u2013            <p>If the Python version is lower than 3.13.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_threading(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in threading mode.\n\n    Note:\n        This method ensures that only a single download is running at a time.\n        It uses a SetQueue to prevent duplicate downloads.\n        The threading mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        RuntimeError: If the Python version is lower than 3.13.\n\n    \"\"\"\n    if not _check_python_version(3, 13):\n        raise RuntimeError(\"Threading mode requires Python 3.13 or higher\")\n    with self._threading_handler:\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        # Wait until all new_items are loaded\n        prev_len = None\n        while True:\n            session = self.repo.readonly_session(\"main\")\n            zcube = zarr.open(store=session.store, mode=\"r\")\n            loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n            new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n            done_tiles = [tile for tile in adjacent_tiles if tile.id in loaded_tiles]\n            if not new_tiles:\n                break\n            if prev_len != len(new_tiles):\n                logger.debug(\n                    f\"{_geobox_repr(geobox)}: {len(done_tiles)} of {len(adjacent_tiles)} downloaded.\"\n                    f\" Missing: {[t.id for t in new_tiles]} Done: {[t.id for t in done_tiles]}\"\n                )\n            for tile in new_tiles:\n                self._threading_handler._queue.put(tile)\n            prev_len = len(new_tiles)\n            time.sleep(5)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.procedural_download_threading(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    import cartopy.crs as ccrs\n    import cartopy.feature as cfeature\n    import matplotlib.path as mpath\n    import matplotlib.pyplot as plt\n\n    tile_info = self.current_state()\n\n    if tile_info is None:\n        raise ValueError(\"Datacube is not created or loaded yet. Can't visualize!\")\n\n    # Define the projection\n    projection = ccrs.Stereographic(central_latitude=90, central_longitude=-45, true_scale_latitude=70)\n\n    # Create a figure\n    fig = None\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": projection})\n\n    # Set the extent to focus on the North Pole\n    ax.set_extent([-180, 180, 50, 90], crs=ccrs.PlateCarree())\n\n    # Add features\n    ax.add_feature(cfeature.LAND, zorder=0, edgecolor=\"black\", facecolor=\"white\")\n    ax.add_feature(cfeature.OCEAN, zorder=0, facecolor=\"lightgrey\")\n    ax.add_feature(cfeature.COASTLINE)\n    ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n    ax.add_feature(cfeature.LAKES, alpha=0.5)\n    ax.add_feature(cfeature.RIVERS)\n\n    # Add gridlines\n    gl = ax.gridlines(draw_labels=True)\n    gl.top_labels = False\n    gl.right_labels = False\n\n    # Compute a circle in axes coordinates, which we can use as a boundary\n    # for the map. We can pan/zoom as much as we like - the boundary will be\n    # permanently circular.\n    theta = np.linspace(0, 2 * np.pi, 100)\n    center, radius = [0.5, 0.5], 0.5\n    verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n    circle = mpath.Path(verts * radius + center)\n\n    ax.set_boundary(circle, transform=ax.transAxes)\n\n    tile_info.plot(\n        \"title\",\n        ax=ax,\n        transform=ccrs.PlateCarree(),\n        edgecolor=\"black\",\n        categorical=True,\n        aspect=\"equal\",\n        alpha=0.5,\n    )\n\n    if fig is not None:\n        return fig\n    else:\n        return ax\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM2m.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m","title":"ArcticDEM32m","text":"<pre><code>ArcticDEM32m(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n)\n</code></pre> <p>               Bases: <code>ArcticDEMABC</code></p> <p>Accessor for ArcticDEM 32m data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the underlaying zarr array. Should be equal to the extent geobox. However, this property is used to find the target index of the downloaded data, so better save than sorry.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_tiles</code>             \u2013              <p>Get adjacent tiles from a STAC API.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_tile</code>             \u2013              <p>Download a tile from a STAC API and write it to a zarr datacube.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download the data for the given geobox.</p> </li> <li> <code>procedural_download_blocking</code>             \u2013              <p>Download tiles procedurally in blocking mode.</p> </li> <li> <code>procedural_download_threading</code>             \u2013              <p>Download tiles procedurally in threading mode.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = StopUhr(logger.debug)\n\n    # The TypeVar used by the ThreadingHandler was added in 3.12\n    # The Shutdown method of the queue was added in 3.13\n    # Hence, we don't want to import the module unless Python 3.13 is installed\n    if _check_python_version(3, 13):\n        from smart_geocubes._concurrency.threading import ThreadingHandler\n\n        self._threading_handler = ThreadingHandler(self._threading_download)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.adjacent_tiles","title":"adjacent_tiles","text":"<pre><code>adjacent_tiles(geobox: GeoBox) -&gt; list[TileWrapper]\n</code></pre> <p>Get adjacent tiles from a STAC API.</p> <p>Overwrite the default implementation from the STAC accessor to use pre-downloaded extent files instead of querying the STAC API. This results in a faster loading time, but requires the extent files to be downloaded beforehand. This is done in the post_create step.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[TileWrapper]</code>           \u2013            <p>list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def adjacent_tiles(self, geobox: GeoBox) -&gt; list[TileWrapper]:\n    \"\"\"Get adjacent tiles from a STAC API.\n\n    Overwrite the default implementation from the STAC accessor\n    to use pre-downloaded extent files instead of querying the STAC API.\n    This results in a faster loading time, but requires the extent files to be downloaded beforehand.\n    This is done in the post_create step.\n\n    Args:\n        geobox (GeoBox): The geobox for which to get adjacent tiles.\n\n    Returns:\n        list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.\n\n    \"\"\"\n    # Assumes that the extent files are already present and the datacube is already created\n    self.assert_created()\n\n    resolution = int(self.extent.resolution.x)\n    extent_info = gpd.read_parquet(self._aux_dir / f\"ArcticDEM_Mosaic_Index_v4_1_{resolution}m.parquet\")\n    adjacent_tiles = extent_info.loc[extent_info.intersects(geobox.extent.geom)].copy()\n    if adjacent_tiles.empty:\n        return []\n    return [LazyStacTileWrapper(tile.dem_id, _get_stac_url(tile.dem_id)) for tile in adjacent_tiles.itertuples()]\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.adjacent_tiles(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox for which to get adjacent tiles.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> <p>Raises:</p> <ul> <li> <code>FileNotFoundError</code>             \u2013            <p>If the datacube does not exist.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\n\n    Raises:\n        FileNotFoundError: If the datacube does not exist.\n\n    \"\"\"\n    if not self.created:\n        msg = f\"Datacube {self.title} does not exist.\"\n        \" Please use the `create` method or pass `create=True` to `load`.\"\n        logger.error(msg)\n        raise FileNotFoundError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.create","title":"create","text":"<pre><code>create(overwrite: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def create(self, overwrite: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube. Defaults to False.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location\n\n    \"\"\"\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        var_encoding = {\n            name: {\n                \"chunks\": (self.chunk_size, self.chunk_size),\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.\n\n\n    \"\"\"\n    import geopandas as gpd\n    import pystac_client\n\n    if not self.created:\n        return None\n\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(session.store, mode=\"r\")\n    loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n\n    if len(loaded_tiles) == 0:\n        return None\n\n    catalog = pystac_client.Client.open(self.stac_api_url)\n    search = catalog.search(collections=[self.collection], ids=loaded_tiles)\n    stac_json = search.item_collection_as_dict()\n\n    gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.download_tile","title":"download_tile","text":"<pre><code>download_tile(tile: TileWrapper) -&gt; xr.Dataset\n</code></pre> <p>Download a tile from a STAC API and write it to a zarr datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded tile data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def download_tile(self, tile: TileWrapper) -&gt; xr.Dataset:\n    \"\"\"Download a tile from a STAC API and write it to a zarr datacube.\n\n    Args:\n        tile (TileWrapper): The tile to download and write.\n\n    Returns:\n        xr.Dataset: The downloaded tile data.\n\n    \"\"\"\n    from odc.stac import stac_load\n\n    tiledata = stac_load([tile.item], bands=self.channels, chunks=None, progress=None)\n\n    # TODO: Allow for multi-temporal datacubes\n    tiledata = tiledata.max(\"time\")\n\n    return tiledata\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.download_tile(tile)","title":"<code>tile</code>","text":"(<code>TileWrapper</code>)           \u2013            <p>The tile to download and write.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.load","title":"load","text":"<pre><code>load(\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load(\n    self,\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        geobox (GeoBox): The reference geobox to load the data for.\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        logger.debug(f\"{_geobox_repr(geobox)}: {geobox.resolution} original resolution\")\n\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        reference_geobox = geobox.to_crs(self.extent.crs, resolution=self.extent.resolution.x).pad(buffer)\n        self.procedural_download(reference_geobox, concurrency_mode=concurrency_mode)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(reference_geobox.extent, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.load(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to load the data for.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.load(buffer)","title":"<code>buffer</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.load(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> <li> <code>concurrency_mode</code>               (<code>ConcurrencyModes</code>)           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    return self.load(_geobox_repr(ref.geobox), **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    xcube = xr.open_zarr(session.store, mask_and_scale=False, consolidated=False).set_coords(\"spatial_ref\")\n    return xcube\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def post_create(self):\n    \"\"\"Download the ArcticDEM mosaic extent info and store it in the datacube.\"\"\"\n    _download_arcticdem_extent(self._aux_dir)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(\n    geobox: GeoBox,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n)\n</code></pre> <p>Download the data for the given geobox.</p> Note <p>The \"threading\" concurrency mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If an unknown concurrency mode is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download(self, geobox: GeoBox, concurrency_mode: ConcurrencyModes = \"blocking\"):\n    \"\"\"Download the data for the given geobox.\n\n    Note:\n        The \"threading\" concurrency mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The reference geobox to download the data for.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Raises:\n        ValueError: If an unknown concurrency mode is provided.\n\n    \"\"\"\n    self.assert_created()\n    if concurrency_mode == \"blocking\":\n        self.procedural_download_blocking(geobox)\n    elif concurrency_mode == \"threading\":\n        self.procedural_download_threading(geobox)\n    else:\n        raise ValueError(f\"Unknown concurrency mode {concurrency_mode}\")\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.procedural_download(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to download the data for.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.procedural_download(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.procedural_download_blocking","title":"procedural_download_blocking","text":"<pre><code>procedural_download_blocking(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in blocking mode.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If no tries are left.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_blocking(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in blocking mode.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If no tries are left.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: Procedural download in blocking mode\"):\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        session = self.repo.readonly_session(\"main\")\n        zcube = zarr.open(store=session.store, mode=\"r\")\n        loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n        new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n        logger.debug(\n            f\"{_geobox_repr(geobox)}:  {len(adjacent_tiles)=} &amp; {len(loaded_tiles)=}\"\n            f\" -&gt; {len(new_tiles)=} to download\"\n        )\n        if not new_tiles:\n            return\n\n        for tile in new_tiles:\n            with self.stopuhr(f\"{tile.id=}: Downloading one new tile in blocking mode\"):\n                logger.debug(f\"{tile.id=}: Start downloading\")\n                tiledata = self.download_tile(tile)\n\n            # Try to write the data to file until a limit is reached\n            limit = 100\n            for i in range(limit):\n                try:\n                    self._write_tile_to_zarr(tiledata, tile)\n                    break\n                except icechunk.ConflictError as conflict_error:\n                    logger.debug(f\"{tile.id=}: {conflict_error=} at retry {i}/{limit}\")\n            else:\n                logger.error(\n                    f\"{tile.id=}: {limit} tries to write the tile failed. \"\n                    \"Please check if the datacube is already created and not empty.\"\n                )\n                raise ValueError(f\"{tile.id=}: {limit} tries to write the tile failed.\")\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.procedural_download_blocking(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.procedural_download_threading","title":"procedural_download_threading","text":"<pre><code>procedural_download_threading(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in threading mode.</p> Note <p>This method ensures that only a single download is running at a time. It uses a SetQueue to prevent duplicate downloads. The threading mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>RuntimeError</code>             \u2013            <p>If the Python version is lower than 3.13.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_threading(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in threading mode.\n\n    Note:\n        This method ensures that only a single download is running at a time.\n        It uses a SetQueue to prevent duplicate downloads.\n        The threading mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        RuntimeError: If the Python version is lower than 3.13.\n\n    \"\"\"\n    if not _check_python_version(3, 13):\n        raise RuntimeError(\"Threading mode requires Python 3.13 or higher\")\n    with self._threading_handler:\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        # Wait until all new_items are loaded\n        prev_len = None\n        while True:\n            session = self.repo.readonly_session(\"main\")\n            zcube = zarr.open(store=session.store, mode=\"r\")\n            loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n            new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n            done_tiles = [tile for tile in adjacent_tiles if tile.id in loaded_tiles]\n            if not new_tiles:\n                break\n            if prev_len != len(new_tiles):\n                logger.debug(\n                    f\"{_geobox_repr(geobox)}: {len(done_tiles)} of {len(adjacent_tiles)} downloaded.\"\n                    f\" Missing: {[t.id for t in new_tiles]} Done: {[t.id for t in done_tiles]}\"\n                )\n            for tile in new_tiles:\n                self._threading_handler._queue.put(tile)\n            prev_len = len(new_tiles)\n            time.sleep(5)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.procedural_download_threading(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    import cartopy.crs as ccrs\n    import cartopy.feature as cfeature\n    import matplotlib.path as mpath\n    import matplotlib.pyplot as plt\n\n    tile_info = self.current_state()\n\n    if tile_info is None:\n        raise ValueError(\"Datacube is not created or loaded yet. Can't visualize!\")\n\n    # Define the projection\n    projection = ccrs.Stereographic(central_latitude=90, central_longitude=-45, true_scale_latitude=70)\n\n    # Create a figure\n    fig = None\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": projection})\n\n    # Set the extent to focus on the North Pole\n    ax.set_extent([-180, 180, 50, 90], crs=ccrs.PlateCarree())\n\n    # Add features\n    ax.add_feature(cfeature.LAND, zorder=0, edgecolor=\"black\", facecolor=\"white\")\n    ax.add_feature(cfeature.OCEAN, zorder=0, facecolor=\"lightgrey\")\n    ax.add_feature(cfeature.COASTLINE)\n    ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n    ax.add_feature(cfeature.LAKES, alpha=0.5)\n    ax.add_feature(cfeature.RIVERS)\n\n    # Add gridlines\n    gl = ax.gridlines(draw_labels=True)\n    gl.top_labels = False\n    gl.right_labels = False\n\n    # Compute a circle in axes coordinates, which we can use as a boundary\n    # for the map. We can pan/zoom as much as we like - the boundary will be\n    # permanently circular.\n    theta = np.linspace(0, 2 * np.pi, 100)\n    center, radius = [0.5, 0.5], 0.5\n    verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n    circle = mpath.Path(verts * radius + center)\n\n    ax.set_boundary(circle, transform=ax.transAxes)\n\n    tile_info.plot(\n        \"title\",\n        ax=ax,\n        transform=ccrs.PlateCarree(),\n        edgecolor=\"black\",\n        categorical=True,\n        aspect=\"equal\",\n        alpha=0.5,\n    )\n\n    if fig is not None:\n        return fig\n    else:\n        return ax\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEM32m.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC","title":"ArcticDEMABC","text":"<pre><code>ArcticDEMABC(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n)\n</code></pre> <p>               Bases: <code>STACAccessor</code></p> <p>ABC for Arcticdem data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the underlaying zarr array. Should be equal to the extent geobox. However, this property is used to find the target index of the downloaded data, so better save than sorry.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_tiles</code>             \u2013              <p>Get adjacent tiles from a STAC API.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_tile</code>             \u2013              <p>Download a tile from a STAC API and write it to a zarr datacube.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download the data for the given geobox.</p> </li> <li> <code>procedural_download_blocking</code>             \u2013              <p>Download tiles procedurally in blocking mode.</p> </li> <li> <code>procedural_download_threading</code>             \u2013              <p>Download tiles procedurally in threading mode.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = StopUhr(logger.debug)\n\n    # The TypeVar used by the ThreadingHandler was added in 3.12\n    # The Shutdown method of the queue was added in 3.13\n    # Hence, we don't want to import the module unless Python 3.13 is installed\n    if _check_python_version(3, 13):\n        from smart_geocubes._concurrency.threading import ThreadingHandler\n\n        self._threading_handler = ThreadingHandler(self._threading_download)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.adjacent_tiles","title":"adjacent_tiles","text":"<pre><code>adjacent_tiles(geobox: GeoBox) -&gt; list[TileWrapper]\n</code></pre> <p>Get adjacent tiles from a STAC API.</p> <p>Overwrite the default implementation from the STAC accessor to use pre-downloaded extent files instead of querying the STAC API. This results in a faster loading time, but requires the extent files to be downloaded beforehand. This is done in the post_create step.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[TileWrapper]</code>           \u2013            <p>list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def adjacent_tiles(self, geobox: GeoBox) -&gt; list[TileWrapper]:\n    \"\"\"Get adjacent tiles from a STAC API.\n\n    Overwrite the default implementation from the STAC accessor\n    to use pre-downloaded extent files instead of querying the STAC API.\n    This results in a faster loading time, but requires the extent files to be downloaded beforehand.\n    This is done in the post_create step.\n\n    Args:\n        geobox (GeoBox): The geobox for which to get adjacent tiles.\n\n    Returns:\n        list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.\n\n    \"\"\"\n    # Assumes that the extent files are already present and the datacube is already created\n    self.assert_created()\n\n    resolution = int(self.extent.resolution.x)\n    extent_info = gpd.read_parquet(self._aux_dir / f\"ArcticDEM_Mosaic_Index_v4_1_{resolution}m.parquet\")\n    adjacent_tiles = extent_info.loc[extent_info.intersects(geobox.extent.geom)].copy()\n    if adjacent_tiles.empty:\n        return []\n    return [LazyStacTileWrapper(tile.dem_id, _get_stac_url(tile.dem_id)) for tile in adjacent_tiles.itertuples()]\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.adjacent_tiles(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox for which to get adjacent tiles.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> <p>Raises:</p> <ul> <li> <code>FileNotFoundError</code>             \u2013            <p>If the datacube does not exist.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\n\n    Raises:\n        FileNotFoundError: If the datacube does not exist.\n\n    \"\"\"\n    if not self.created:\n        msg = f\"Datacube {self.title} does not exist.\"\n        \" Please use the `create` method or pass `create=True` to `load`.\"\n        logger.error(msg)\n        raise FileNotFoundError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.create","title":"create","text":"<pre><code>create(overwrite: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def create(self, overwrite: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube. Defaults to False.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location\n\n    \"\"\"\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        var_encoding = {\n            name: {\n                \"chunks\": (self.chunk_size, self.chunk_size),\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tile info from pystac. None if datacube is empty.\n\n\n    \"\"\"\n    import geopandas as gpd\n    import pystac_client\n\n    if not self.created:\n        return None\n\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(session.store, mode=\"r\")\n    loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n\n    if len(loaded_tiles) == 0:\n        return None\n\n    catalog = pystac_client.Client.open(self.stac_api_url)\n    search = catalog.search(collections=[self.collection], ids=loaded_tiles)\n    stac_json = search.item_collection_as_dict()\n\n    gdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.download_tile","title":"download_tile","text":"<pre><code>download_tile(tile: TileWrapper) -&gt; xr.Dataset\n</code></pre> <p>Download a tile from a STAC API and write it to a zarr datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded tile data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/stac.py</code> <pre><code>def download_tile(self, tile: TileWrapper) -&gt; xr.Dataset:\n    \"\"\"Download a tile from a STAC API and write it to a zarr datacube.\n\n    Args:\n        tile (TileWrapper): The tile to download and write.\n\n    Returns:\n        xr.Dataset: The downloaded tile data.\n\n    \"\"\"\n    from odc.stac import stac_load\n\n    tiledata = stac_load([tile.item], bands=self.channels, chunks=None, progress=None)\n\n    # TODO: Allow for multi-temporal datacubes\n    tiledata = tiledata.max(\"time\")\n\n    return tiledata\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.download_tile(tile)","title":"<code>tile</code>","text":"(<code>TileWrapper</code>)           \u2013            <p>The tile to download and write.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.load","title":"load","text":"<pre><code>load(\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load(\n    self,\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        geobox (GeoBox): The reference geobox to load the data for.\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        logger.debug(f\"{_geobox_repr(geobox)}: {geobox.resolution} original resolution\")\n\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        reference_geobox = geobox.to_crs(self.extent.crs, resolution=self.extent.resolution.x).pad(buffer)\n        self.procedural_download(reference_geobox, concurrency_mode=concurrency_mode)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(reference_geobox.extent, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.load(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to load the data for.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.load(buffer)","title":"<code>buffer</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.load(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> <li> <code>concurrency_mode</code>               (<code>ConcurrencyModes</code>)           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    return self.load(_geobox_repr(ref.geobox), **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    xcube = xr.open_zarr(session.store, mask_and_scale=False, consolidated=False).set_coords(\"spatial_ref\")\n    return xcube\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Download the ArcticDEM mosaic extent info and store it in the datacube.</p> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def post_create(self):\n    \"\"\"Download the ArcticDEM mosaic extent info and store it in the datacube.\"\"\"\n    _download_arcticdem_extent(self._aux_dir)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(\n    geobox: GeoBox,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n)\n</code></pre> <p>Download the data for the given geobox.</p> Note <p>The \"threading\" concurrency mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If an unknown concurrency mode is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download(self, geobox: GeoBox, concurrency_mode: ConcurrencyModes = \"blocking\"):\n    \"\"\"Download the data for the given geobox.\n\n    Note:\n        The \"threading\" concurrency mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The reference geobox to download the data for.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Raises:\n        ValueError: If an unknown concurrency mode is provided.\n\n    \"\"\"\n    self.assert_created()\n    if concurrency_mode == \"blocking\":\n        self.procedural_download_blocking(geobox)\n    elif concurrency_mode == \"threading\":\n        self.procedural_download_threading(geobox)\n    else:\n        raise ValueError(f\"Unknown concurrency mode {concurrency_mode}\")\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.procedural_download(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to download the data for.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.procedural_download(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.procedural_download_blocking","title":"procedural_download_blocking","text":"<pre><code>procedural_download_blocking(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in blocking mode.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If no tries are left.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_blocking(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in blocking mode.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If no tries are left.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: Procedural download in blocking mode\"):\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        session = self.repo.readonly_session(\"main\")\n        zcube = zarr.open(store=session.store, mode=\"r\")\n        loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n        new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n        logger.debug(\n            f\"{_geobox_repr(geobox)}:  {len(adjacent_tiles)=} &amp; {len(loaded_tiles)=}\"\n            f\" -&gt; {len(new_tiles)=} to download\"\n        )\n        if not new_tiles:\n            return\n\n        for tile in new_tiles:\n            with self.stopuhr(f\"{tile.id=}: Downloading one new tile in blocking mode\"):\n                logger.debug(f\"{tile.id=}: Start downloading\")\n                tiledata = self.download_tile(tile)\n\n            # Try to write the data to file until a limit is reached\n            limit = 100\n            for i in range(limit):\n                try:\n                    self._write_tile_to_zarr(tiledata, tile)\n                    break\n                except icechunk.ConflictError as conflict_error:\n                    logger.debug(f\"{tile.id=}: {conflict_error=} at retry {i}/{limit}\")\n            else:\n                logger.error(\n                    f\"{tile.id=}: {limit} tries to write the tile failed. \"\n                    \"Please check if the datacube is already created and not empty.\"\n                )\n                raise ValueError(f\"{tile.id=}: {limit} tries to write the tile failed.\")\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.procedural_download_blocking(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.procedural_download_threading","title":"procedural_download_threading","text":"<pre><code>procedural_download_threading(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in threading mode.</p> Note <p>This method ensures that only a single download is running at a time. It uses a SetQueue to prevent duplicate downloads. The threading mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>RuntimeError</code>             \u2013            <p>If the Python version is lower than 3.13.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_threading(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in threading mode.\n\n    Note:\n        This method ensures that only a single download is running at a time.\n        It uses a SetQueue to prevent duplicate downloads.\n        The threading mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        RuntimeError: If the Python version is lower than 3.13.\n\n    \"\"\"\n    if not _check_python_version(3, 13):\n        raise RuntimeError(\"Threading mode requires Python 3.13 or higher\")\n    with self._threading_handler:\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        # Wait until all new_items are loaded\n        prev_len = None\n        while True:\n            session = self.repo.readonly_session(\"main\")\n            zcube = zarr.open(store=session.store, mode=\"r\")\n            loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n            new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n            done_tiles = [tile for tile in adjacent_tiles if tile.id in loaded_tiles]\n            if not new_tiles:\n                break\n            if prev_len != len(new_tiles):\n                logger.debug(\n                    f\"{_geobox_repr(geobox)}: {len(done_tiles)} of {len(adjacent_tiles)} downloaded.\"\n                    f\" Missing: {[t.id for t in new_tiles]} Done: {[t.id for t in done_tiles]}\"\n                )\n            for tile in new_tiles:\n                self._threading_handler._queue.put(tile)\n            prev_len = len(new_tiles)\n            time.sleep(5)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.procedural_download_threading(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    import cartopy.crs as ccrs\n    import cartopy.feature as cfeature\n    import matplotlib.path as mpath\n    import matplotlib.pyplot as plt\n\n    tile_info = self.current_state()\n\n    if tile_info is None:\n        raise ValueError(\"Datacube is not created or loaded yet. Can't visualize!\")\n\n    # Define the projection\n    projection = ccrs.Stereographic(central_latitude=90, central_longitude=-45, true_scale_latitude=70)\n\n    # Create a figure\n    fig = None\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": projection})\n\n    # Set the extent to focus on the North Pole\n    ax.set_extent([-180, 180, 50, 90], crs=ccrs.PlateCarree())\n\n    # Add features\n    ax.add_feature(cfeature.LAND, zorder=0, edgecolor=\"black\", facecolor=\"white\")\n    ax.add_feature(cfeature.OCEAN, zorder=0, facecolor=\"lightgrey\")\n    ax.add_feature(cfeature.COASTLINE)\n    ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n    ax.add_feature(cfeature.LAKES, alpha=0.5)\n    ax.add_feature(cfeature.RIVERS)\n\n    # Add gridlines\n    gl = ax.gridlines(draw_labels=True)\n    gl.top_labels = False\n    gl.right_labels = False\n\n    # Compute a circle in axes coordinates, which we can use as a boundary\n    # for the map. We can pan/zoom as much as we like - the boundary will be\n    # permanently circular.\n    theta = np.linspace(0, 2 * np.pi, 100)\n    center, radius = [0.5, 0.5], 0.5\n    verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n    circle = mpath.Path(verts * radius + center)\n\n    ax.set_boundary(circle, transform=ax.transAxes)\n\n    tile_info.plot(\n        \"title\",\n        ax=ax,\n        transform=ccrs.PlateCarree(),\n        edgecolor=\"black\",\n        categorical=True,\n        aspect=\"equal\",\n        alpha=0.5,\n    )\n\n    if fig is not None:\n        return fig\n    else:\n        return ax\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.ArcticDEMABC.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/datasets/arcticdem/#smart_geocubes.datasets.arcticdem.LazyStacTileWrapper","title":"LazyStacTileWrapper","text":"<pre><code>LazyStacTileWrapper(tile_id: str, stac_file: str)\n</code></pre> <p>Lazy wrapper for a TileWrapper containing a STAC Item.</p> <p>This is necessary since the download function of the STAC accessor expects a TileWrapper object containing a pystac.Item.</p> <p>However, creating such a pystac Item always fetches the metadata from the STAC API. For just loading the ArcticDEM data, we don't need this pystac Item. Hence, we create it lazily when it is actually needed.</p> Source code in <code>src/smart_geocubes/datasets/arcticdem.py</code> <pre><code>def __init__(self, tile_id: str, stac_file: str):  # noqa: D107\n    self.id = tile_id\n    self.stac_file = stac_file\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/","title":"smart_geocubes.datasets.tctrend","text":""},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend","title":"smart_geocubes.datasets.tctrend","text":"<p>Predefined accessor for TCTrend data.</p> <p>Classes:</p> <ul> <li> <code>TCTrend</code>           \u2013            <p>Accessor for TCTrend data.</p> </li> </ul>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend","title":"TCTrend","text":"<pre><code>TCTrend(\n    storage: Storage | Path | str,\n    create_icechunk_storage: bool = True,\n)\n</code></pre> <p>               Bases: <code>GEEAccessor</code></p> <p>Accessor for TCTrend data.</p> <p>Attributes:</p> <ul> <li> <code>extent</code>               (<code>GeoBox</code>)           \u2013            <p>The extent of the datacube represented by a GeoBox.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The chunk size of the datacube.</p> </li> <li> <code>channels</code>               (<code>list</code>)           \u2013            <p>The channels of the datacube.</p> </li> <li> <code>storage</code>               (<code>Storage</code>)           \u2013            <p>The icechunk storage.</p> </li> <li> <code>repo</code>               (<code>Repository</code>)           \u2013            <p>The icechunk repository.</p> </li> <li> <code>title</code>               (<code>str</code>)           \u2013            <p>The title of the datacube.</p> </li> <li> <code>stopuhr</code>               (<code>StopUhr</code>)           \u2013            <p>The benchmarking timer from the stopuhr library.</p> </li> <li> <code>zgeobox</code>               (<code>GeoBox</code>)           \u2013            <p>The geobox of the zarr array. Should be equal to the extent geobox.</p> </li> <li> <code>created</code>               (<code>bool</code>)           \u2013            <p>True if the datacube already exists in the storage.</p> </li> </ul> <p>Initialize base class for remote accessors.</p> <p>Warning</p> <p>In a multiprocessing environment, it is strongly recommended to not set <code>create_icechunk_storage=False</code>.</p> <p>Parameters:</p> <ul> <li> </li> <li> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the storage is not an icechunk.Storage.</p> </li> </ul> <p>Methods:</p> <ul> <li> <code>adjacent_tiles</code>             \u2013              <p>Get adjacent tiles from Google Earth Engine.</p> </li> <li> <code>assert_created</code>             \u2013              <p>Assert that the datacube exists in the storage.</p> </li> <li> <code>create</code>             \u2013              <p>Create an empty datacube and write it to the store.</p> </li> <li> <code>current_state</code>             \u2013              <p>Get info about currently stored tiles.</p> </li> <li> <code>download_tile</code>             \u2013              <p>Download a tile from Google Earth Engine.</p> </li> <li> <code>load</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>load_like</code>             \u2013              <p>Load the data for the given geobox.</p> </li> <li> <code>log_benchmark_summary</code>             \u2013              <p>Log the benchmark summary.</p> </li> <li> <code>open_xarray</code>             \u2013              <p>Open the xarray datacube in read-only mode.</p> </li> <li> <code>open_zarr</code>             \u2013              <p>Open the zarr datacube in read-only mode.</p> </li> <li> <code>post_create</code>             \u2013              <p>Post create actions. Can be overwritten by the dataset accessor.</p> </li> <li> <code>procedural_download</code>             \u2013              <p>Download the data for the given geobox.</p> </li> <li> <code>procedural_download_blocking</code>             \u2013              <p>Download tiles procedurally in blocking mode.</p> </li> <li> <code>procedural_download_threading</code>             \u2013              <p>Download tiles procedurally in threading mode.</p> </li> <li> <code>visualize_state</code>             \u2013              <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def __init__(\n    self,\n    storage: icechunk.Storage | Path | str,\n    create_icechunk_storage: bool = True,\n):\n    \"\"\"Initialize base class for remote accessors.\n\n    !!! warning\n\n        In a multiprocessing environment, it is strongly recommended to not set `create_icechunk_storage=False`.\n\n    Args:\n        storage (icechunk.Storage): The icechunk storage of the datacube.\n        create_icechunk_storage (bool, optional): If an icechunk repository should be created at provided storage\n            if no exists.\n            This should be disabled in a multiprocessing environment.\n            Defaults to True.\n\n    Raises:\n        ValueError: If the storage is not an icechunk.Storage.\n\n    \"\"\"\n    # Title is used for logging, debugging and as a default name for the datacube\n    self.title = self.__class__.__name__\n\n    if isinstance(storage, (str | Path)):\n        storage = storage if isinstance(storage, str) else str(storage.resolve())\n        storage = icechunk.local_filesystem_storage(storage)\n    if not isinstance(storage, icechunk.Storage):\n        raise ValueError(f\"Expected an icechunk.Storage, but got {type(storage)}\")\n    self.storage = storage\n    logger.debug(f\"Using storage {storage=}\")\n    if create_icechunk_storage:\n        self.repo = icechunk.Repository.open_or_create(storage)  # Will create a \"main\" branch\n    else:\n        self.repo = icechunk.Repository.open(storage)\n    logger.debug(f\"Using repository {self.repo=}\")\n\n    # The benchmarking timer for this accessor\n    self.stopuhr = StopUhr(logger.debug)\n\n    # The TypeVar used by the ThreadingHandler was added in 3.12\n    # The Shutdown method of the queue was added in 3.13\n    # Hence, we don't want to import the module unless Python 3.13 is installed\n    if _check_python_version(3, 13):\n        from smart_geocubes._concurrency.threading import ThreadingHandler\n\n        self._threading_handler = ThreadingHandler(self._threading_download)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend(storage)","title":"<code>storage</code>","text":"(<code>Storage</code>)           \u2013            <p>The icechunk storage of the datacube.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend(create_icechunk_storage)","title":"<code>create_icechunk_storage</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If an icechunk repository should be created at provided storage if no exists. This should be disabled in a multiprocessing environment. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.adjacent_tiles","title":"adjacent_tiles","text":"<pre><code>adjacent_tiles(geobox: GeoBox) -&gt; list[TileWrapper]\n</code></pre> <p>Get adjacent tiles from Google Earth Engine.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>list[TileWrapper]</code>           \u2013            <p>list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def adjacent_tiles(self, geobox: GeoBox) -&gt; list[TileWrapper]:\n    \"\"\"Get adjacent tiles from Google Earth Engine.\n\n    Args:\n        geobox (GeoBox): The geobox for which to get adjacent tiles.\n\n    Returns:\n        list[TileWrapper]: List of adjacent tiles, wrapped in own datastructure for easier processing.\n\n    \"\"\"\n    extent_tiles = GeoboxTiles(self.extent, (self.chunk_size, self.chunk_size))\n    return [TileWrapper(_tileidx_to_id(idx), extent_tiles[idx]) for idx in extent_tiles.tiles(geobox.extent)]\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.adjacent_tiles(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox for which to get adjacent tiles.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.assert_created","title":"assert_created","text":"<pre><code>assert_created()\n</code></pre> <p>Assert that the datacube exists in the storage.</p> <p>Raises:</p> <ul> <li> <code>FileNotFoundError</code>             \u2013            <p>If the datacube does not exist.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def assert_created(self):\n    \"\"\"Assert that the datacube exists in the storage.\n\n    Raises:\n        FileNotFoundError: If the datacube does not exist.\n\n    \"\"\"\n    if not self.created:\n        msg = f\"Datacube {self.title} does not exist.\"\n        \" Please use the `create` method or pass `create=True` to `load`.\"\n        logger.error(msg)\n        raise FileNotFoundError(msg)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.create","title":"create","text":"<pre><code>create(overwrite: bool = False)\n</code></pre> <p>Create an empty datacube and write it to the store.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>FileExistsError</code>             \u2013            <p>If a datacube already exists at location</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def create(self, overwrite: bool = False):\n    \"\"\"Create an empty datacube and write it to the store.\n\n    Args:\n        overwrite (bool, optional): Allowing overwriting an existing datacube. Defaults to False.\n\n    Raises:\n        FileExistsError: If a datacube already exists at location\n\n    \"\"\"\n    with self.stopuhr(\"Empty datacube creation\"):\n        # Check if the zarr data already exists\n        session = self.repo.writable_session(\"main\")\n        cube_is_empty = sync(session.store.is_empty(\"\"))\n        if not overwrite and not cube_is_empty:\n            logger.debug(f\"Unable to create a new datacube. {overwrite=} {cube_is_empty=} {session.store=}\")\n            raise FileExistsError(f\"Cannot create a new  datacube. {session.store=} is not empty!\")\n\n        logger.debug(\n            f\"Creating an empty zarr datacube '{self.title}' with the variables\"\n            f\" {self.channels} at a {self.extent.resolution=} (epsg:{self.extent.crs.epsg})\"\n            f\" and {self.chunk_size=} to {session.store=}\"\n        )\n\n        ds = xr.Dataset(\n            {\n                name: odc.geo.xr.xr_zeros(\n                    self.extent,\n                    chunks=-1,\n                    dtype=self._channels_encoding[name].get(\"dtype\", \"float32\"),\n                    always_yx=True,\n                )\n                for name in self.channels\n            },\n            attrs={\"title\": self.title, \"loaded_tiles\": []},\n        )\n\n        # Add metadata\n        for name, meta in self._channels_meta.items():\n            ds[name].attrs.update(meta)\n\n        # Get the encoding for the coordinates, variables and spatial reference\n        coords_encoding = {\n            \"x\": {\"chunks\": ds.x.shape, **optimize_coord_encoding(ds.x.values, self.extent.resolution.x)},\n            \"y\": {\"chunks\": ds.y.shape, **optimize_coord_encoding(ds.y.values, self.extent.resolution.y)},\n        }\n        var_encoding = {\n            name: {\n                \"chunks\": (self.chunk_size, self.chunk_size),\n                \"compressors\": [BloscCodec(clevel=9)],\n                **self._channels_encoding[name],\n            }\n            for name in self.channels\n        }\n        encoding = {\n            \"spatial_ref\": {\"chunks\": None, \"dtype\": \"int32\"},\n            **coords_encoding,\n            **var_encoding,\n        }\n        logger.debug(f\"Datacube {encoding=}\")\n\n        ds.to_zarr(\n            session.store,\n            encoding=encoding,\n            compute=False,\n            consolidated=False,\n            zarr_format=3,\n            mode=\"w\" if overwrite else \"w-\",\n        )\n\n        commit = session.commit(\"Initialize empty datacube\")\n        logger.debug(f\"Datacube created: {commit=}\")\n\n        self.post_create()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.create(overwrite)","title":"<code>overwrite</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Allowing overwriting an existing datacube. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.current_state","title":"current_state","text":"<pre><code>current_state() -&gt; gpd.GeoDataFrame | None\n</code></pre> <p>Get info about currently stored tiles.</p> <p>Returns:</p> <ul> <li> <code>GeoDataFrame | None</code>           \u2013            <p>gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def current_state(self) -&gt; gpd.GeoDataFrame | None:\n    \"\"\"Get info about currently stored tiles.\n\n    Returns:\n        gpd.GeoDataFrame: Tiles from odc.geo.GeoboxTiles. None if datacube is empty.\n\n    \"\"\"\n    import geopandas as gpd\n\n    if not self.created:\n        return None\n\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(session.store, mode=\"r\")\n    loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n\n    if len(loaded_tiles) == 0:\n        return None\n\n    tiles = GeoboxTiles(self.extent, (self.chunk_size, self.chunk_size))\n    loaded_tiles = [{\"geometry\": tiles[_id_to_tileidx(tid)].extent.geom, \"id\": tid} for tid in loaded_tiles]\n    gdf = gpd.GeoDataFrame(loaded_tiles, crs=self.extent.crs.to_wkt())\n    return gdf\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.download_tile","title":"download_tile","text":"<pre><code>download_tile(\n    zcube: Group, tile: TileWrapper\n) -&gt; xr.Dataset\n</code></pre> <p>Download a tile from Google Earth Engine.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The downloaded tile data.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/gee.py</code> <pre><code>def download_tile(self, zcube: zarr.Group, tile: TileWrapper) -&gt; xr.Dataset:\n    \"\"\"Download a tile from Google Earth Engine.\n\n    Args:\n        zcube (zarr.Group): The zarr datacube to download the tile to.\n        tile (TileWrapper): The tile to download.\n\n    Returns:\n        xr.Dataset: The downloaded tile data.\n\n    \"\"\"\n    import ee\n    import rioxarray  # noqa: F401\n    import xee  # noqa: F401\n\n    # Note: This is a little bit weird: First we create an own grid which overlaps to the chunks\n    # of the zarr array. Then we create a mosaic of the data and clip it to a single chunk.\n    # We could load the images from the collection directly instead of creating a mosaic.\n    # However, this would require more testing and probably results a lot of manual computation\n    # of slices etc. like in the stac variant. So for now, we just use the mosaic.\n    logging.getLogger(\"urllib3.connectionpool\").disabled = True\n    geom = ee.Geometry.Rectangle(tile.item.geographic_extent.boundingbox)\n    ee_img = ee.ImageCollection(self.collection).mosaic().clip(geom)\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=UserWarning, message=EE_WARN_MSG)\n        tiledata = xr.open_dataset(\n            ee_img,\n            engine=\"ee\",\n            geometry=geom,\n            crs=f\"epsg:{self.extent.crs.to_epsg()}\",\n            scale=self.extent.resolution.x,\n        )\n\n    # TODO: Allow for multi-temporal datacubes and lat/lon coordinates\n    tiledata = tiledata.max(\"time\").rename({\"lon\": \"x\", \"lat\": \"y\"}).transpose(\"y\", \"x\")\n\n    # Download the data\n    tiledata.load()\n    logging.getLogger(\"urllib3.connectionpool\").disabled = False\n\n    # Flip y-axis, because convention is x in positive direction and y in negative, but gee use positive for both\n    tiledata = tiledata.isel(y=slice(None, None, -1))\n\n    # For some reason xee does not always set the crs\n    tiledata = tiledata.odc.assign_crs(self.extent.crs)\n\n    # Recrop the data to the tile, since gee does not always return the exact extent\n    tiledata = tiledata.odc.crop(tile.item.extent)\n\n    # Save original min-max values for each band for clipping later\n    clip_values = {\n        band: (tiledata[band].min().values.item(), tiledata[band].max().values.item())\n        for band in tiledata.data_vars\n    }\n\n    # Interpolate missing values (there are very few, so we actually can interpolate them)\n    tiledata.rio.set_spatial_dims(x_dim=\"x\", y_dim=\"y\", inplace=True)\n    for band in tiledata.data_vars:\n        tiledata[band] = tiledata[band].rio.write_nodata(np.nan).rio.interpolate_na()\n\n    # Convert to uint8\n    for band in tiledata.data_vars:\n        band_min, band_max = clip_values[band]\n        tiledata[band] = (\n            tiledata[band].clip(band_min, band_max, keep_attrs=True).astype(\"uint8\").rio.write_nodata(None)\n        )\n\n    return tiledata\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.download_tile(zcube)","title":"<code>zcube</code>","text":"(<code>Group</code>)           \u2013            <p>The zarr datacube to download the tile to.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.download_tile(tile)","title":"<code>tile</code>","text":"(<code>TileWrapper</code>)           \u2013            <p>The tile to download.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.load","title":"load","text":"<pre><code>load(\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load(\n    self,\n    geobox: GeoBox,\n    buffer: int = 0,\n    persist: bool = True,\n    create: bool = False,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        geobox (GeoBox): The reference geobox to load the data for.\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} tile {'loading' if persist else 'lazy-loading'}\"):\n        logger.debug(f\"{_geobox_repr(geobox)}: {geobox.resolution} original resolution\")\n\n        # Create the datacube if it does not exist\n        if create:\n            try:\n                self.create(overwrite=False)\n            except FileExistsError:  # We are okay if the datacube already exists\n                pass\n        else:\n            # Check if the datacube exists\n            self.assert_created()\n\n        # Download the adjacent tiles (if necessary)\n        reference_geobox = geobox.to_crs(self.extent.crs, resolution=self.extent.resolution.x).pad(buffer)\n        self.procedural_download(reference_geobox, concurrency_mode=concurrency_mode)\n\n        # Load the datacube and set the spatial_ref since it is set as a coordinate within the zarr format\n        session = self.repo.readonly_session(\"main\")\n        chunks = None if persist else \"auto\"\n        xrcube = xr.open_zarr(\n            session.store,\n            mask_and_scale=False,\n            chunks=chunks,\n            consolidated=False,\n        ).set_coords(\"spatial_ref\")\n\n        # Get an AOI slice of the datacube\n        xrcube_aoi = xrcube.odc.crop(reference_geobox.extent, apply_mask=False)\n\n        # The following code would load the lazy zarr data from disk into memory\n        if persist:\n            with self.stopuhr(f\"{_geobox_repr(geobox)}: {self.title} AOI loading from disk\"):\n                xrcube_aoi = xrcube_aoi.load()\n    return xrcube_aoi\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.load(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to load the data for.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.load(buffer)","title":"<code>buffer</code>","text":"(<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.load(persist)","title":"<code>persist</code>","text":"(<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.load(create)","title":"<code>create</code>","text":"(<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.load(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.load_like","title":"load_like","text":"<pre><code>load_like(\n    ref: Dataset | DataArray, **kwargs: Unpack[LoadParams]\n) -&gt; xr.Dataset\n</code></pre> <p>Load the data for the given geobox.</p> <p>Parameters:</p> <p>Other Parameters:</p> <ul> <li> <code>buffer</code>               (<code>int</code>)           \u2013            <p>The buffer around the projected geobox in pixels. Defaults to 0.</p> </li> <li> <code>persist</code>               (<code>bool</code>)           \u2013            <p>If the data should be persisted in memory. If not, this will return a Dask backed Dataset. Defaults to True.</p> </li> <li> <code>create</code>               (<code>bool</code>)           \u2013            <p>Create a new zarr array at defined storage if it not exists. This is not recommended, because it can have side effects in a multi-process environment. Defaults to False.</p> </li> <li> <code>concurrency_mode</code>               (<code>ConcurrencyModes</code>)           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def load_like(\n    self,\n    ref: xr.Dataset | xr.DataArray,\n    **kwargs: Unpack[LoadParams],\n) -&gt; xr.Dataset:\n    \"\"\"Load the data for the given geobox.\n\n    Args:\n        ref (xr.Dataset | xr.DataArray): The reference dataarray or dataset to load the data for.\n        **kwargs: The load parameters (buffer, persist, create, concurrency_mode).\n\n    Keyword Args:\n        buffer (int, optional): The buffer around the projected geobox in pixels. Defaults to 0.\n        persist (bool, optional): If the data should be persisted in memory.\n            If not, this will return a Dask backed Dataset. Defaults to True.\n        create (bool, optional): Create a new zarr array at defined storage if it not exists.\n            This is not recommended, because it can have side effects in a multi-process environment.\n            Defaults to False.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Returns:\n        xr.Dataset: The loaded dataset in the same resolution and extent like the geobox.\n\n    \"\"\"\n    return self.load(_geobox_repr(ref.geobox), **kwargs)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.load_like(ref)","title":"<code>ref</code>","text":"(<code>Dataset | DataArray</code>)           \u2013            <p>The reference dataarray or dataset to load the data for.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.load_like(**kwargs)","title":"<code>**kwargs</code>","text":"(<code>Unpack[LoadParams]</code>, default:                   <code>{}</code> )           \u2013            <p>The load parameters (buffer, persist, create, concurrency_mode).</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.log_benchmark_summary","title":"log_benchmark_summary","text":"<pre><code>log_benchmark_summary()\n</code></pre> <p>Log the benchmark summary.</p> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def log_benchmark_summary(self):\n    \"\"\"Log the benchmark summary.\"\"\"\n    self.stopuhr.summary()\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.open_xarray","title":"open_xarray","text":"<pre><code>open_xarray() -&gt; xr.Dataset\n</code></pre> <p>Open the xarray datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Dataset</code>           \u2013            <p>xr.Dataset: The xarray datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_xarray(self) -&gt; xr.Dataset:\n    \"\"\"Open the xarray datacube in read-only mode.\n\n    Returns:\n        xr.Dataset: The xarray datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    xcube = xr.open_zarr(session.store, mask_and_scale=False, consolidated=False).set_coords(\"spatial_ref\")\n    return xcube\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.open_zarr","title":"open_zarr","text":"<pre><code>open_zarr() -&gt; zarr.Group\n</code></pre> <p>Open the zarr datacube in read-only mode.</p> <p>Returns:</p> <ul> <li> <code>Group</code>           \u2013            <p>zarr.Group: The zarr datacube.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def open_zarr(self) -&gt; zarr.Group:\n    \"\"\"Open the zarr datacube in read-only mode.\n\n    Returns:\n        zarr.Group: The zarr datacube.\n\n    \"\"\"\n    self.assert_created()\n    session = self.repo.readonly_session(\"main\")\n    zcube = zarr.open(store=session.store, mode=\"r\")\n    return zcube\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.post_create","title":"post_create","text":"<pre><code>post_create()\n</code></pre> <p>Post create actions. Can be overwritten by the dataset accessor.</p> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def post_create(self):\n    \"\"\"Post create actions. Can be overwritten by the dataset accessor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.procedural_download","title":"procedural_download","text":"<pre><code>procedural_download(\n    geobox: GeoBox,\n    concurrency_mode: ConcurrencyModes = \"blocking\",\n)\n</code></pre> <p>Download the data for the given geobox.</p> Note <p>The \"threading\" concurrency mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If an unknown concurrency mode is provided.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download(self, geobox: GeoBox, concurrency_mode: ConcurrencyModes = \"blocking\"):\n    \"\"\"Download the data for the given geobox.\n\n    Note:\n        The \"threading\" concurrency mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The reference geobox to download the data for.\n        concurrency_mode (ConcurrencyModes, optional): The concurrency mode for the download.\n            Defaults to \"blocking\".\n\n    Raises:\n        ValueError: If an unknown concurrency mode is provided.\n\n    \"\"\"\n    self.assert_created()\n    if concurrency_mode == \"blocking\":\n        self.procedural_download_blocking(geobox)\n    elif concurrency_mode == \"threading\":\n        self.procedural_download_threading(geobox)\n    else:\n        raise ValueError(f\"Unknown concurrency mode {concurrency_mode}\")\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.procedural_download(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The reference geobox to download the data for.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.procedural_download(concurrency_mode)","title":"<code>concurrency_mode</code>","text":"(<code>ConcurrencyModes</code>, default:                   <code>'blocking'</code> )           \u2013            <p>The concurrency mode for the download. Defaults to \"blocking\".</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.procedural_download_blocking","title":"procedural_download_blocking","text":"<pre><code>procedural_download_blocking(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in blocking mode.</p> Warning <p>This method is meant for single-process use, but can (in theory) be used in a multi-process environment. However, in a multi-process environment it can happen that multiple processes try to write concurrently, which results in a conflict. In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If no tries are left.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_blocking(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in blocking mode.\n\n    Warning:\n        This method is meant for single-process use, but can (in theory) be used in a multi-process environment.\n        However, in a multi-process environment it can happen that multiple processes try to write concurrently,\n        which results in a conflict.\n        In such cases, the download will be retried until it succeeds or the number of maximum-tries is reached.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        ValueError: If no tries are left.\n\n    \"\"\"\n    with self.stopuhr(f\"{_geobox_repr(geobox)}: Procedural download in blocking mode\"):\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        session = self.repo.readonly_session(\"main\")\n        zcube = zarr.open(store=session.store, mode=\"r\")\n        loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n        new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n        logger.debug(\n            f\"{_geobox_repr(geobox)}:  {len(adjacent_tiles)=} &amp; {len(loaded_tiles)=}\"\n            f\" -&gt; {len(new_tiles)=} to download\"\n        )\n        if not new_tiles:\n            return\n\n        for tile in new_tiles:\n            with self.stopuhr(f\"{tile.id=}: Downloading one new tile in blocking mode\"):\n                logger.debug(f\"{tile.id=}: Start downloading\")\n                tiledata = self.download_tile(tile)\n\n            # Try to write the data to file until a limit is reached\n            limit = 100\n            for i in range(limit):\n                try:\n                    self._write_tile_to_zarr(tiledata, tile)\n                    break\n                except icechunk.ConflictError as conflict_error:\n                    logger.debug(f\"{tile.id=}: {conflict_error=} at retry {i}/{limit}\")\n            else:\n                logger.error(\n                    f\"{tile.id=}: {limit} tries to write the tile failed. \"\n                    \"Please check if the datacube is already created and not empty.\"\n                )\n                raise ValueError(f\"{tile.id=}: {limit} tries to write the tile failed.\")\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.procedural_download_blocking(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.procedural_download_threading","title":"procedural_download_threading","text":"<pre><code>procedural_download_threading(geobox: GeoBox)\n</code></pre> <p>Download tiles procedurally in threading mode.</p> Note <p>This method ensures that only a single download is running at a time. It uses a SetQueue to prevent duplicate downloads. The threading mode requires Python 3.13 or higher.</p> <p>Parameters:</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.</p> </li> <li> <code>RuntimeError</code>             \u2013            <p>If the Python version is lower than 3.13.</p> </li> </ul> Source code in <code>src/smart_geocubes/accessors/base.py</code> <pre><code>def procedural_download_threading(self, geobox: GeoBox):\n    \"\"\"Download tiles procedurally in threading mode.\n\n    Note:\n        This method ensures that only a single download is running at a time.\n        It uses a SetQueue to prevent duplicate downloads.\n        The threading mode requires Python 3.13 or higher.\n\n    Args:\n        geobox (GeoBox): The geobox of the aoi to download.\n\n    Raises:\n        ValueError: If no adjacent tiles are found. This can happen if the geobox is out of the dataset bounds.\n        RuntimeError: If the Python version is lower than 3.13.\n\n    \"\"\"\n    if not _check_python_version(3, 13):\n        raise RuntimeError(\"Threading mode requires Python 3.13 or higher\")\n    with self._threading_handler:\n        adjacent_tiles = self.adjacent_tiles(geobox)\n        if not adjacent_tiles:\n            logger.error(f\"{_geobox_repr(geobox)}: No adjacent tiles found: {adjacent_tiles=}\")\n            raise ValueError(\"No adjacent tiles found - is the provided geobox corrent?\")\n\n        # Wait until all new_items are loaded\n        prev_len = None\n        while True:\n            session = self.repo.readonly_session(\"main\")\n            zcube = zarr.open(store=session.store, mode=\"r\")\n            loaded_tiles = zcube.attrs.get(\"loaded_tiles\", [])\n            new_tiles = [tile for tile in adjacent_tiles if tile.id not in loaded_tiles]\n            done_tiles = [tile for tile in adjacent_tiles if tile.id in loaded_tiles]\n            if not new_tiles:\n                break\n            if prev_len != len(new_tiles):\n                logger.debug(\n                    f\"{_geobox_repr(geobox)}: {len(done_tiles)} of {len(adjacent_tiles)} downloaded.\"\n                    f\" Missing: {[t.id for t in new_tiles]} Done: {[t.id for t in done_tiles]}\"\n                )\n            for tile in new_tiles:\n                self._threading_handler._queue.put(tile)\n            prev_len = len(new_tiles)\n            time.sleep(5)\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.procedural_download_threading(geobox)","title":"<code>geobox</code>","text":"(<code>GeoBox</code>)           \u2013            <p>The geobox of the aoi to download.</p>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.visualize_state","title":"visualize_state","text":"<pre><code>visualize_state(\n    ax: Axes | None = None,\n) -&gt; plt.Figure | plt.Axes\n</code></pre> <p>Visulize the extend, hence the already downloaded and filled data, of the datacube.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Figure | Axes</code>           \u2013            <p>plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the datacube is empty</p> </li> </ul> Source code in <code>src/smart_geocubes/datasets/tctrend.py</code> <pre><code>def visualize_state(self, ax: \"plt.Axes | None\" = None) -&gt; \"plt.Figure | plt.Axes\":\n    \"\"\"Visulize the extend, hence the already downloaded and filled data, of the datacube.\n\n    Args:\n        ax (plt.Axes | None): The axes drawn to. If None, will create a new figure and axes.\n\n    Returns:\n        plt.Figure | plt.Axes: The figure with the visualization if no axes was provided, else the axes.\n\n    Raises:\n        ValueError: If the datacube is empty\n\n    \"\"\"\n    import cartopy.crs as ccrs\n    import cartopy.feature as cfeature\n    import matplotlib.pyplot as plt\n\n    tile_info = self.current_state()\n\n    if tile_info is None:\n        raise ValueError(\"Datacube is not created or loaded yet. Can't visualize!\")\n\n    # Define the projection\n    projection = ccrs.PlateCarree()\n\n    # Create a figure\n    fig = None\n    if ax is None:\n        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={\"projection\": projection})\n\n    # Set the extent to show the whole world\n    ax.set_extent([-180, 180, -90, 90], crs=ccrs.PlateCarree())\n\n    # Add features\n    ax.add_feature(cfeature.LAND, zorder=0, edgecolor=\"black\", facecolor=\"white\")\n    ax.add_feature(cfeature.OCEAN, zorder=0, facecolor=\"lightgrey\")\n    ax.add_feature(cfeature.COASTLINE)\n    ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n    ax.add_feature(cfeature.LAKES, alpha=0.5)\n    ax.add_feature(cfeature.RIVERS)\n\n    # Add gridlines\n    gl = ax.gridlines(draw_labels=True)\n    gl.top_labels = False\n    gl.right_labels = False\n\n    tile_info.plot(\n        \"id\",\n        ax=ax,\n        transform=ccrs.PlateCarree(),\n        edgecolor=\"black\",\n        categorical=True,\n        aspect=\"equal\",\n        alpha=0.5,\n    )\n\n    if fig is not None:\n        return fig\n    else:\n        return ax\n</code></pre>"},{"location":"reference/smart_geocubes/datasets/tctrend/#smart_geocubes.datasets.tctrend.TCTrend.visualize_state(ax)","title":"<code>ax</code>","text":"(<code>Axes | None</code>, default:                   <code>None</code> )           \u2013            <p>The axes drawn to. If None, will create a new figure and axes.</p>"},{"location":"reference/smart_geocubes/exceptions/","title":"smart_geocubes.exceptions","text":""},{"location":"reference/smart_geocubes/exceptions/#smart_geocubes.exceptions","title":"smart_geocubes.exceptions","text":"<p>Exceptions for the smart_geocubes package.</p> <p>Classes:</p> <ul> <li> <code>AlreadyDownloadedError</code>           \u2013            <p>Exception to raise when a tile is already downloaded.</p> </li> </ul>"},{"location":"reference/smart_geocubes/exceptions/#smart_geocubes.exceptions.AlreadyDownloadedError","title":"AlreadyDownloadedError","text":"<p>               Bases: <code>Exception</code></p> <p>Exception to raise when a tile is already downloaded.</p>"}]}